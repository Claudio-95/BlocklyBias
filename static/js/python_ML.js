// Do not edit this file; automatically generated by gulp.

/* eslint-disable */

var VarData = {};


(function (root, factory) {
    if (typeof define === "function" && define.amd) {
        // AMD
        define(["./blockly_compressed.js"], factory);
    } else if (typeof exports === "object") {
        // Node.js
        module.exports = factory(require("./blockly_compressed.js"));
    } else {
        // Browser
        root.Blockly.Python = factory(root.Blockly);
    }
})(this, function (Blockly) {
    "use strict";
    Blockly.Python = new Blockly.Generator("Python");
    Blockly.Python.addReservedWords(
        "False,None,True,and,as,assert,break,class,continue,def,del,elif,else,except,exec,finally,for,from,global,if,import,in,is,lambda,nonlocal,not,or,pass,print,raise,return,try,while,with,yield,NotImplemented,Ellipsis,__debug__,quit,exit,copyright,license,credits,ArithmeticError,AssertionError,AttributeError,BaseException,BlockingIOError,BrokenPipeError,BufferError,BytesWarning,ChildProcessError,ConnectionAbortedError,ConnectionError,ConnectionRefusedError,ConnectionResetError,DeprecationWarning,EOFError,Ellipsis,EnvironmentError,Exception,FileExistsError,FileNotFoundError,FloatingPointError,FutureWarning,GeneratorExit,IOError,ImportError,ImportWarning,IndentationError,IndexError,InterruptedError,IsADirectoryError,KeyError,KeyboardInterrupt,LookupError,MemoryError,ModuleNotFoundError,NameError,NotADirectoryError,NotImplemented,NotImplementedError,OSError,OverflowError,PendingDeprecationWarning,PermissionError,ProcessLookupError,RecursionError,ReferenceError,ResourceWarning,RuntimeError,RuntimeWarning,StandardError,StopAsyncIteration,StopIteration,SyntaxError,SyntaxWarning,SystemError,SystemExit,TabError,TimeoutError,TypeError,UnboundLocalError,UnicodeDecodeError,UnicodeEncodeError,UnicodeError,UnicodeTranslateError,UnicodeWarning,UserWarning,ValueError,Warning,ZeroDivisionError,_,__build_class__,__debug__,__doc__,__import__,__loader__,__name__,__package__,__spec__,abs,all,any,apply,ascii,basestring,bin,bool,buffer,bytearray,bytes,callable,chr,classmethod,cmp,coerce,compile,complex,copyright,credits,delattr,dict,dir,divmod,enumerate,eval,exec,execfile,exit,file,filter,float,format,frozenset,getattr,globals,hasattr,hash,help,hex,id,input,int,intern,isinstance,issubclass,iter,len,license,list,locals,long,map,max,memoryview,min,next,object,oct,open,ord,pow,print,property,quit,range,raw_input,reduce,reload,repr,reversed,round,set,setattr,slice,sorted,staticmethod,str,sum,super,tuple,type,unichr,unicode,vars,xrange,zip"
    );
    Blockly.Python.VARDATA = [];
    Blockly.Python.ORDER_ATOMIC = 0;
    Blockly.Python.ORDER_COLLECTION = 1;
    Blockly.Python.ORDER_STRING_CONVERSION = 1;
    Blockly.Python.ORDER_MEMBER = 2.1;
    Blockly.Python.ORDER_FUNCTION_CALL = 2.2;
    Blockly.Python.ORDER_EXPONENTIATION = 3;
    Blockly.Python.ORDER_UNARY_SIGN = 4;
    Blockly.Python.ORDER_BITWISE_NOT = 4;
    Blockly.Python.ORDER_MULTIPLICATIVE = 5;
    Blockly.Python.ORDER_ADDITIVE = 6;
    Blockly.Python.ORDER_BITWISE_SHIFT = 7;
    Blockly.Python.ORDER_BITWISE_AND = 8;
    Blockly.Python.ORDER_BITWISE_XOR = 9;
    Blockly.Python.ORDER_BITWISE_OR = 10;
    Blockly.Python.ORDER_RELATIONAL = 11;
    Blockly.Python.ORDER_LOGICAL_NOT = 12;
    Blockly.Python.ORDER_LOGICAL_AND = 13;
    Blockly.Python.ORDER_LOGICAL_OR = 14;
    Blockly.Python.ORDER_CONDITIONAL = 15;
    Blockly.Python.ORDER_LAMBDA = 16;
    Blockly.Python.ORDER_NONE = 99;
    Blockly.Python.ORDER_OVERRIDES = [
        [Blockly.Python.ORDER_FUNCTION_CALL, Blockly.Python.ORDER_MEMBER],
        [Blockly.Python.ORDER_FUNCTION_CALL, Blockly.Python.ORDER_FUNCTION_CALL],
        [Blockly.Python.ORDER_MEMBER, Blockly.Python.ORDER_MEMBER],
        [Blockly.Python.ORDER_MEMBER, Blockly.Python.ORDER_FUNCTION_CALL],
        [Blockly.Python.ORDER_LOGICAL_NOT, Blockly.Python.ORDER_LOGICAL_NOT],
        [Blockly.Python.ORDER_LOGICAL_AND, Blockly.Python.ORDER_LOGICAL_AND],
        [Blockly.Python.ORDER_LOGICAL_OR, Blockly.Python.ORDER_LOGICAL_OR],
    ];
    Blockly.Python.isInitialized = !1;
    Blockly.Python.init = function (a) {
        Blockly.Python.PASS = this.INDENT + "pass\n";
        Blockly.Python.definitions_ = Object.create(null);
        Blockly.Python.functionNames_ = Object.create(null);
        Blockly.Python.variableDB_ ? Blockly.Python.variableDB_.reset() : (Blockly.Python.variableDB_ = new Blockly.Names(Blockly.Python.RESERVED_WORDS_));
        Blockly.Python.variableDB_.setVariableMap(a.getVariableMap());
        for (var b = [], c = Blockly.Variables.allDeveloperVariables(a), d = 0; d < c.length; d++) b.push(Blockly.Python.variableDB_.getName(c[d], Blockly.Names.DEVELOPER_VARIABLE_TYPE) + " = None");
        a = Blockly.Variables.allUsedVarModels(a);

        for (d = 0; d < a.length; d++) b.push(Blockly.Python.variableDB_.getName(a[d].getId(), Blockly.VARIABLE_CATEGORY_NAME) + " = None");
        Blockly.Python.definitions_.variables = b.join("\n");
        this.isInitialized = !0;
    };
    Blockly.Python.finish = function (a) {
        var b = [],
            c = [],
            d;
        for (d in Blockly.Python.definitions_) {
            var e = Blockly.Python.definitions_[d];
            e.match(/^(from\s+\S+\s+)?import\s+\S+/) ? b.push(e) : c.push(e);
        }
        delete Blockly.Python.definitions_;
        delete Blockly.Python.functionNames_;
        Blockly.Python.variableDB_.reset();
        return (b.join("\n") + "\n\n" + c.join("\n\n")).replace(/\n\n+/g, "\n\n").replace(/\n*$/, "\n\n\n") + a;
    };
    Blockly.Python.scrubNakedValue = function (a) {
        return a + "\n";
    };
    Blockly.Python.quote_ = function (a) {
        a = a.replace(/\\/g, "\\\\").replace(/\n/g, "\\\n");
        var b = "'";
        -1 !== a.indexOf("'") && (-1 === a.indexOf('"') ? (b = '"') : (a = a.replace(/'/g, "\\'")));
        return b + a + b;
    };
    Blockly.Python.multiline_quote_ = function (a) {
        return a.split(/\n/g).map(Blockly.Python.quote_).join(" + '\\n' + \n");
    };
    Blockly.Python.scrub_ = function (a, b, c) {
        var d = "";
        if (!a.outputConnection || !a.outputConnection.targetConnection) {
            var e = a.getCommentText();
            e && ((e = Blockly.utils.string.wrap(e, Blockly.Python.COMMENT_WRAP - 3)), (d += Blockly.Python.prefixLines(e + "\n", "# ")));
            for (var f = 0; f < a.inputList.length; f++) a.inputList[f].type == Blockly.INPUT_VALUE && (e = a.inputList[f].connection.targetBlock()) && (e = Blockly.Python.allNestedComments(e)) && (d += Blockly.Python.prefixLines(e, "# "));
        }
        a = a.nextConnection && a.nextConnection.targetBlock();
        c = c ? "" : Blockly.Python.blockToCode(a);
        return d + b + c;
    };
    Blockly.Python.getAdjustedInt = function (a, b, c, d) {
        c = c || 0;
        a.workspace.options.oneBasedIndex && c--;
        var e = a.workspace.options.oneBasedIndex ? "1" : "0";
        a = Blockly.Python.valueToCode(a, b, c ? Blockly.Python.ORDER_ADDITIVE : Blockly.Python.ORDER_NONE) || e;
        Blockly.isNumber(a) ? ((a = parseInt(a, 10) + c), d && (a = -a)) : ((a = 0 < c ? "int(" + a + " + " + c + ")" : 0 > c ? "int(" + a + " - " + -c + ")" : "int(" + a + ")"), d && (a = "-" + a));
        return a;
    };
    Blockly.Python.colour = {};
    Blockly.Python.colour_picker = function (a) {
        return [Blockly.Python.quote_(a.getFieldValue("COLOUR")), Blockly.Python.ORDER_ATOMIC];
    };
    Blockly.Python.colour_random = function (a) {
        Blockly.Python.definitions_.import_random = "import random";
        return ["'#%06x' % random.randint(0, 2**24 - 1)", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.colour_rgb = function (a) {
        var b = Blockly.Python.provideFunction_("colour_rgb", [
            "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(r, g, b):",
            "  r = round(min(100, max(0, r)) * 2.55)",
            "  g = round(min(100, max(0, g)) * 2.55)",
            "  b = round(min(100, max(0, b)) * 2.55)",
            "  return '#%02x%02x%02x' % (r, g, b)",
        ]),
            c = Blockly.Python.valueToCode(a, "RED", Blockly.Python.ORDER_NONE) || 0,
            d = Blockly.Python.valueToCode(a, "GREEN", Blockly.Python.ORDER_NONE) || 0;
        a = Blockly.Python.valueToCode(a, "BLUE", Blockly.Python.ORDER_NONE) || 0;
        return [b + "(" + c + ", " + d + ", " + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.colour_blend = function (a) {
        var b = Blockly.Python.provideFunction_("colour_blend", [
            "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(colour1, colour2, ratio):",
            "  r1, r2 = int(colour1[1:3], 16), int(colour2[1:3], 16)",
            "  g1, g2 = int(colour1[3:5], 16), int(colour2[3:5], 16)",
            "  b1, b2 = int(colour1[5:7], 16), int(colour2[5:7], 16)",
            "  ratio = min(1, max(0, ratio))",
            "  r = round(r1 * (1 - ratio) + r2 * ratio)",
            "  g = round(g1 * (1 - ratio) + g2 * ratio)",
            "  b = round(b1 * (1 - ratio) + b2 * ratio)",
            "  return '#%02x%02x%02x' % (r, g, b)",
        ]),
            c = Blockly.Python.valueToCode(a, "COLOUR1", Blockly.Python.ORDER_NONE) || "'#000000'",
            d = Blockly.Python.valueToCode(a, "COLOUR2", Blockly.Python.ORDER_NONE) || "'#000000'";
        a = Blockly.Python.valueToCode(a, "RATIO", Blockly.Python.ORDER_NONE) || 0;
        return [b + "(" + c + ", " + d + ", " + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.lists = {};
    Blockly.Python.lists_create_empty = function (a) {
        return ["[]", Blockly.Python.ORDER_ATOMIC];
    };
    Blockly.Python.lists_create_with = function (a) {
        for (var b = Array(a.itemCount_), c = 0; c < a.itemCount_; c++) b[c] = Blockly.Python.valueToCode(a, "ADD" + c, Blockly.Python.ORDER_NONE) || "None";
        return ["[" + b.join(", ") + "]", Blockly.Python.ORDER_ATOMIC];
    };
    Blockly.Python.lists_repeat = function (a) {
        var b = Blockly.Python.valueToCode(a, "ITEM", Blockly.Python.ORDER_NONE) || "None";
        a = Blockly.Python.valueToCode(a, "NUM", Blockly.Python.ORDER_MULTIPLICATIVE) || "0";
        return ["[" + b + "] * " + a, Blockly.Python.ORDER_MULTIPLICATIVE];
    };
    Blockly.Python.lists_length = function (a) {
        return ["len(" + (Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "[]") + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.lists_isEmpty = function (a) {
        return ["not len(" + (Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "[]") + ")", Blockly.Python.ORDER_LOGICAL_NOT];
    };
    Blockly.Python.lists_indexOf = function (a) {
        var b = Blockly.Python.valueToCode(a, "FIND", Blockly.Python.ORDER_NONE) || "[]",
            c = Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "''";
        if (a.workspace.options.oneBasedIndex)
            var d = " 0",
                e = " + 1",
                f = "";
        else (d = " -1"), (e = ""), (f = " - 1");
        if ("FIRST" == a.getFieldValue("END"))
            return (
                (a = Blockly.Python.provideFunction_("first_index", ["def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(my_list, elem):", "  try: index = my_list.index(elem)" + e, "  except: index =" + d, "  return index"])),
                [a + "(" + c + ", " + b + ")", Blockly.Python.ORDER_FUNCTION_CALL]
            );
        a = Blockly.Python.provideFunction_("last_index", ["def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(my_list, elem):", "  try: index = len(my_list) - my_list[::-1].index(elem)" + f, "  except: index =" + d, "  return index"]);
        return [a + "(" + c + ", " + b + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.lists_getIndex = function (a) {
        var b = a.getFieldValue("MODE") || "GET",
            c = a.getFieldValue("WHERE") || "FROM_START",
            d = Blockly.Python.valueToCode(a, "VALUE", "RANDOM" == c ? Blockly.Python.ORDER_NONE : Blockly.Python.ORDER_MEMBER) || "[]";
        switch (c) {
            case "FIRST":
                if ("GET" == b) return [d + "[0]", Blockly.Python.ORDER_MEMBER];
                if ("GET_REMOVE" == b) return [d + ".pop(0)", Blockly.Python.ORDER_FUNCTION_CALL];
                if ("REMOVE" == b) return d + ".pop(0)\n";
                break;
            case "LAST":
                if ("GET" == b) return [d + "[-1]", Blockly.Python.ORDER_MEMBER];
                if ("GET_REMOVE" == b) return [d + ".pop()", Blockly.Python.ORDER_FUNCTION_CALL];
                if ("REMOVE" == b) return d + ".pop()\n";
                break;
            case "FROM_START":
                a = Blockly.Python.getAdjustedInt(a, "AT");
                if ("GET" == b) return [d + "[" + a + "]", Blockly.Python.ORDER_MEMBER];
                if ("GET_REMOVE" == b) return [d + ".pop(" + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
                if ("REMOVE" == b) return d + ".pop(" + a + ")\n";
                break;
            case "FROM_END":
                a = Blockly.Python.getAdjustedInt(a, "AT", 1, !0);
                if ("GET" == b) return [d + "[" + a + "]", Blockly.Python.ORDER_MEMBER];
                if ("GET_REMOVE" == b) return [d + ".pop(" + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
                if ("REMOVE" == b) return d + ".pop(" + a + ")\n";
                break;
            case "RANDOM":
                Blockly.Python.definitions_.import_random = "import random";
                if ("GET" == b) return ["random.choice(" + d + ")", Blockly.Python.ORDER_FUNCTION_CALL];
                d = Blockly.Python.provideFunction_("lists_remove_random_item", ["def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(myList):", "  x = int(random.random() * len(myList))", "  return myList.pop(x)"]) + "(" + d + ")";
                if ("GET_REMOVE" == b) return [d, Blockly.Python.ORDER_FUNCTION_CALL];
                if ("REMOVE" == b) return d + "\n";
        }
        throw Error("Unhandled combination (lists_getIndex).");
    };
    Blockly.Python.lists_setIndex = function (a) {
        var b = Blockly.Python.valueToCode(a, "LIST", Blockly.Python.ORDER_MEMBER) || "[]",
            c = a.getFieldValue("MODE") || "GET",
            d = a.getFieldValue("WHERE") || "FROM_START",
            e = Blockly.Python.valueToCode(a, "TO", Blockly.Python.ORDER_NONE) || "None";
        switch (d) {
            case "FIRST":
                if ("SET" == c) return b + "[0] = " + e + "\n";
                if ("INSERT" == c) return b + ".insert(0, " + e + ")\n";
                break;
            case "LAST":
                if ("SET" == c) return b + "[-1] = " + e + "\n";
                if ("INSERT" == c) return b + ".append(" + e + ")\n";
                break;
            case "FROM_START":
                a = Blockly.Python.getAdjustedInt(a, "AT");
                if ("SET" == c) return b + "[" + a + "] = " + e + "\n";
                if ("INSERT" == c) return b + ".insert(" + a + ", " + e + ")\n";
                break;
            case "FROM_END":
                a = Blockly.Python.getAdjustedInt(a, "AT", 1, !0);
                if ("SET" == c) return b + "[" + a + "] = " + e + "\n";
                if ("INSERT" == c) return b + ".insert(" + a + ", " + e + ")\n";
                break;
            case "RANDOM":
                Blockly.Python.definitions_.import_random = "import random";
                b.match(/^\w+$/) ? (a = "") : ((a = Blockly.Python.variableDB_.getDistinctName("tmp_list", Blockly.VARIABLE_CATEGORY_NAME)), (d = a + " = " + b + "\n"), (b = a), (a = d));
                d = Blockly.Python.variableDB_.getDistinctName("tmp_x", Blockly.VARIABLE_CATEGORY_NAME);
                a += d + " = int(random.random() * len(" + b + "))\n";
                if ("SET" == c) return a + (b + "[" + d + "] = " + e + "\n");
                if ("INSERT" == c) return a + (b + ".insert(" + d + ", " + e + ")\n");
        }
        throw Error("Unhandled combination (lists_setIndex).");
    };
    Blockly.Python.lists_getSublist = function (a) {
        var b = Blockly.Python.valueToCode(a, "LIST", Blockly.Python.ORDER_MEMBER) || "[]",
            c = a.getFieldValue("WHERE1"),
            d = a.getFieldValue("WHERE2");
        switch (c) {
            case "FROM_START":
                c = Blockly.Python.getAdjustedInt(a, "AT1");
                "0" == c && (c = "");
                break;
            case "FROM_END":
                c = Blockly.Python.getAdjustedInt(a, "AT1", 1, !0);
                break;
            case "FIRST":
                c = "";
                break;
            default:
                throw Error("Unhandled option (lists_getSublist)");
        }
        switch (d) {
            case "FROM_START":
                a = Blockly.Python.getAdjustedInt(a, "AT2", 1);
                break;
            case "FROM_END":
                a = Blockly.Python.getAdjustedInt(a, "AT2", 0, !0);
                Blockly.isNumber(String(a)) ? "0" == a && (a = "") : ((Blockly.Python.definitions_.import_sys = "import sys"), (a += " or sys.maxsize"));
                break;
            case "LAST":
                a = "";
                break;
            default:
                throw Error("Unhandled option (lists_getSublist)");
        }
        return [b + "[" + c + " : " + a + "]", Blockly.Python.ORDER_MEMBER];
    };
    Blockly.Python.lists_sort = function (a) {
        var b = Blockly.Python.valueToCode(a, "LIST", Blockly.Python.ORDER_NONE) || "[]",
            c = a.getFieldValue("TYPE");
        a = "1" === a.getFieldValue("DIRECTION") ? "False" : "True";
        return [
            Blockly.Python.provideFunction_("lists_sort", [
                "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(my_list, type, reverse):",
                "  def try_float(s):",
                "    try:",
                "      return float(s)",
                "    except:",
                "      return 0",
                "  key_funcs = {",
                '    "NUMERIC": try_float,',
                '    "TEXT": str,',
                '    "IGNORE_CASE": lambda s: str(s).lower()',
                "  }",
                "  key_func = key_funcs[type]",
                "  list_cpy = list(my_list)",
                "  return sorted(list_cpy, key=key_func, reverse=reverse)",
            ]) +
            "(" +
            b +
            ', "' +
            c +
            '", ' +
            a +
            ")",
            Blockly.Python.ORDER_FUNCTION_CALL,
        ];
    };
    Blockly.Python.lists_split = function (a) {
        var b = a.getFieldValue("MODE");
        if ("SPLIT" == b) (b = Blockly.Python.valueToCode(a, "INPUT", Blockly.Python.ORDER_MEMBER) || "''"), (a = Blockly.Python.valueToCode(a, "DELIM", Blockly.Python.ORDER_NONE)), (a = b + ".split(" + a + ")");
        else if ("JOIN" == b) (b = Blockly.Python.valueToCode(a, "INPUT", Blockly.Python.ORDER_NONE) || "[]"), (a = Blockly.Python.valueToCode(a, "DELIM", Blockly.Python.ORDER_MEMBER) || "''"), (a = a + ".join(" + b + ")");
        else throw Error("Unknown mode: " + b);
        return [a, Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.lists_reverse = function (a) {
        return ["list(reversed(" + (Blockly.Python.valueToCode(a, "LIST", Blockly.Python.ORDER_NONE) || "[]") + "))", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.logic = {};
    Blockly.Python.controls_if = function (a) {
        var b = 0,
            c = "";
        Blockly.Python.STATEMENT_PREFIX && (c += Blockly.Python.injectId(Blockly.Python.STATEMENT_PREFIX, a));
        do {
            var d = Blockly.Python.valueToCode(a, "IF" + b, Blockly.Python.ORDER_NONE) || "False";
            var e = Blockly.Python.statementToCode(a, "DO" + b) || Blockly.Python.PASS;
            Blockly.Python.STATEMENT_SUFFIX && (e = Blockly.Python.prefixLines(Blockly.Python.injectId(Blockly.Python.STATEMENT_SUFFIX, a), Blockly.Python.INDENT) + e);
            c += (0 == b ? "if " : "elif ") + d + ":\n" + e;
            ++b;
        } while (a.getInput("IF" + b));
        if (a.getInput("ELSE") || Blockly.Python.STATEMENT_SUFFIX)
            (e = Blockly.Python.statementToCode(a, "ELSE") || Blockly.Python.PASS),
                Blockly.Python.STATEMENT_SUFFIX && (e = Blockly.Python.prefixLines(Blockly.Python.injectId(Blockly.Python.STATEMENT_SUFFIX, a), Blockly.Python.INDENT) + e),
                (c += "else:\n" + e);
        return c;
    };
    Blockly.Python.controls_ifelse = Blockly.Python.controls_if;
    Blockly.Python.logic_compare = function (a) {
        var b = { EQ: "==", NEQ: "!=", LT: "<", LTE: "<=", GT: ">", GTE: ">=" }[a.getFieldValue("OP")],
            c = Blockly.Python.ORDER_RELATIONAL,
            d = Blockly.Python.valueToCode(a, "A", c) || "0";
        a = Blockly.Python.valueToCode(a, "B", c) || "0";
        return [d + " " + b + " " + a, c];
    };
    Blockly.Python.logic_operation = function (a) {
        var b = "AND" == a.getFieldValue("OP") ? "and" : "or",
            c = "and" == b ? Blockly.Python.ORDER_LOGICAL_AND : Blockly.Python.ORDER_LOGICAL_OR,
            d = Blockly.Python.valueToCode(a, "A", c);
        a = Blockly.Python.valueToCode(a, "B", c);
        if (d || a) {
            var e = "and" == b ? "True" : "False";
            d || (d = e);
            a || (a = e);
        } else a = d = "False";
        return [d + " " + b + " " + a, c];
    };
    Blockly.Python.logic_negate = function (a) {
        return ["not " + (Blockly.Python.valueToCode(a, "BOOL", Blockly.Python.ORDER_LOGICAL_NOT) || "True"), Blockly.Python.ORDER_LOGICAL_NOT];
    };
    Blockly.Python.logic_boolean = function (a) {
        return ["TRUE" == a.getFieldValue("BOOL") ? "True" : "False", Blockly.Python.ORDER_ATOMIC];
    };
    Blockly.Python.logic_null = function (a) {
        return ["None", Blockly.Python.ORDER_ATOMIC];
    };
    Blockly.Python.logic_ternary = function (a) {
        var b = Blockly.Python.valueToCode(a, "IF", Blockly.Python.ORDER_CONDITIONAL) || "False",
            c = Blockly.Python.valueToCode(a, "THEN", Blockly.Python.ORDER_CONDITIONAL) || "None";
        a = Blockly.Python.valueToCode(a, "ELSE", Blockly.Python.ORDER_CONDITIONAL) || "None";
        return [c + " if " + b + " else " + a, Blockly.Python.ORDER_CONDITIONAL];
    };
    Blockly.Python.loops = {};
    Blockly.Python.controls_repeat_ext = function (a) {
        var b = a.getField("TIMES") ? String(parseInt(a.getFieldValue("TIMES"), 10)) : Blockly.Python.valueToCode(a, "TIMES", Blockly.Python.ORDER_NONE) || "0";
        b = Blockly.isNumber(b) ? parseInt(b, 10) : "int(" + b + ")";
        var c = Blockly.Python.statementToCode(a, "DO");
        c = Blockly.Python.addLoopTrap(c, a) || Blockly.Python.PASS;
        return "for " + Blockly.Python.variableDB_.getDistinctName("count", Blockly.VARIABLE_CATEGORY_NAME) + " in range(" + b + "):\n" + c;
    };
    Blockly.Python.controls_repeat = Blockly.Python.controls_repeat_ext;
    Blockly.Python.controls_whileUntil = function (a) {
        var b = "UNTIL" == a.getFieldValue("MODE"),
            c = Blockly.Python.valueToCode(a, "BOOL", b ? Blockly.Python.ORDER_LOGICAL_NOT : Blockly.Python.ORDER_NONE) || "False",
            d = Blockly.Python.statementToCode(a, "DO");
        d = Blockly.Python.addLoopTrap(d, a) || Blockly.Python.PASS;
        b && (c = "not " + c);
        return "while " + c + ":\n" + d;
    };
    Blockly.Python.controls_for = function (a) {
        var b = Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME),
            c = Blockly.Python.valueToCode(a, "FROM", Blockly.Python.ORDER_NONE) || "0",
            d = Blockly.Python.valueToCode(a, "TO", Blockly.Python.ORDER_NONE) || "0",
            e = Blockly.Python.valueToCode(a, "BY", Blockly.Python.ORDER_NONE) || "1",
            f = Blockly.Python.statementToCode(a, "DO");
        f = Blockly.Python.addLoopTrap(f, a) || Blockly.Python.PASS;
        var n = "",
            k = function () {
                return Blockly.Python.provideFunction_("upRange", ["def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(start, stop, step):", "  while start <= stop:", "    yield start", "    start += abs(step)"]);
            },
            h = function () {
                return Blockly.Python.provideFunction_("downRange", ["def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(start, stop, step):", "  while start >= stop:", "    yield start", "    start -= abs(step)"]);
            };
        a = function (g, l, p) {
            return "(" + g + " <= " + l + ") and " + k() + "(" + g + ", " + l + ", " + p + ") or " + h() + "(" + g + ", " + l + ", " + p + ")";
        };
        if (Blockly.isNumber(c) && Blockly.isNumber(d) && Blockly.isNumber(e))
            (c = Number(c)),
                (d = Number(d)),
                (e = Math.abs(Number(e))),
                0 === c % 1 && 0 === d % 1 && 0 === e % 1
                    ? (c <= d ? (d++, (a = 0 == c && 1 == e ? d : c + ", " + d), 1 != e && (a += ", " + e)) : (d--, (a = c + ", " + d + ", -" + e)), (a = "range(" + a + ")"))
                    : ((a = c < d ? k() : h()), (a += "(" + c + ", " + d + ", " + e + ")"));
        else {
            var m = function (g, l) {
                Blockly.isNumber(g) ? (g = Number(g)) : g.match(/^\w+$/) ? (g = "float(" + g + ")") : ((l = Blockly.Python.variableDB_.getDistinctName(b + l, Blockly.VARIABLE_CATEGORY_NAME)), (n += l + " = float(" + g + ")\n"), (g = l));
                return g;
            };
            c = m(c, "_start");
            d = m(d, "_end");
            e = m(e, "_inc");
            "number" == typeof c && "number" == typeof d ? ((a = c < d ? k() : h()), (a += "(" + c + ", " + d + ", " + e + ")")) : (a = a(c, d, e));
        }
        return (n += "for " + b + " in " + a + ":\n" + f);
    };
    Blockly.Python.controls_forEach = function (a) {
        var b = Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME),
            c = Blockly.Python.valueToCode(a, "LIST", Blockly.Python.ORDER_RELATIONAL) || "[]",
            d = Blockly.Python.statementToCode(a, "DO");
        d = Blockly.Python.addLoopTrap(d, a) || Blockly.Python.PASS;
        return "for " + b + " in " + c + ":\n" + d;
    };
    Blockly.Python.controls_flow_statements = function (a) {
        var b = "";
        Blockly.Python.STATEMENT_PREFIX && (b += Blockly.Python.injectId(Blockly.Python.STATEMENT_PREFIX, a));
        Blockly.Python.STATEMENT_SUFFIX && (b += Blockly.Python.injectId(Blockly.Python.STATEMENT_SUFFIX, a));
        if (Blockly.Python.STATEMENT_PREFIX) {
            var c = Blockly.Constants.Loops.CONTROL_FLOW_IN_LOOP_CHECK_MIXIN.getSurroundLoop(a);
            c && !c.suppressPrefixSuffix && (b += Blockly.Python.injectId(Blockly.Python.STATEMENT_PREFIX, c));
        }
        switch (a.getFieldValue("FLOW")) {
            case "BREAK":
                return b + "break\n";
            case "CONTINUE":
                return b + "continue\n";
        }
        throw Error("Unknown flow statement.");
    };
    /*
     * Custom
     */
    Blockly.Python.pandas = {};
    Blockly.Python['pandas_read_csv'] = function (a) {
        Blockly.Python.definitions_.pandas = "import pandas as pd";
        // it makes compatible the block with both variable and string blocks
        if (String(a).split(" ").length > 3) {
            // string block input
            return ['pd.read_csv("' + String(a).split(" ")[3] + '")', Blockly.Python.ORDER_FUNCTION_CALL] //Original row: return ['pd.read_csv(' + String(a).split(" ")[2] + ')', Blockly.Python.ORDER_FUNCTION_CALL]
        } else {
            // variable block input
            return ['pd.read_csv(' + String(a).split(" ")[2] + ')', Blockly.Python.ORDER_FUNCTION_CALL];
        }
    }

    Blockly.Python['dataframe_print'] = function (a) {
        var df = Blockly.Python.valueToCode(a, "DATAFRAME", Blockly.Python.ORDER_NONE);
        var codeString = "df_print = " + df + "\n"+
            "df_print\n";
        return codeString;
    }

    Blockly.Python["create_dict"] = function (a) {

        var b = 1,
            c = "{";
        do {
            var d = Blockly.Python.valueToCode(a, "KEY" + b, Blockly.Python.ORDER_NONE) || "";
            var e = Blockly.Python.valueToCode(a, "VAL" + b, Blockly.Python.ORDER_NONE) || "";
            Blockly.Python.STATEMENT_SUFFIX && (e = Blockly.Python.prefixLines(Blockly.Python.injectId(Blockly.Python.STATEMENT_SUFFIX, a), Blockly.Python.INDENT) + e);
            if (b > 1) {
                c += ",";
            }
            c += d + ":" + e;
            ++b;
        } while (a.getInput("KEY" + b));
        c += "}";
        if ((e != "") && (d != "")) {
            return [c, Blockly.Python.ORDER_FUNCTION_CALL];
        } else {
            return ["None", Blockly.Python.ORDER_FUNCTION_CALL];
        }
    }
    Blockly.Python["dict_append"] = function (a) {
        var e = ""
        var b = Blockly.Python.valueToCode(a, "DICTIONARY", Blockly.Python.ORDER_NONE) || "";
        var c = Blockly.Python.valueToCode(a, "KEY", Blockly.Python.ORDER_NONE) || "";
        var d = Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "";
        if ((b != "") && (c != "") && (d != "")) {
            e = b + "[" + c + "] = " + d;
        }
        return e;
    }

    Blockly.Python['seaborn_dataset'] = function (a) {
        Blockly.Python.definitions_.seaborn = "import seaborn as sns";
        VarData[a.inputList[0].fieldRow[1].value_] = 'sns.load_dataset("' + a.inputList[0].fieldRow[1].value_ + '")', Blockly.Python.ORDER_FUNCTION_CALL;
        return ['sns.load_dataset("' + a.inputList[0].fieldRow[1].value_ + '")', Blockly.Python.ORDER_FUNCTION_CALL]
    }

    Blockly.Python['pandas_drop_columns'] = function (a) {
        var columns = Blockly.Python.valueToCode(a, "COLUMN", Blockly.Python.ORDER_UNARY_SIGN)
        if (columns == "") {
            return ""
        }
        var DataFrame = Blockly.Python.valueToCode(a, "DATAFRAME", Blockly.Python.ORDER_UNARY_SIGN)
        if (a.getInputTargetBlock("COLUMN").outputConnection.getCheck() == "String") {
            return [DataFrame + " = " + DataFrame + ".drop([" + columns + "], axis = 1)", Blockly.Python.ORDER_ATOMIC];
        } if (a.getInputTargetBlock("COLUMN").outputConnection.getCheck() == "Array") {
            return [DataFrame + " = " + DataFrame + ".drop(" + columns + ", axis = 1)", Blockly.Python.ORDER_ATOMIC];
        } if (columns == "" || DataFrame == "") {
            return ["", Blockly.Python.ORDER_ATOMIC];
        }
    }

    Blockly.Python['pandas_sample'] = function (a) {
        var factor = Blockly.Python.valueToCode(a, "FACTOR", Blockly.Python.ORDER_UNARY_SIGN)
        if (factor == "") {
            return ""
        }
        var DataFrame = Blockly.Python.valueToCode(a, "DATAFRAME", Blockly.Python.ORDER_UNARY_SIGN)
        if (factor != "" || DataFrame != "") {
            return [DataFrame + ".sample(frac=" + factor + ", replace=True, random_state=123)", Blockly.Python.ORDER_ATOMIC];
        }
    }


    Blockly.Python['pandas_select_columns'] = function (a) {
        var columns = Blockly.Python.valueToCode(a, "COLUMN", Blockly.Python.ORDER_UNARY_SIGN)
        if (columns == "") {
            columns = "[]"
        }
        var DataFrame = Blockly.Python.valueToCode(a, "DATAFRAME", Blockly.Python.ORDER_UNARY_SIGN)
        return [DataFrame + "[" + columns + "]", Blockly.Python.ORDER_ATOMIC];
    }

    Blockly.Python['Print'] = function (a) {
        var INPUT = Blockly.Python.valueToCode(a, "INPUT", Blockly.Python.ORDER_FUNCTION_CALL) || "''";
        var End = a.getFieldValue("END")

        if (End == "newLine") {
            return "print(" + INPUT + ")" + "\n";
        }
        if (End == "tab") {
            return "print(" + INPUT + ",end='\\t')" + "\n";
        }
        if (End == "space") {
            return "print(" + INPUT + ",end=' ')" + "\n";
        }
        if (End == "comma") {
            return "print(" + INPUT + ",end=',')" + "\n";
        }
    }

    Blockly.Python['Input'] = function (a) {
        var INPUT = Blockly.Python.valueToCode(a, "INPUT", Blockly.Python.ORDER_NONE) || "''";
        return ["input(" + INPUT + ")", Blockly.Python.ORDER_FUNCTION_CALL]
    }
    Blockly.Python['pandas_set_columns'] = function (a) {
        var columns = Blockly.Python.valueToCode(a, "COLUMN", Blockly.Python.ORDER_UNARY_SIGN)
        if (columns == "") {
            columns = "[]"
        }
        var DATAFRAME_IN = Blockly.Python.valueToCode(a, "DATAFRAME_IN", Blockly.Python.ORDER_UNARY_SIGN)
        var DATAFRAME_OUT = Blockly.Python.valueToCode(a, "DATAFRAME_OUT", Blockly.Python.ORDER_UNARY_SIGN)
        if (DATAFRAME_IN != "" || DATAFRAME_OUT != "" || columns != "") {
            return DATAFRAME_OUT + "[" + columns + "]=" + DATAFRAME_IN + "\n";
        }
        else {
            return ""
        }
    }




    Blockly.Python['dataframe_Filter'] = function (a) {
        var b = { EQ: "==", NEQ: "!=", LT: "<", LTE: "<=", GT: ">", GTE: ">=" }[a.getFieldValue("OP")];
        var c = Blockly.Python.ORDER_RELATIONAL;
        var d = Blockly.Python.valueToCode(a, "A", c) || "";
        var e = Blockly.Python.valueToCode(a, "C", c) || "";
        a = Blockly.Python.valueToCode(a, "B", c) || "";
        if (d == "" || e == "" || a == "") {
            return ["", Blockly.Python.ORDER_NONE]
        }

        return [e + "[" + d + " " + b + " " + a + "]", Blockly.Python.ORDER_FUNCTION_CALL];
    };


    Blockly.Python['dataframe_Map'] = function (a) {
        var c = Blockly.Python.ORDER_NONE;
        var b = Blockly.Python.valueToCode(a, "Map", c) || "";
        var d = Blockly.Python.valueToCode(a, "Series", c) || "";
        if (b == "" || d == "") {
            return ["", Blockly.Python.ORDER_NONE]
        }

        return [d + " = " + d + ".map(" + b + ")", Blockly.Python.ORDER_ATOMIC];
    };

    Blockly.Python['dataframe_change_column_type'] = function (a) {
        var c = Blockly.Python.ORDER_NONE;
        var column = Blockly.Python.valueToCode(a, "COLUMN", c) || "";
        var df = Blockly.Python.valueToCode(a, "DATAFRAME", c) || "";
        var type = Blockly.Python.valueToCode(a, "VALUE", c) || "";
        var codeString = "def change_column_type(df, label, x):\n" +
        "    if x == 'object' or x == 'str' or x == 'mixed':\n" +
        "        df[label] = df[label].apply(str)\n" +
        "    elif 'int' in x:\n" +
        "        df[label] = df[label].apply(int)\n" +
        "    elif 'float' in x:\n" +
        "        df[label] = df[label].apply(float)\n" +
        "    elif 'datetime' in x:\n" +
        "        df[label] = pd.to_datetime(df[label], format='%Y%m%d')\n" +
        "    else:\n" +
        "        raise Exception(\"Invalid type entered.\")\n" +
        "df = " + df + "\n" +
        "column = " + column + "\n" +
        "to_change = " + type + "\n" +
        "if type(column) == list:\n" +
        "    for label in column:\n" +
        "        change_column_type(df, label, to_change)\n" +
        "else:\n" +
        "    change_column_type(df, column, to_change)"
        if (column == "" || df == "" || type == "") {
            return ["", Blockly.Python.ORDER_NONE]
        }
        return [codeString, Blockly.Python.ORDER_ATOMIC];
    };

    Blockly.Python['dataframe_Binarization'] = function (a) {
        var c = Blockly.Python.ORDER_NONE;
        var column = Blockly.Python.valueToCode(a, "COLUMN", c) || "";
        var df = Blockly.Python.valueToCode(a, "DATAFRAME", c) || "";
        var condition = { EQ: "==", NEQ: "!=", LT: "<", LTE: "<=", GT: ">", GTE: ">=" }[a.getFieldValue("OP")];
        var threshold = Blockly.Python.valueToCode(a, "VALUE", c) || "";
        var value1 = Blockly.Python.valueToCode(a, "VALUE1", c) || "";
        var value2 = Blockly.Python.valueToCode(a, "VALUE2", c) || "";
        var new_column = Blockly.Python.valueToCode(a, "VALUE3", c) || "";
        var codeString = "df = " + df + "\n" +
            "threshold = " + threshold + "\n" +
            "condition = '" + condition + "'\n" +
            df + "[" + new_column + "] = \"\"" +
            "# Modify the column values based on the user supplied threshold and conditional expression\n" +
            "mask = None\n" +
            "if condition == \"<=\":\n" +
            "    mask = df[" + column + "] <= threshold\n" +
            "elif condition == \">=\":\n" +
            "    mask = df[" + column + "] >= threshold\n" +
            "elif condition == \"<\":\n" +
            "    mask = df[" + column + "] < threshold\n" +
            "elif condition == \">\":\n" +
            "    mask = df[" + column + "] > threshold\n" +
            "else:\n" +
            "    raise Exception(\"Invalid conditional expression!\")\n" +
            "if mask is not None:\n" +
            "    df.loc[mask, " + new_column + "] = " + value1 + "\n" +
            "    df.loc[~mask, " + new_column + "] = " + value2
        if (column == "" || df == "" || condition == "" || threshold == "") {
            return ["", Blockly.Python.ORDER_NONE]
        }
        return [codeString, Blockly.Python.ORDER_ATOMIC];
    };

    Blockly.Python.math = {};
    Blockly.Python.addReservedWords("math,random,Number");
    Blockly.Python.math_number = function (a) {
        a = Number(a.getFieldValue("NUM"));

        if (Infinity == a) {
            a = 'float("inf")';
            var b = Blockly.Python.ORDER_FUNCTION_CALL;
        } else -Infinity == a ? ((a = '-float("inf")'), (b = Blockly.Python.ORDER_UNARY_SIGN)) : (b = 0 > a ? Blockly.Python.ORDER_UNARY_SIGN : Blockly.Python.ORDER_ATOMIC);
        return [a, b];
    };
    Blockly.Python.math_arithmetic = function (a) {
        var b = {
            ADD: [" + ", Blockly.Python.ORDER_ADDITIVE],
            MINUS: [" - ", Blockly.Python.ORDER_ADDITIVE],
            MULTIPLY: [" * ", Blockly.Python.ORDER_MULTIPLICATIVE],
            DIVIDE: [" / ", Blockly.Python.ORDER_MULTIPLICATIVE],
            POWER: [" ** ", Blockly.Python.ORDER_EXPONENTIATION],
        }[a.getFieldValue("OP")],
            c = b[0];
        b = b[1];
        var d = Blockly.Python.valueToCode(a, "A", b) || "0";
        a = Blockly.Python.valueToCode(a, "B", b) || "0";
        return [d + c + a, b];
    };
    Blockly.Python.math_single = function (a) {
        var b = a.getFieldValue("OP");
        if ("NEG" == b) {
            var c = Blockly.Python.valueToCode(a, "NUM", Blockly.Python.ORDER_UNARY_SIGN) || "0";
            return ["-" + c, Blockly.Python.ORDER_UNARY_SIGN];
        }
        Blockly.Python.definitions_.import_math = "import math";
        a = "SIN" == b || "COS" == b || "TAN" == b ? Blockly.Python.valueToCode(a, "NUM", Blockly.Python.ORDER_MULTIPLICATIVE) || "0" : Blockly.Python.valueToCode(a, "NUM", Blockly.Python.ORDER_NONE) || "0";
        switch (b) {
            case "ABS":
                c = "math.fabs(" + a + ")";
                break;
            case "ROOT":
                c = "math.sqrt(" + a + ")";
                break;
            case "LN":
                c = "math.log(" + a + ")";
                break;
            case "LOG10":
                c = "math.log10(" + a + ")";
                break;
            case "EXP":
                c = "math.exp(" + a + ")";
                break;
            case "POW10":
                c = "math.pow(10," + a + ")";
                break;
            case "ROUND":
                c = "round(" + a + ")";
                break;
            case "ROUNDUP":
                c = "math.ceil(" + a + ")";
                break;
            case "ROUNDDOWN":
                c = "math.floor(" + a + ")";
                break;
            case "SIN":
                c = "math.sin(" + a + " / 180.0 * math.pi)";
                break;
            case "COS":
                c = "math.cos(" + a + " / 180.0 * math.pi)";
                break;
            case "TAN":
                c = "math.tan(" + a + " / 180.0 * math.pi)";
        }
        if (c) return [c, Blockly.Python.ORDER_FUNCTION_CALL];
        switch (b) {
            case "ASIN":
                c = "math.asin(" + a + ") / math.pi * 180";
                break;
            case "ACOS":
                c = "math.acos(" + a + ") / math.pi * 180";
                break;
            case "ATAN":
                c = "math.atan(" + a + ") / math.pi * 180";
                break;
            default:
                throw Error("Unknown math operator: " + b);
        }
        return [c, Blockly.Python.ORDER_MULTIPLICATIVE];
    };
    Blockly.Python.math_constant = function (a) {
        var b = {
            PI: ["math.pi", Blockly.Python.ORDER_MEMBER],
            E: ["math.e", Blockly.Python.ORDER_MEMBER],
            GOLDEN_RATIO: ["(1 + math.sqrt(5)) / 2", Blockly.Python.ORDER_MULTIPLICATIVE],
            SQRT2: ["math.sqrt(2)", Blockly.Python.ORDER_MEMBER],
            SQRT1_2: ["math.sqrt(1.0 / 2)", Blockly.Python.ORDER_MEMBER],
            INFINITY: ["float('inf')", Blockly.Python.ORDER_ATOMIC],
        };
        a = a.getFieldValue("CONSTANT");
        "INFINITY" != a && (Blockly.Python.definitions_.import_math = "import math");
        return b[a];
    };
    Blockly.Python.math_number_property = function (a) {
        var b = Blockly.Python.valueToCode(a, "NUMBER_TO_CHECK", Blockly.Python.ORDER_MULTIPLICATIVE) || "0",
            c = a.getFieldValue("PROPERTY");
        if ("PRIME" == c)
            return (
                (Blockly.Python.definitions_.import_math = "import math"),
                (Blockly.Python.definitions_.from_numbers_import_Number = "from numbers import Number"),
                [
                    Blockly.Python.provideFunction_("math_isPrime", [
                        "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(n):",
                        "  # https://en.wikipedia.org/wiki/Primality_test#Naive_methods",
                        "  # If n is not a number but a string, try parsing it.",
                        "  if not isinstance(n, Number):",
                        "    try:",
                        "      n = float(n)",
                        "    except:",
                        "      return False",
                        "  if n == 2 or n == 3:",
                        "    return True",
                        "  # False if n is negative, is 1, or not whole, or if n is divisible by 2 or 3.",
                        "  if n <= 1 or n % 1 != 0 or n % 2 == 0 or n % 3 == 0:",
                        "    return False",
                        "  # Check all the numbers of form 6k +/- 1, up to sqrt(n).",
                        "  for x in range(6, int(math.sqrt(n)) + 2, 6):",
                        "    if n % (x - 1) == 0 or n % (x + 1) == 0:",
                        "      return False",
                        "  return True",
                    ]) +
                    "(" +
                    b +
                    ")",
                    Blockly.Python.ORDER_FUNCTION_CALL,
                ]
            );
        switch (c) {
            case "EVEN":
                var d = b + " % 2 == 0";
                break;
            case "ODD":
                d = b + " % 2 == 1";
                break;
            case "WHOLE":
                d = b + " % 1 == 0";
                break;
            case "POSITIVE":
                d = b + " > 0";
                break;
            case "NEGATIVE":
                d = b + " < 0";
                break;
            case "DIVISIBLE_BY":
                a = Blockly.Python.valueToCode(a, "DIVISOR", Blockly.Python.ORDER_MULTIPLICATIVE);
                if (!a || "0" == a) return ["False", Blockly.Python.ORDER_ATOMIC];
                d = b + " % " + a + " == 0";
        }
        return [d, Blockly.Python.ORDER_RELATIONAL];
    };
    Blockly.Python.math_change = function (a) {
        Blockly.Python.definitions_.from_numbers_import_Number = "from numbers import Number";
        var b = Blockly.Python.valueToCode(a, "DELTA", Blockly.Python.ORDER_ADDITIVE) || "0";
        a = Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME);
        return a + " = (" + a + " if isinstance(" + a + ", Number) else 0) + " + b + "\n";
    };
    Blockly.Python.math_round = Blockly.Python.math_single;
    Blockly.Python.math_trig = Blockly.Python.math_single;
    Blockly.Python.math_on_list = function (a) {
        var b = a.getFieldValue("OP");
        a = Blockly.Python.valueToCode(a, "LIST", Blockly.Python.ORDER_NONE) || "[]";
        switch (b) {
            case "SUM":
                b = "sum(" + a + ")";
                break;
            case "MIN":
                b = "min(" + a + ")";
                break;
            case "MAX":
                b = "max(" + a + ")";
                break;
            case "AVERAGE":
                Blockly.Python.definitions_.from_numbers_import_Number = "from numbers import Number";
                b = Blockly.Python.provideFunction_("math_mean", [
                    "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(myList):",
                    "  localList = [e for e in myList if isinstance(e, Number)]",
                    "  if not localList: return",
                    "  return float(sum(localList)) / len(localList)",
                ]);
                b = b + "(" + a + ")";
                break;
            case "MEDIAN":
                Blockly.Python.definitions_.from_numbers_import_Number = "from numbers import Number";
                b = Blockly.Python.provideFunction_("math_median", [
                    "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(myList):",
                    "  localList = sorted([e for e in myList if isinstance(e, Number)])",
                    "  if not localList: return",
                    "  if len(localList) % 2 == 0:",
                    "    return (localList[len(localList) // 2 - 1] + localList[len(localList) // 2]) / 2.0",
                    "  else:",
                    "    return localList[(len(localList) - 1) // 2]",
                ]);
                b = b + "(" + a + ")";
                break;
            case "MODE":
                b = Blockly.Python.provideFunction_("math_modes", [
                    "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(some_list):",
                    "  modes = []",
                    "  # Using a lists of [item, count] to keep count rather than dict",
                    '  # to avoid "unhashable" errors when the counted item is itself a list or dict.',
                    "  counts = []",
                    "  maxCount = 1",
                    "  for item in some_list:",
                    "    found = False",
                    "    for count in counts:",
                    "      if count[0] == item:",
                    "        count[1] += 1",
                    "        maxCount = max(maxCount, count[1])",
                    "        found = True",
                    "    if not found:",
                    "      counts.append([item, 1])",
                    "  for counted_item, item_count in counts:",
                    "    if item_count == maxCount:",
                    "      modes.append(counted_item)",
                    "  return modes",
                ]);
                b = b + "(" + a + ")";
                break;
            case "STD_DEV":
                Blockly.Python.definitions_.import_math = "import math";
                b = Blockly.Python.provideFunction_("math_standard_deviation", [
                    "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(numbers):",
                    "  n = len(numbers)",
                    "  if n == 0: return",
                    "  mean = float(sum(numbers)) / n",
                    "  variance = sum((x - mean) ** 2 for x in numbers) / n",
                    "  return math.sqrt(variance)",
                ]);
                b = b + "(" + a + ")";
                break;
            case "RANDOM":
                Blockly.Python.definitions_.import_random = "import random";
                b = "random.choice(" + a + ")";
                break;
            default:
                throw Error("Unknown operator: " + b);
        }
        return [b, Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.math_modulo = function (a) {
        var b = Blockly.Python.valueToCode(a, "DIVIDEND", Blockly.Python.ORDER_MULTIPLICATIVE) || "0";
        a = Blockly.Python.valueToCode(a, "DIVISOR", Blockly.Python.ORDER_MULTIPLICATIVE) || "0";
        return [b + " % " + a, Blockly.Python.ORDER_MULTIPLICATIVE];
    };
    Blockly.Python.math_constrain = function (a) {
        var b = Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "0",
            c = Blockly.Python.valueToCode(a, "LOW", Blockly.Python.ORDER_NONE) || "0";
        a = Blockly.Python.valueToCode(a, "HIGH", Blockly.Python.ORDER_NONE) || "float('inf')";
        return ["min(max(" + b + ", " + c + "), " + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.math_random_int = function (a) {
        Blockly.Python.definitions_.import_random = "import random";
        var b = Blockly.Python.valueToCode(a, "FROM", Blockly.Python.ORDER_NONE) || "0";
        a = Blockly.Python.valueToCode(a, "TO", Blockly.Python.ORDER_NONE) || "0";
        return ["random.randint(" + b + ", " + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.math_random_float = function (a) {
        Blockly.Python.definitions_.import_random = "import random";
        return ["random.random()", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.math_atan2 = function (a) {
        Blockly.Python.definitions_.import_math = "import math";
        var b = Blockly.Python.valueToCode(a, "X", Blockly.Python.ORDER_NONE) || "0";
        return ["math.atan2(" + (Blockly.Python.valueToCode(a, "Y", Blockly.Python.ORDER_NONE) || "0") + ", " + b + ") / math.pi * 180", Blockly.Python.ORDER_MULTIPLICATIVE];
    };
    Blockly.Python.procedures = {};
    Blockly.Python.procedures_defreturn = function (a) {
        for (var b = [], c, d = a.workspace, e = Blockly.Variables.allUsedVarModels(d) || [], f = 0; (c = e[f]); f++)
            (c = c.name), -1 == a.getVars().indexOf(c) && b.push(Blockly.Python.variableDB_.getName(c, Blockly.VARIABLE_CATEGORY_NAME));
        e = Blockly.Variables.allDeveloperVariables(d);
        for (f = 0; f < e.length; f++) b.push(Blockly.Python.variableDB_.getName(e[f], Blockly.Names.DEVELOPER_VARIABLE_TYPE));
        b = b.length ? Blockly.Python.INDENT + "global " + b.join(", ") + "\n" : "";
        d = Blockly.Python.variableDB_.getName(a.getFieldValue("NAME"), Blockly.PROCEDURE_CATEGORY_NAME);
        c = "";
        Blockly.Python.STATEMENT_PREFIX && (c += Blockly.Python.injectId(Blockly.Python.STATEMENT_PREFIX, a));
        Blockly.Python.STATEMENT_SUFFIX && (c += Blockly.Python.injectId(Blockly.Python.STATEMENT_SUFFIX, a));
        c && (c = Blockly.Python.prefixLines(c, Blockly.Python.INDENT));
        var n = "";
        Blockly.Python.INFINITE_LOOP_TRAP && (n = Blockly.Python.prefixLines(Blockly.Python.injectId(Blockly.Python.INFINITE_LOOP_TRAP, a), Blockly.Python.INDENT));
        var k = Blockly.Python.statementToCode(a, "STACK"),
            h = Blockly.Python.valueToCode(a, "RETURN", Blockly.Python.ORDER_NONE) || "",
            m = "";
        k && h && (m = c);
        h ? (h = Blockly.Python.INDENT + "return " + h + "\n") : k || (k = Blockly.Python.PASS);
        var g = [];
        e = a.getVars();
        for (f = 0; f < e.length; f++) g[f] = Blockly.Python.variableDB_.getName(e[f], Blockly.VARIABLE_CATEGORY_NAME);
        b = "def " + d + "(" + g.join(", ") + "):\n" + b + c + n + k + m + h;
        b = Blockly.Python.scrub_(a, b);
        Blockly.Python.definitions_["%" + d] = b;
        return null;
    };
    Blockly.Python.procedures_defnoreturn = Blockly.Python.procedures_defreturn;
    Blockly.Python.procedures_callreturn = function (a) {
        for (var b = Blockly.Python.variableDB_.getName(a.getFieldValue("NAME"), Blockly.PROCEDURE_CATEGORY_NAME), c = [], d = a.getVars(), e = 0; e < d.length; e++)
            c[e] = Blockly.Python.valueToCode(a, "ARG" + e, Blockly.Python.ORDER_NONE) || "None";
        return [b + "(" + c.join(", ") + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.procedures_callnoreturn = function (a) {
        return Blockly.Python.procedures_callreturn(a)[0] + "\n";
    };
    Blockly.Python.procedures_ifreturn = function (a) {
        var b = "if " + (Blockly.Python.valueToCode(a, "CONDITION", Blockly.Python.ORDER_NONE) || "False") + ":\n";
        Blockly.Python.STATEMENT_SUFFIX && (b += Blockly.Python.prefixLines(Blockly.Python.injectId(Blockly.Python.STATEMENT_SUFFIX, a), Blockly.Python.INDENT));
        a.hasReturnValue_ ? ((a = Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "None"), (b += Blockly.Python.INDENT + "return " + a + "\n")) : (b += Blockly.Python.INDENT + "return\n");
        return b;
    };
    Blockly.Python.texts = {};
    Blockly.Python.text = function (a) {
        return [Blockly.Python.quote_(a.getFieldValue("TEXT")), Blockly.Python.ORDER_ATOMIC];
    };
    Blockly.Python.text_multiline = function (a) {
        a = Blockly.Python.multiline_quote_(a.getFieldValue("TEXT"));
        var b = -1 != a.indexOf("+") ? Blockly.Python.ORDER_ADDITIVE : Blockly.Python.ORDER_ATOMIC;
        return [a, b];
    };
    Blockly.Python.text.forceString_ = function (a) {
        return Blockly.Python.text.forceString_.strRegExp.test(a) ? [a, Blockly.Python.ORDER_ATOMIC] : ["str(" + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.text.forceString_.strRegExp = /^\s*'([^']|\\')*'\s*$/;
    Blockly.Python.text_join = function (a) {
        switch (a.itemCount_) {
            case 0:
                return ["''", Blockly.Python.ORDER_ATOMIC];
            case 1:
                return (a = Blockly.Python.valueToCode(a, "ADD0", Blockly.Python.ORDER_NONE) || "''"), Blockly.Python.text.forceString_(a);
            case 2:
                var b = Blockly.Python.valueToCode(a, "ADD0", Blockly.Python.ORDER_NONE) || "''";
                a = Blockly.Python.valueToCode(a, "ADD1", Blockly.Python.ORDER_NONE) || "''";
                a = Blockly.Python.text.forceString_(b)[0] + " + " + Blockly.Python.text.forceString_(a)[0];
                return [a, Blockly.Python.ORDER_ADDITIVE];
            default:
                b = [];
                for (var c = 0; c < a.itemCount_; c++) b[c] = Blockly.Python.valueToCode(a, "ADD" + c, Blockly.Python.ORDER_NONE) || "''";
                a = Blockly.Python.variableDB_.getDistinctName("x", Blockly.VARIABLE_CATEGORY_NAME);
                a = "''.join([str(" + a + ") for " + a + " in [" + b.join(", ") + "]])";
                return [a, Blockly.Python.ORDER_FUNCTION_CALL];
        }
    };
    Blockly.Python.text_append = function (a) {
        var b = Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME);
        a = Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_NONE) || "''";
        return b + " = str(" + b + ") + " + Blockly.Python.text.forceString_(a)[0] + "\n";
    };
    Blockly.Python.text_length = function (a) {
        return ["len(" + (Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "''") + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.text_isEmpty = function (a) {
        return ["not len(" + (Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "''") + ")", Blockly.Python.ORDER_LOGICAL_NOT];
    };
    Blockly.Python.text_isEmpty2 = function (a) {
        return ["not len(" + (Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "''") + ")x", Blockly.Python.ORDER_LOGICAL_NOT];
    };
    Blockly.Python.text_indexOf = function (a) {
        var b = "FIRST" == a.getFieldValue("END") ? "find" : "rfind",
            c = Blockly.Python.valueToCode(a, "FIND", Blockly.Python.ORDER_NONE) || "''";
        b = (Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_MEMBER) || "''") + "." + b + "(" + c + ")";
        return a.workspace.options.oneBasedIndex ? [b + " + 1", Blockly.Python.ORDER_ADDITIVE] : [b, Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.text_charAt = function (a) {
        var b = a.getFieldValue("WHERE") || "FROM_START",
            c = Blockly.Python.valueToCode(a, "VALUE", "RANDOM" == b ? Blockly.Python.ORDER_NONE : Blockly.Python.ORDER_MEMBER) || "''";
        switch (b) {
            case "FIRST":
                return [c + "[0]", Blockly.Python.ORDER_MEMBER];
            case "LAST":
                return [c + "[-1]", Blockly.Python.ORDER_MEMBER];
            case "FROM_START":
                return (a = Blockly.Python.getAdjustedInt(a, "AT")), [c + "[" + a + "]", Blockly.Python.ORDER_MEMBER];
            case "FROM_END":
                return (a = Blockly.Python.getAdjustedInt(a, "AT", 1, !0)), [c + "[" + a + "]", Blockly.Python.ORDER_MEMBER];
            case "RANDOM":
                return (
                    (Blockly.Python.definitions_.import_random = "import random"),
                    [
                        Blockly.Python.provideFunction_("text_random_letter", ["def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(text):", "  x = int(random.random() * len(text))", "  return text[x];"]) + "(" + c + ")",
                        Blockly.Python.ORDER_FUNCTION_CALL,
                    ]
                );
        }
        throw Error("Unhandled option (text_charAt).");
    };
    Blockly.Python.text_getSubstring = function (a) {
        var b = a.getFieldValue("WHERE1"),
            c = a.getFieldValue("WHERE2"),
            d = Blockly.Python.valueToCode(a, "STRING", Blockly.Python.ORDER_MEMBER) || "''";
        switch (b) {
            case "FROM_START":
                b = Blockly.Python.getAdjustedInt(a, "AT1");
                "0" == b && (b = "");
                break;
            case "FROM_END":
                b = Blockly.Python.getAdjustedInt(a, "AT1", 1, !0);
                break;
            case "FIRST":
                b = "";
                break;
            default:
                throw Error("Unhandled option (text_getSubstring)");
        }
        switch (c) {
            case "FROM_START":
                a = Blockly.Python.getAdjustedInt(a, "AT2", 1);
                break;
            case "FROM_END":
                a = Blockly.Python.getAdjustedInt(a, "AT2", 0, !0);
                Blockly.isNumber(String(a)) ? "0" == a && (a = "") : ((Blockly.Python.definitions_.import_sys = "import sys"), (a += " or sys.maxsize"));
                break;
            case "LAST":
                a = "";
                break;
            default:
                throw Error("Unhandled option (text_getSubstring)");
        }
        return [d + "[" + b + " : " + a + "]", Blockly.Python.ORDER_MEMBER];
    };
    Blockly.Python.text_changeCase = function (a) {
        var b = { UPPERCASE: ".upper()", LOWERCASE: ".lower()", TITLECASE: ".title()" }[a.getFieldValue("CASE")];
        return [(Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_MEMBER) || "''") + b, Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.text_trim = function (a) {
        var b = { LEFT: ".lstrip()", RIGHT: ".rstrip()", BOTH: ".strip()" }[a.getFieldValue("MODE")];
        return [(Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_MEMBER) || "''") + b, Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.text_print = function (a) {
        return "print(" + (Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_NONE) || "''") + ")\n";
    };
    Blockly.Python.text_prompt_ext = function (a) {
        var b = Blockly.Python.provideFunction_("text_prompt", ["def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(msg):", "  try:", "    return raw_input(msg)", "  except NameError:", "    return input(msg)"]),
            c = a.getField("TEXT") ? Blockly.Python.quote_(a.getFieldValue("TEXT")) : Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_NONE) || "''";
        b = b + "(" + c + ")";
        "NUMBER" == a.getFieldValue("TYPE") && (b = "float(" + b + ")");
        return [b, Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.text_prompt = Blockly.Python.text_prompt_ext;
    Blockly.Python.text_count = function (a) {
        var b = Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_MEMBER) || "''";
        a = Blockly.Python.valueToCode(a, "SUB", Blockly.Python.ORDER_NONE) || "''";
        return [b + ".count(" + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.text_replace = function (a) {
        var b = Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_MEMBER) || "''",
            c = Blockly.Python.valueToCode(a, "FROM", Blockly.Python.ORDER_NONE) || "''";
        a = Blockly.Python.valueToCode(a, "TO", Blockly.Python.ORDER_NONE) || "''";
        return [b + ".replace(" + c + ", " + a + ")", Blockly.Python.ORDER_MEMBER];
    };
    Blockly.Python.text_reverse = function (a) {
        return [(Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_MEMBER) || "''") + "[::-1]", Blockly.Python.ORDER_MEMBER];
    };
    Blockly.Python.variables = {};
    Blockly.Python.variables_get = function (a) {
        return [Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME), Blockly.Python.ORDER_ATOMIC];
    };

    Blockly.Python.variables_set = function (a) {

        var b = Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "0";
        if (a.getInputTargetBlock() != null){

            if (a.getInputTargetBlock("VALUE").outputConnection.getCheck() == "DataFrame") {
                VarData[Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME)] = b;
            }

        }
        return Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME) + " = " + b + "\n";
    };
    Blockly.Python.variablesDynamic = {};
    Blockly.Python.variables_get_dynamic = Blockly.Python.variables_get;
    Blockly.Python.variables_set_dynamic = Blockly.Python.variables_set;

    Blockly.Python.intersectionalBias = function (a) {
        var df = Blockly.Python.valueToCode(a, "DATAFRAME", Blockly.Python.ORDER_NONE);
        Blockly.Python.definitions_.etiq_core = "from etiq_core import *";
        Blockly.Python.definitions_.opendatasets = "import opendatasets as od";
        Blockly.Python.definitions_.pandas = "import pandas as pd";
        Blockly.Python.definitions_.numpy = "import numpy as np";
        Blockly.Python.definitions_.warnings = "import warnings";
        Blockly.Python.definitions_.pprint = "import pprint";
        Blockly.Python.definitions_.deepcopy = "from copy import deepcopy";
        Blockly.Python.definitions_.matplotlib_pyplot = "import matplotlib.pyplot as plt";
        Blockly.Python.definitions_.seaborn = "import seaborn as sns";
        Blockly.Python.definitions_.scipy = "import scipy.stats as st";
        Blockly.Python.definitions_.re = "import re";
        Blockly.Python.definitions_.datetime = "import datetime";
        Blockly.Python.definitions_.import_math = "import math";
        Blockly.Python.definitions_.interactiveShell = "from IPython.core.interactiveshell import InteractiveShell";
        Blockly.Python.definitions_.is_string_dtype = "from pandas.api.types import is_string_dtype";
        Blockly.Python.definitions_.pythonwarnings = "import warnings";
        Blockly.Python.definitions_.pythonlogging = "import logging";
        Blockly.Python.definitions_.markdown = "from IPython.display import Markdown as md";
        var dropnan = 0
        if (a.getFieldValue("SPLIT") == "dropNa") {
            dropnan = 1
        }
        var biased_cols = Blockly.Python.valueToCode(a, "BIASEDCOLS", Blockly.Python.ORDER_NONE);
        var privileged_cols = Blockly.Python.valueToCode(a, "PRIVILEGEDCOLS", Blockly.Python.ORDER_NONE);
        var pos_outcome = Blockly.Python.valueToCode(a, "POSOUTCOME", Blockly.Python.ORDER_NONE);
        var codeString = "# Setting display off warning and info messages\n"+
            "warnings.filterwarnings(\"ignore\")\n"+
            "logger = logging.getLogger(\"etiq_core\")\n"+
            "logger.setLevel(level = logging.CRITICAL)\n"+
            "\n\n"+
            "def get_debias_params(protected, privileged, unprivileged, positive_label, negative_label):\n"+
            "    return BiasParams(protected=protected, privileged=privileged, unprivileged=unprivileged, positive_outcome_label=positive_label, negative_outcome_label=negative_label) \n"+
            "\n\n"+
            "transforms = [Dropna, EncodeLabels]\n"+
            "metrics_bonus = [accuracy,  equal_opportunity,demographic_parity, equal_odds_tpr, equal_odds_tnr, true_neg_rate, true_pos_rate, individual_fairness, individual_fairness_cf]\n"+
            "metrics_initial = [accuracy,  equal_opportunity,demographic_parity, equal_odds_tnr, individual_fairness]\n"+
            "metrics_short = [accuracy, demographic_parity, equal_opportunity, individual_fairness]\n"+
            "metrics_sshort = [accuracy, demographic_parity, equal_opportunity]\n"+
            "metrics_list = ['accuracy','demographic_parity','equal_opportunity', 'individual_fairness']\n"+
            "metrics_list_short = ['accuracy','demographic_parity','equal_opportunity']\n"+
            "\n"+
            "# Wrapper to avoid having to call the clean classifier, dl and pipe, returns metrics\n"+
            "def etiq_wrapper_run(data, debias_params, cont_val, cat_val, p_feature, metrics):\n"+
            "    xgb = DefaultXGBoostClassifier()\n"+
            "    dl = DatasetLoader(data=data, label=p_feature, transforms=transforms, bias_params=debias_params, train_valid_test_splits=[0.8, 0.1, 0.1], cat_col=cat_vars, cont_col=cont_vars, names_col = data.columns.values);\n"+
            "    pipeline_initial = DataPipeline(dataset_loader=dl, model=xgb, metrics=metrics);\n"+
            "    pipeline_initial.run();\n"+
            "    metrics = pipeline_initial.get_protected_metrics();\n"+
            "    return metrics\n"+
            "\n\n"+
            "# Insert into the given dataset the column obtained by intersecting protected1 and protected2, drop the two original columns if drop is true\n"+
            "def get_intersection(data, protected1, protected2, drop = True):\n"+
            "    column_name = protected1 + \"_\" + protected2\n"+
            "    data[column_name] = data[protected1] + \"_\" + data[protected2]\n"+
            "    if(drop): data = data.drop([protected1, protected2],axis=1)\n"+
            "    return data\n"+
            "\n\n"+
            "# Create a dataframe from metrics_result of two rows (privileged and unprivileged), the columns are the metrics in debias_params (set globally)\n"+
            "def get_df_from_metrics(metrics_result):\n"+
            "    m = deepcopy(metrics_result)\n"+
            "    item = m.popitem()\n"+
            "    if(item[1] is not None):\n"+
            "        l = item[1]\n"+
            "        d = {'privilege':['privileged', 'unprivileged']}\n"+
            "        d['class'] = [debias_params.privileged, debias_params.unprivileged]\n"+
            "        for x in l:\n"+
            "            ppitem = x.popitem()\n"+
            "            d[ppitem[0]] = [ppitem[1][1], ppitem[1][3]]\n"+
            "        df = pd.DataFrame(data = d)\n"+
            "        return df\n"+
            "    else:\n"+
            "        return None\n"+
            "\n\n"+
            "# Create a dataframe from metrics_result with one row for metrics in metrics_in, columns are the parameters in biasParams_in and one column\n"+
            "# for the calculated disparity as a ratio\n"+
            "def get_disparity_df(metrics_result, biasParams_in, metrics_in):\n"+
            "    m = deepcopy(metrics_result)\n"+
            "    item = m.popitem()\n"+
            "    if(item[1] is not None):\n"+
            "        l = item[1]\n"+
            "        d = {'metric': ['group'], 'privileged': [biasParams_in.privileged], 'unprivileged': [biasParams_in.unprivileged], 'disparity': ['']}\n"+
            "        for x in l:\n"+
            "            ppitem = x.popitem()\n"+
            "            if(ppitem[0] in metrics_in):\n"+
            "                d['metric'].append(ppitem[0])\n"+
            "                d['privileged'].append(ppitem[1][1])\n"+
            "                d['unprivileged'].append(ppitem[1][3])\n"+
            "                d['disparity'].append(ppitem[1][3] / ppitem[1][1])\n"+
            "        df = pd.DataFrame(data = d)\n"+
            "        df = df.set_index('metric')\n"+
            "        return df\n"+
            "    else:\n"+
            "        return None\n"+
            "\n\n"+
            "# Intersects feature1 and feature2 in dataset data. Calculate the EDF on the p_feature of the entries in the subgroups obtained by joining\n"+
            "# attributes1 and attributes2. If in_place modifies d (intersects the columns but does NOT delete the originals)\n"+
            "# I intersect f1 and f2, I choose which subgroups of the features I want to examine (e.g. I intersect Sex and Race, I choose 'White, Black' and\n"+
            "# 'Male, Female' to search for elements in \"White_Male\", \"White_Female\", \"Black_Male\" and \" Black_Female\")\n"+
            "def get_edf_df(data, feature1, feature2, attributes1, attributes2, p_feature, in_place = True):\n"+
            "    d = data\n"+
            "    if not in_place: d = data.deepcopy(data)\n"+
            "    subg = feature1+'_'+feature2\n"+
            "    intersections = []\n"+
            "    for a1 in attributes1:\n"+
            "        for a2 in attributes2:\n"+
            "            if a1 != a2: intersections.append(a1+'_'+a2)\n"+
            "    d = get_intersection(d, feature1, feature2, drop = False)\n"+
            "    result = {'group1': [], 'group2': []}\n"+
            "    for g in intersections:\n"+
            "        for other in intersections:\n"+
            "            if g != other:\n"+
            "                result['group1'].append(g)\n"+
            "                result['group2'].append(other)\n"+
            "                #for s in subgs:\n"+
            "                if 'disparity' not in result: result['disparity'] = []\n"+
            "                if g in d[subg].unique() and other in d[subg].unique():\n"+
            "                    p = d.groupby(subg).sum()\n"+
            "                    Nys_i = p.at[g, p_feature]\n"+
            "                    Ns_i = len(d[d[subg] == g])\n"+
            "                    Nys_j = p.at[other, p_feature]\n"+
            "                    Ns_j = len(d[d[subg] == other])\n"+
            "                    result['disparity'].append((Nys_i / Ns_i) * (Ns_j / Nys_j))\n"+
            "                else: result['disparity'].append('')\n"+
            "    df = pd.DataFrame(data = result)\n"+
            "    if not in_place: del d\n"+
            "    return df\n"+
            "\n\n"+
            "# Extracts the n pairs with greatest difference of EDF from edf obtained from get_edf_df\n"+
            "def read_edf(edf, n = 1):\n"+
            "    groups = []\n"+
            "    wedf = edf\n"+
            "    if n > 1:\n"+
            "        wedf = edf.copy()\n"+
            "    for i in range(n):\n"+
            "        idx = wedf['disparity'].idxmax()\n"+
            "    val = wedf['disparity'].max()\n"+
            "    groups.append((wedf.at[idx, 'group1'], wedf.at[idx, 'group2'], val))\n"+
            "    if n > 1:\n"+
            "        wedf.drop([idx], axis = 0, inplace = True)\n"+
            "    return groups\n"+
            "\n\n"+
            "# Create a dataframe from dataset data with modal values and their occurrences of features in features for positive_outcome outcomes\n"+
            "# and negative_outcome outcomes of the p_feature\n"+
            "def get_mode_df(data, features, p_feature, positive_outcome, negative_outcome):\n"+
            "    d = {'feature': [],\n"+
            "        'mode_pos': [], 'mode_occ_pos': [], 'total_mode_occ_pos': [],\n"+
            "        'mode_neg': [], 'mode_occ_neg': [], 'total_mode_occ_neg': []}\n"+
            "    for ft in features:\n"+
            "        pos = data[data[p_feature] == positive_outcome].groupby(ft).size()\n"+
            "        neg = data[data[p_feature] == negative_outcome].groupby(ft).size()\n"+
            "        d['feature'].append(ft)\n"+
            "        d['mode_pos'].append(pos.idxmax())\n"+
            "        d['mode_occ_pos'].append(pos.max())\n"+
            "        d['total_mode_occ_pos'].append(len(data[data[ft] == pos.idxmax()]))\n"+
            "        d['mode_neg'].append(neg.idxmax())\n"+
            "        d['mode_occ_neg'].append(neg.max())\n"+
            "        d['total_mode_occ_neg'].append(len(data[data[ft] == neg.idxmax()]))\n"+
            "    df = pd.DataFrame(data = d)\n"+
            "    df = df.set_index('feature')\n"+
            "    return df\n"+
            "\n\n"+
            "# Like get_mode_df, but instead of the modal value, the value with the greatest ratio between occurrences and total cardinality\n"+
            "def get_ratio_df(data, features, p_feature, positive_outcome, negative_outcome):\n"+
            "    d = {'feature': [], 'max_ratio_pos': [], 'max_ratio_occ_pos': [], 'max_ratio_tot_occ_pos': [], 'max_ratio_neg': [], 'max_ratio_occ_neg':[], 'max_ratio_tot_occ_neg':[]}\n"+
            "    for ft in features:\n"+
            "        pos = data[data[p_feature] == positive_outcome].groupby(ft).size()\n"+
            "        neg = data[data[p_feature] == negative_outcome].groupby(ft).size()\n"+
            "        d['feature'].append(ft)\n"+
            "        ratios = {}\n"+
            "        for i, v in enumerate(pos):\n"+
            "            n = len(data[data[ft] == pos.index[i]])\n"+
            "            ratios[pos.index[i]] = v / n\n"+
            "        pos_ratios = sorted(ratios.items(), key = lambda x : x[1], reverse = True)\n"+
            "        cat, val = pos_ratios[0]\n"+
            "        max_i = (cat, round(val, 2))\n"+
            "        d['max_ratio_pos'].append(max_i)\n"+
            "        d['max_ratio_occ_pos'].append(pos[max_i[0]])\n"+
            "        d['max_ratio_tot_occ_pos'].append(len(data[data[ft] == max_i[0]]))\n"+
            "        ratios = {}\n"+
            "        for i, v in enumerate(neg):\n"+
            "            n = len(data[data[ft] == neg.index[i]])\n"+
            "            ratios[neg.index[i]] = v / n\n"+
            "        neg_ratios = sorted(ratios.items(), key = lambda x : x[1], reverse = True)\n"+
            "        cat, val = neg_ratios[0]\n"+
            "        max_i = (cat, round(val, 2))\n"+
            "        d['max_ratio_neg'].append(max_i)\n"+
            "        d['max_ratio_occ_neg'].append(neg[max_i[0]])\n"+
            "        d['max_ratio_tot_occ_neg'].append(len(data[data[ft] == max_i[0]]))\n"+
            "    df = pd.DataFrame(data = d)\n"+
            "    df = df.set_index('feature')\n"+
            "    return df\n"+
            "\n\n"+
            "# Merge of the two functions above\n"+
            "def get_mode_ratio_df(data, features, p_feature, positive_outcome, negative_outcome):\n"+
            "    d = {'feature': [], 'mode_pos': [], 'mode_occ_pos': [], 'total_mode_occ_pos': [], 'max_ratio_pos': [], 'max_ratio_occ_pos': [], 'max_ratio_tot_occ_pos': [], 'mode_neg': [], 'mode_occ_neg': [], 'total_mode_occ_neg': [], 'max_ratio_neg': [], 'max_ratio_occ_neg':[], 'max_ratio_tot_occ_neg':[]}\n"+
            "    for ft in features:\n"+
            "        pos = data[data[p_feature] == positive_outcome].groupby(ft).size()\n"+
            "        neg = data[data[p_feature] == negative_outcome].groupby(ft).size()\n"+
            "        d['feature'].append(ft)\n"+
            "        d['mode_pos'].append(pos.idxmax())\n"+
            "        d['mode_occ_pos'].append(pos.max())\n"+
            "        d['total_mode_occ_pos'].append(len(data[data[ft] == pos.idxmax()]))\n"+
            "        ratios = {}\n"+
            "        for i, v in enumerate(pos):\n"+
            "            n = len(data[data[ft] == pos.index[i]])\n"+
            "            ratios[pos.index[i]] = v / n\n"+
            "        pos_ratios = sorted(ratios.items(), key = lambda x : x[1], reverse = True)\n"+
            "        cat, val = pos_ratios[0]\n"+
            "        max_i = (cat, round(val, 2))\n"+
            "        d['max_ratio_pos'].append(max_i)\n"+
            "        d['max_ratio_occ_pos'].append(pos[max_i[0]])\n"+
            "        d['max_ratio_tot_occ_pos'].append(len(data[data[ft] == max_i[0]]))\n"+
            "        d['mode_neg'].append(neg.idxmax())\n"+
            "        d['mode_occ_neg'].append(neg.max())\n"+
            "        d['total_mode_occ_neg'].append(len(data[data[ft] == neg.idxmax()]))\n"+
            "        ratios = {}\n"+
            "        for i, v in enumerate(neg):\n"+
            "            n = len(data[data[ft] == neg.index[i]])\n"+
            "            ratios[neg.index[i]] = v / n\n"+
            "        neg_ratios = sorted(ratios.items(), key = lambda x : x[1], reverse = True)\n"+
            "        cat, val = neg_ratios[0]\n"+
            "        max_i = (cat, round(val, 2))\n"+
            "        d['max_ratio_neg'].append(max_i)\n"+
            "        d['max_ratio_occ_neg'].append(neg[max_i[0]])\n"+
            "        d['max_ratio_tot_occ_neg'].append(len(data[data[ft] == max_i[0]]))\n"+
            "    df = pd.DataFrame(data = d)\n"+
            "    df = df.set_index('feature')\n"+
            "    return df\n"+
            "\n\n"+
            "# Returns a pair of dicts, the first for occurrences of positive_outcome of the p_feature and the second for occurrences\n"+
            "# of negative_outcome. Each dict contains, for each feature in features, the number of times a value has been modal for at least\n"+
            "# one of the samples\n"+
            "def get_maxOccurrences_in_samples(samples, features, p_feature, positive_outcome, negative_outcome):\n"+
            "    results_pos = {}\n"+
            "    results_neg = {}\n"+
            "    for i in range(len(samples)):\n"+
            "        df = get_mode_ratio_df(data = samples[i], features = features, p_feature = p_feature, positive_outcome = positive_outcome, negative_outcome = negative_outcome)\n"+
            "        for ind in df.index:\n"+
            "            ft = ind\n"+
            "            if ft not in results_pos: results_pos[ft] = {}\n"+
            "            val = df.at[ind, 'mode_pos']\n"+
            "            if val not in results_pos[ft]: results_pos[ft][val] = 0\n"+
            "            results_pos[ft][val] += 1\n"+
            "            if ft not in results_neg: results_neg[ft] = {}\n"+
            "            val = df.at[ind, 'mode_neg']\n"+
            "            if val not in results_neg[ft]: results_neg[ft][val] = 0\n"+
            "            results_neg[ft][val] += 1\n"+
            "    return (results_pos, results_neg)\n"+
            "\n\n"+
            "# As above but with reports\n"+
            "def get_maxOccurrences_ratio_in_samples(samples, features, p_feature, positive_outcome, negative_outcome):\n"+
            "    results_pos = {}\n"+
            "    results_neg = {}\n"+
            "    for i in range(len(samples)):\n"+
            "        df = get_mode_ratio_df(data = samples[i], features = features, p_feature = p_feature, positive_outcome = positive_outcome, negative_outcome = negative_outcome)\n"+
            "        for ind in df.index:\n"+
            "            ft = ind\n"+
            "            if ft not in results_pos: results_pos[ft] = {}\n"+
            "            val, k = df.at[ind, 'max_ratio_pos']\n"+
            "            if val not in results_pos[ft]: results_pos[ft][val] = 0\n"+
            "            results_pos[ft][val] += 1\n"+
            "            if ft not in results_neg: results_neg[ft] = {}\n"+
            "            val, k = df.at[ind, 'max_ratio_neg']\n"+
            "            if val not in results_neg[ft]: results_neg[ft][val] = 0\n"+
            "            results_neg[ft][val] += 1\n"+
            "    return (results_pos, results_neg)\n"+
            "\n\n"+
            "# Not used(?)\n"+
            "def get_intersections_count(samples, features1, features2, attributes1, attributes2):\n"+
            "    results = {}\n"+
            "    subgs = []\n"+
            "    for f1 in features1:\n"+
            "        for f2 in features2:\n"+
            "            if f1 != f2: subgs.append(f1+'_'+f2)\n"+
            "    intersections = []\n"+
            "    for a1 in attributes1:\n"+
            "        for a2 in attributes2:\n"+
            "            if a1 != a2: intersections.append(a1+'_'+a2)\n"+
            "    for sample in samples:\n"+
            "        for f1 in features1:\n"+
            "            for f2 in features2:\n"+
            "                if f1 != f2:\n"+
            "                    sample = get_intersection(sample, f1, f2, drop = False)\n"+
            "    for g in subgs:\n"+
            "        for t in intersections:\n"+
            "            n = len(sample[sample[g] == t])\n"+
            "            if n > 0:\n"+
            "                if g not in results: results[g] = {}\n"+
            "                if t not in results[g]: results[g][t] = 0\n"+
            "                results[g][t] += n\n"+
            "    return results\n"+
            "\n\n"+
            "# Dict with modal feature values for the feature's value (bad name for var, sorry)\n"+
            "# the usage examples in the rest of the notebook are far more helpful than the explanation\n"+
            "def get_values_of(samples, feature, value, features):\n"+
            "    result = {}\n"+
            "    for sample in samples:\n"+
            "        subset = sample[sample[feature] == value]\n"+
            "    for ft in features:\n"+
            "        if ft not in result: result[ft] = None\n"+
            "        count = subset.groupby(ft).size()\n"+
            "        if len(count) > 0: result[ft] = count.idxmax()\n"+
            "    return result\n"+
            "\n\n"+
            "# Same as above, but filter by the outcome of the p_feature\n"+
            "def get_values_of_outcome(samples, feature, value, features, p_feature, outcome):\n"+
            "    result = {}\n"+
            "    for sample in samples:\n"+
            "        subset = sample[(sample[feature] == value) & (sample[p_feature] == outcome)]\n"+
            "        for ft in features:\n"+
            "            if ft not in result: result[ft] = None\n"+
            "            count = subset.groupby(ft).size()\n"+
            "            if len(count) > 0: result[ft] = count.idxmax()\n"+
            "    return result\n"+
            "\n\n"+
            "# Removes the feature most closely related to the p_feature among the features in relevant_features\n"+
            "# Returns a pair with the data changed and the index removed\n"+
            "def remove_max_corr(data, relevant_features, p_feature):\n"+
            "    corr = data.corr(numeric_only = True).abs()\n"+
            "    corr.drop([p_feature], axis = 0, inplace = True)\n"+
            "    for i in corr.index:\n"+
            "        if i not in relevant_features:\n"+
            "            corr.drop([i], axis = 0, inplace = True)\n"+
            "    idx = corr[p_feature].idxmax()\n"+
            "    data = data.drop([idx], axis = 1)\n"+
            "    return (data, idx)\n"+
            "\n\n"+
            "# As above but repeated n times\n"+
            "# Returns a pair with data and indexes removed\n"+
            "def iterative_correlation_removal(n, data, relevant_features, p_feature):\n"+
            "    removed = []\n"+
            "    for i in range(n):\n"+
            "        data, r = remove_max_corr(data, relevant_features, p_feature)\n"+
            "        removed.append(r)\n"+
            "    return data, removed\n"+
            "\n\n"+
            "# Iterates the process of removing a feature related to p_feature n times. If reinsert = false the result is cumulative,\n"+
            "# otherwise I reinsert at each step and calculate the next in order of correlation\n"+
            "# Returns a dict with disparity changes\n"+
            "def disparity_change(data, n, reinsert, relevant_features, p_feature, debias_params, cont_vars, cat_vars, metrics):\n"+
            "    old = {}\n"+
            "    result = {}\n"+
            "    metrics_list = []\n"+
            "    columns = {}\n"+
            "    for m in metrics:\n"+
            "        metrics_list.append(m.__name__)\n"+
            "    metrics_in = get_disparity_df(etiq_wrapper_run(data, debias_params, cont_vars, cat_vars, p_feature, metrics), debias_params, metrics_list)\n"+
            "    for m in metrics_list:\n"+
            "        old[m] = metrics_in.loc[m]['disparity']\n"+
            "    corr = data.corr(numeric_only = True).abs()\n"+
            "    corr.drop([p_feature], axis = 0, inplace = True)\n"+
            "    for i in corr.index:\n"+
            "        if i not in relevant_features:\n"+
            "            corr.drop([i], axis = 0, inplace = True)\n"+
            "    for i in range(n):\n"+
            "        idx = corr[p_feature].idxmax()\n"+
            "        corr.drop([idx], axis = 0, inplace = True)\n"+
            "        column = data[idx]\n"+
            "        columns[idx] = column\n"+
            "        data.drop([idx], axis = 1, inplace = True)\n"+
            "        cont_vars = list(set(cont_vars) - set([idx]))\n"+
            "        xgb = DefaultXGBoostClassifier()\n"+
            "        dl = DatasetLoader(data=data, label=p_feature, transforms=transforms, bias_params=debias_params, train_valid_test_splits=[0.8, 0.1, 0.1], cat_col=cat_vars, cont_col=cont_vars, names_col = data.columns.values);\n"+
            "        pipeline_initial = DataPipeline(dataset_loader=dl, model=xgb, metrics=metrics);\n"+
            "        pipeline_initial.run();\n"+
            "        metr = pipeline_initial.get_protected_metrics();\n"+
            "        metrics_out = get_disparity_df(metr, debias_params, metrics_list)\n"+
            "        #metrics_out = get_disparity_df(etiq_wrapper_run(data, debias_params, cont_vars, cat_vars, p_feature, metrics),\n"+
            "        #                              debias_params, metrics_list)\n"+
            "        if idx not in result: result[idx] = {}\n"+
            "        for m in metrics_list:\n"+
            "            new = metrics_out.loc[m]['disparity']\n"+
            "            result[idx][m] = new - old[m]\n"+
            "        if reinsert:\n"+
            "            cont_vars.append(idx)\n"+
            "            data[idx] = column\n"+
            "    if not reinsert:\n"+
            "        for c in columns:\n"+
            "            data[c] = columns[c]\n"+
            "    return result\n"+
            "\n\n"+
            "# From the above function it extracts the features whose removal modifies the value of p_feature the most\n"+
            "def disparity_change_get_max(result):\n"+
            "    out = {}\n"+
            "    for ft in result:\n"+
            "        for m in result[ft]:\n"+
            "            if m not in out: out[m] = (ft, result[ft][m], ft, result[ft][m])\n"+
            "            if result[ft][m] < out[m][1]: out[m] = (ft, result[ft][m], out[m][2], out[m][3])\n"+
            "            if result[ft][m] > out[m][3]: out[m] = (out[m][0], out[m][1], ft, result[ft][m])\n"+
            "    return out\n"+
            "\n\n";
        var codeString2 = "dataset = " + df + "\n"+
            "df_copy = dataset\n"+
            "dropnan = " + dropnan + "\n"+
            "biased_cols = " + biased_cols + "\n"+
            "privileged_cols = " + privileged_cols + "\n"+
            "pos_outcome = " + pos_outcome + "\n"+
            "\n"+
            "# Checking input\n"+
            "dataset_labels = []\n"+
            "for elem in dataset.columns:\n"+
            "    dataset_labels.append(str(elem))\n"+
            "for col in biased_cols:\n"+
            "    if col not in dataset_labels:\n"+
            "        raise Exception(\"One or both biased columns are not in the dataset.\")\n"+
            "if privileged_cols not in dataset_labels:\n"+
            "    raise Exception(\"The privileged variable is not in the dataset.\")\n"+
            "if pos_outcome not in dataset[privileged_cols].unique():\n"+
            "    raise Exception(\"The positive outcome is not a possible value of the privileged variable.\")\n"+
            "\n"+
            "# Detecting dataset NaN values\n"+
            "if dropnan == 1:\n"+
            "    valuesToCheck = \"?\\/-\"\n"+
            "    for elem in valuesToCheck:\n"+
            "        if elem in dataset.values:\n"+
            "            dataset.replace(elem, np.nan)\n"+
            "    dataset = dataset.dropna()\n"+
            "\n\n"+
            "# Check that the input biased columns are in dataset\n"+
            "error_message = 1\n"+
            "count_bias_cols = 0\n"+
            "for elem in dataset.columns:\n"+
            "    for label in biased_cols:\n"+
            "        if label == elem:\n"+
            "            count_bias_cols += 1\n"+
            "if count_bias_cols == 0:\n"+
            "    raise Exception(\"The specified biased columns are not in the dataset\")\n"+
            "elif count_bias_cols == 1:\n"+
            "    raise Exception(\"One specified biased column is not in the dataset\")\n"+
            "\n\n"+
            "# Set the size of the chart\n" +
            "plt.figure(figsize = [10, 10])\n" +
            "\n" +
            "try:\n"+
            "    # Correlation calculation (Pearson) and matrix\n"+
            "    corr = df.corr()\n"+
            "    matrix = np.triu(corr)\n"+
            "except ValueError:\n"+
            "    corr = \"\"\n"+
            "\n\n"+
            "# Here start the real bias analysis\n"+
            "result = \"\"\n"+
            "# Check that the input privileged column is in dataset\n"+
            "error_message = 1\n"+
            "for label in dataset.columns:\n"+
            "    if label == privileged_cols:\n"+
            "        error_message = 0\n"+
            "if error_message == 1:\n"+
            "    raise Exception(\"The specified privileged column is not in the dataset\")\n"+
            "\n\n"+
            "# Calculate EDF metric\n"+
            "edf_list = []\n"+
            "df_edf_list = []\n"+
            "attribute1_set = np.array(dataset[biased_cols[0]].unique()).tolist()\n"+
            "attribute2_set = np.array(dataset[biased_cols[1]].unique()).tolist()\n"+
            "new_privileged_cols = privileged_cols + \"_01\"\n"+
            "threshold = dataset[privileged_cols].unique().tolist()\n"+
            "dataset[new_privileged_cols] = (dataset[privileged_cols] == threshold[0]).astype(int) # for each row check if the value is equal to threshold, if yes put 1 in new_privileged_cols, 0 otherwise\n"+
            "try:\n"+
            "    edf = get_edf_df(dataset, biased_cols[0], biased_cols[1], attribute1_set, attribute2_set, new_privileged_cols)\n"+
            "except TypeError:\n"+
            "    raise Exception(\"The two biased columns must be of the same type \'string\'\")\n"+
            "edf_list.append(edf)\n"+
            "df = pd.DataFrame(read_edf(edf, n = 3))\n"+
            "df_edf_list.append(df)\n"+
            "\n"+
            "# Setting final message\n"+
            "edf_result = 0\n"+
            "if not df_edf_list:\n"+
            "    result += \" but compatible columns cannot be found to calculate EDF metric\"\n"+
            "    raise Exception(result)\n"+
            "else:\n"+
            "    max_edf = 0\n"+
            "    max_df_edf = df_edf_list[0]\n"+
            "    for elem in df_edf_list:\n"+
            "        if elem.iloc[0][2] > max_edf:\n"+
            "            max_edf = elem.iloc[0][2]\n"+
            "            max_df_edf = elem\n"+
            "    edf_result = 1\n"+
            "\n\n"+
            "if edf_result == 0:\n"+
            "    result += \" but compatible columns cannot be found to calculate EDF metric\"\n"+
            "    raise Exception(result)\n"+
            "else:\n"+
            "\n\n"+
            "    # Calculate intersection, metrics and disparity\n"+
            "    data_copy = get_intersection(dataset, biased_cols[0], biased_cols[1])\n"+
            "    intersect_var = biased_cols[0] + \"_\" + biased_cols[1]\n"+
            "    cont_vars = []\n"+
            "    for label in dataset.columns:\n"+
            "        if label == intersect_var or label == privileged_cols:\n"+
            "            pass\n"+
            "        elif dataset[label].dtype == np.int64 or dataset[label].dtype == np.float64 or dataset[label].dtype == np.complex128 or dataset[label].dtype == np.int32 or dataset[label].dtype == np.float32:\n"+
            "            cont_vars.append(label)\n"+
            "    cat_vars = list(set(dataset.columns.values) - set(cont_vars))\n"+
            "    privilege_values = dataset[privileged_cols].unique().tolist()\n"+
            "    neg_outcome = \"\"\n"+
            "    for v in privilege_values:\n"+
            "        if str(v) != pos_outcome:\n"+
            "            neg_outcome = str(v)\n"+
            "    if not neg_outcome:\n"+
            "        raise ValueError(\"The value of the negative outcome could not be found. Please check that the privilege variable contains exactly two values.\")\n"+
            "    debias_params = get_debias_params(intersect_var, max_df_edf.iloc[0, 0], max_df_edf.iloc[0, 1], pos_outcome, neg_outcome)\n"+
            "    try:\n"+
            "        metrics = etiq_wrapper_run(dataset, debias_params, cont_vars, cat_vars, privileged_cols, metrics_bonus)\n"+
            "        df_metrics = get_df_from_metrics(metrics)\n"+
            "        df_disparity = get_disparity_df(metrics, debias_params, metrics_list)\n"+
            "    except KeyError: # for little datasets\n"+
            "        metrics = etiq_wrapper_run(dataset, debias_params, cont_vars, cat_vars, privileged_cols, metrics_sshort)\n"+
            "        df_metrics = get_df_from_metrics(metrics)\n"+
            "        df_disparity = get_disparity_df(metrics, debias_params, metrics_list_short)\n"+
            "\n\n"+
            "    # Calculate modal values, ratio between positive and negative outcome, occurrences of associating values to a datum feature\n"+
            "    features = cat_vars\n"+
            "    df_ratio = get_ratio_df(data = dataset, features = features, p_feature = privileged_cols, positive_outcome = pos_outcome, negative_outcome = neg_outcome)\n"+
            "    df_mode = get_mode_df(data = dataset, features = features, p_feature = privileged_cols, positive_outcome = pos_outcome, negative_outcome = neg_outcome)\n"+
            "    df_intersection = get_intersection(dataset, biased_cols[0], biased_cols[1], drop = False)\n"+
            "    samples = []\n"+
            "    try:\n"+
            "        for i in range(50):\n"+
            "            sample = dataset.sample(n = 1000, ignore_index = True)\n"+
            "            samples.append(sample)\n"+
            "    except ValueError: # for little datasets\n"+
            "        for i in range(50):\n"+
            "            sample = dataset.sample(n = 100, ignore_index = True)\n"+
            "            samples.append(sample)\n"+
            "    results_pos, results_neg = get_maxOccurrences_in_samples(samples = samples, features = features, p_feature = privileged_cols, positive_outcome = pos_outcome, negative_outcome = neg_outcome)\n"+
            "    df_values_of_1st = get_values_of(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 0], features = features)\n"+
            "    df_values_of_2nd = get_values_of(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 1], features = features)\n"+
            "    df_values_of_outcome_1st = get_values_of_outcome(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 0], features = features, p_feature = privileged_cols, outcome = pos_outcome)\n"+
            "    df_values_of_outcome_2nd = get_values_of_outcome(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 1], features = features, p_feature = privileged_cols, outcome = pos_outcome)\n"+
            "    df_outcome_1st_neg = get_values_of_outcome(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 0], features = features, p_feature = privileged_cols, outcome = neg_outcome)\n"+
            "    df_outcome_2nd_neg = get_values_of_outcome(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 1], features = features, p_feature = privileged_cols, outcome = neg_outcome)\n"+
            "\n"+
            "    # Here starts the features removal to verify any improvements in fairness and equity in the groups\n"+
            "    dataset = df_copy\n"+
            "    dataset = get_intersection(dataset, biased_cols[0], biased_cols[1], drop = True)\n"+
            "    threshold = [pos_outcome, neg_outcome]\n"+
            "    dataset[privileged_cols] = (dataset[privileged_cols] == threshold[0]).astype(int)\n"+
            "    conditions = [\n"+
            "        dataset[intersect_var] == max_df_edf.iloc[0, 0],\n"+
            "        dataset[intersect_var] == max_df_edf.iloc[0, 1]\n"+
            "    ]\n"+
            "    choices = [1, -1]\n"+
            "    dataset[intersect_var] = np.select(conditions, choices, default = 0)\n"+
            "    cont_vars = []\n"+
            "    for label in dataset.columns:\n"+
            "        if label == intersect_var or label == privileged_cols:\n"+
            "            pass\n"+
            "        elif dataset[label].dtype == np.int64 or dataset[label].dtype == np.float64 or dataset[label].dtype == np.complex128 or dataset[label].dtype == np.int32 or dataset[label].dtype == np.float32:\n"+
            "            cont_vars.append(label)\n"+
            "    cat_vars = list(set(dataset.columns.values) - set(cont_vars))\n"+
            "    debias_params = get_debias_params(intersect_var, \'1\', \'-1\', \'1\', \'0\')\n"+
            "    metrics = etiq_wrapper_run(dataset, debias_params, cont_vars, cat_vars, privileged_cols, metrics_initial)\n"+
            "    try:\n"+
            "        res_r = disparity_change(dataset, 6, True, cont_vars, privileged_cols, debias_params, cont_vars, cat_vars, metrics_short)\n"+
            "        df_dis_change_max = pd.DataFrame(disparity_change_get_max(res_r)).T\n"+
            "    except KeyError: # for little datasets\n"+
            "        res_r = disparity_change(dataset, 6, True, cont_vars, privileged_cols, debias_params, cont_vars, cat_vars, metrics_sshort)\n"+
            "        df_dis_change_max = pd.DataFrame(disparity_change_get_max(res_r)).T\n"+
            "max_df_edf\n"+
            "df_metrics\n"+
            "df_disparity\n"+
            "df_ratio\n"+
            "df_mode\n"+
            "df_intersection\n"+
            "pd.DataFrame(results_pos)\n"+
            "pd.DataFrame(results_neg)\n"+
            "pd.DataFrame(df_values_of_1st,index=[0])\n"+
            "pd.DataFrame(df_values_of_2nd,index=[0])\n"+
            "pd.DataFrame(df_values_of_outcome_1st,index=[0])\n"+
            "pd.DataFrame(df_values_of_outcome_2nd,index=[0])\n"+
            "pd.DataFrame(df_outcome_1st_neg,index=[0])\n"+
            "pd.DataFrame(df_outcome_2nd_neg,index=[0])\n"+
            "df_dis_change_max\n"+
            "if not corr:\n"+
            "    pass\n"+
            "else:\n"+
            "    sns.heatmap(corr, annot = True, mask = matrix, cmap = 'BuPu')\n"+
            "    plt.show()"
        return codeString + codeString2;
    }

    /*
    Blockly.Python.anchoringBias = function (a) {
        // copy here Giorgia's library
        var b = Blockly.Python.provideFunction_("do_null", [
            "pass"
        ]);
        return b;
    }
    */

    Blockly.Python.BIAS_Intersectional = Blockly.Python.intersectionalBias;
    //Blockly.Python.BIAS_Anchoring = Blockly.Python.anchoringBias;

    return Blockly.Python;

});
