// Do not edit this file; automatically generated by gulp.

/* eslint-disable */

var VarData = {};


(function (root, factory) {
    if (typeof define === "function" && define.amd) {
        // AMD
        define(["./blockly_compressed.js"], factory);
    } else if (typeof exports === "object") {
        // Node.js
        module.exports = factory(require("./blockly_compressed.js"));
    } else {
        // Browser
        root.Blockly.Python = factory(root.Blockly);
    }
})(this, function (Blockly) {
    "use strict";
    Blockly.Python = new Blockly.Generator("Python");
    Blockly.Python.addReservedWords(
        "False,None,True,and,as,assert,break,class,continue,def,del,elif,else,except,exec,finally,for,from,global,if,import,in,is,lambda,nonlocal,not,or,pass,print,raise,return,try,while,with,yield,NotImplemented,Ellipsis,__debug__,quit,exit,copyright,license,credits,ArithmeticError,AssertionError,AttributeError,BaseException,BlockingIOError,BrokenPipeError,BufferError,BytesWarning,ChildProcessError,ConnectionAbortedError,ConnectionError,ConnectionRefusedError,ConnectionResetError,DeprecationWarning,EOFError,Ellipsis,EnvironmentError,Exception,FileExistsError,FileNotFoundError,FloatingPointError,FutureWarning,GeneratorExit,IOError,ImportError,ImportWarning,IndentationError,IndexError,InterruptedError,IsADirectoryError,KeyError,KeyboardInterrupt,LookupError,MemoryError,ModuleNotFoundError,NameError,NotADirectoryError,NotImplemented,NotImplementedError,OSError,OverflowError,PendingDeprecationWarning,PermissionError,ProcessLookupError,RecursionError,ReferenceError,ResourceWarning,RuntimeError,RuntimeWarning,StandardError,StopAsyncIteration,StopIteration,SyntaxError,SyntaxWarning,SystemError,SystemExit,TabError,TimeoutError,TypeError,UnboundLocalError,UnicodeDecodeError,UnicodeEncodeError,UnicodeError,UnicodeTranslateError,UnicodeWarning,UserWarning,ValueError,Warning,ZeroDivisionError,_,__build_class__,__debug__,__doc__,__import__,__loader__,__name__,__package__,__spec__,abs,all,any,apply,ascii,basestring,bin,bool,buffer,bytearray,bytes,callable,chr,classmethod,cmp,coerce,compile,complex,copyright,credits,delattr,dict,dir,divmod,enumerate,eval,exec,execfile,exit,file,filter,float,format,frozenset,getattr,globals,hasattr,hash,help,hex,id,input,int,intern,isinstance,issubclass,iter,len,license,list,locals,long,map,max,memoryview,min,next,object,oct,open,ord,pow,print,property,quit,range,raw_input,reduce,reload,repr,reversed,round,set,setattr,slice,sorted,staticmethod,str,sum,super,tuple,type,unichr,unicode,vars,xrange,zip"
    );
    Blockly.Python.VARDATA = [];
    Blockly.Python.ORDER_ATOMIC = 0;
    Blockly.Python.ORDER_COLLECTION = 1;
    Blockly.Python.ORDER_STRING_CONVERSION = 1;
    Blockly.Python.ORDER_MEMBER = 2.1;
    Blockly.Python.ORDER_FUNCTION_CALL = 2.2;
    Blockly.Python.ORDER_EXPONENTIATION = 3;
    Blockly.Python.ORDER_UNARY_SIGN = 4;
    Blockly.Python.ORDER_BITWISE_NOT = 4;
    Blockly.Python.ORDER_MULTIPLICATIVE = 5;
    Blockly.Python.ORDER_ADDITIVE = 6;
    Blockly.Python.ORDER_BITWISE_SHIFT = 7;
    Blockly.Python.ORDER_BITWISE_AND = 8;
    Blockly.Python.ORDER_BITWISE_XOR = 9;
    Blockly.Python.ORDER_BITWISE_OR = 10;
    Blockly.Python.ORDER_RELATIONAL = 11;
    Blockly.Python.ORDER_LOGICAL_NOT = 12;
    Blockly.Python.ORDER_LOGICAL_AND = 13;
    Blockly.Python.ORDER_LOGICAL_OR = 14;
    Blockly.Python.ORDER_CONDITIONAL = 15;
    Blockly.Python.ORDER_LAMBDA = 16;
    Blockly.Python.ORDER_NONE = 99;
    Blockly.Python.ORDER_OVERRIDES = [
        [Blockly.Python.ORDER_FUNCTION_CALL, Blockly.Python.ORDER_MEMBER],
        [Blockly.Python.ORDER_FUNCTION_CALL, Blockly.Python.ORDER_FUNCTION_CALL],
        [Blockly.Python.ORDER_MEMBER, Blockly.Python.ORDER_MEMBER],
        [Blockly.Python.ORDER_MEMBER, Blockly.Python.ORDER_FUNCTION_CALL],
        [Blockly.Python.ORDER_LOGICAL_NOT, Blockly.Python.ORDER_LOGICAL_NOT],
        [Blockly.Python.ORDER_LOGICAL_AND, Blockly.Python.ORDER_LOGICAL_AND],
        [Blockly.Python.ORDER_LOGICAL_OR, Blockly.Python.ORDER_LOGICAL_OR],
    ];
    Blockly.Python.isInitialized = !1;
    Blockly.Python.init = function (a) {
        Blockly.Python.PASS = this.INDENT + "pass\n";
        Blockly.Python.definitions_ = Object.create(null);
        Blockly.Python.functionNames_ = Object.create(null);
        Blockly.Python.variableDB_ ? Blockly.Python.variableDB_.reset() : (Blockly.Python.variableDB_ = new Blockly.Names(Blockly.Python.RESERVED_WORDS_));
        Blockly.Python.variableDB_.setVariableMap(a.getVariableMap());
        for (var b = [], c = Blockly.Variables.allDeveloperVariables(a), d = 0; d < c.length; d++) b.push(Blockly.Python.variableDB_.getName(c[d], Blockly.Names.DEVELOPER_VARIABLE_TYPE) + " = None");
        a = Blockly.Variables.allUsedVarModels(a);

        for (d = 0; d < a.length; d++) b.push(Blockly.Python.variableDB_.getName(a[d].getId(), Blockly.VARIABLE_CATEGORY_NAME) + " = None");
        Blockly.Python.definitions_.variables = b.join("\n");
        this.isInitialized = !0;
    };
    Blockly.Python.finish = function (a) {
        var b = [],
            c = [],
            d;
        for (d in Blockly.Python.definitions_) {
            var e = Blockly.Python.definitions_[d];
            e.match(/^(from\s+\S+\s+)?import\s+\S+/) ? b.push(e) : c.push(e);
        }
        delete Blockly.Python.definitions_;
        delete Blockly.Python.functionNames_;
        Blockly.Python.variableDB_.reset();
        return (b.join("\n") + "\n\n" + c.join("\n\n")).replace(/\n\n+/g, "\n\n").replace(/\n*$/, "\n\n\n") + a;
    };
    Blockly.Python.scrubNakedValue = function (a) {
        return a + "\n";
    };
    Blockly.Python.quote_ = function (a) {
        a = a.replace(/\\/g, "\\\\").replace(/\n/g, "\\\n");
        var b = "'";
        -1 !== a.indexOf("'") && (-1 === a.indexOf('"') ? (b = '"') : (a = a.replace(/'/g, "\\'")));
        return b + a + b;
    };
    Blockly.Python.multiline_quote_ = function (a) {
        return a.split(/\n/g).map(Blockly.Python.quote_).join(" + '\\n' + \n");
    };
    Blockly.Python.scrub_ = function (a, b, c) {
        var d = "";
        if (!a.outputConnection || !a.outputConnection.targetConnection) {
            var e = a.getCommentText();
            e && ((e = Blockly.utils.string.wrap(e, Blockly.Python.COMMENT_WRAP - 3)), (d += Blockly.Python.prefixLines(e + "\n", "# ")));
            for (var f = 0; f < a.inputList.length; f++) a.inputList[f].type == Blockly.INPUT_VALUE && (e = a.inputList[f].connection.targetBlock()) && (e = Blockly.Python.allNestedComments(e)) && (d += Blockly.Python.prefixLines(e, "# "));
        }
        a = a.nextConnection && a.nextConnection.targetBlock();
        c = c ? "" : Blockly.Python.blockToCode(a);
        return d + b + c;
    };
    Blockly.Python.getAdjustedInt = function (a, b, c, d) {
        c = c || 0;
        a.workspace.options.oneBasedIndex && c--;
        var e = a.workspace.options.oneBasedIndex ? "1" : "0";
        a = Blockly.Python.valueToCode(a, b, c ? Blockly.Python.ORDER_ADDITIVE : Blockly.Python.ORDER_NONE) || e;
        Blockly.isNumber(a) ? ((a = parseInt(a, 10) + c), d && (a = -a)) : ((a = 0 < c ? "int(" + a + " + " + c + ")" : 0 > c ? "int(" + a + " - " + -c + ")" : "int(" + a + ")"), d && (a = "-" + a));
        return a;
    };
    Blockly.Python.colour = {};
    Blockly.Python.colour_picker = function (a) {
        return [Blockly.Python.quote_(a.getFieldValue("COLOUR")), Blockly.Python.ORDER_ATOMIC];
    };
    Blockly.Python.colour_random = function (a) {
        Blockly.Python.definitions_.import_random = "import random";
        return ["'#%06x' % random.randint(0, 2**24 - 1)", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.colour_rgb = function (a) {
        var b = Blockly.Python.provideFunction_("colour_rgb", [
            "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(r, g, b):",
            "  r = round(min(100, max(0, r)) * 2.55)",
            "  g = round(min(100, max(0, g)) * 2.55)",
            "  b = round(min(100, max(0, b)) * 2.55)",
            "  return '#%02x%02x%02x' % (r, g, b)",
        ]),
            c = Blockly.Python.valueToCode(a, "RED", Blockly.Python.ORDER_NONE) || 0,
            d = Blockly.Python.valueToCode(a, "GREEN", Blockly.Python.ORDER_NONE) || 0;
        a = Blockly.Python.valueToCode(a, "BLUE", Blockly.Python.ORDER_NONE) || 0;
        return [b + "(" + c + ", " + d + ", " + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.colour_blend = function (a) {
        var b = Blockly.Python.provideFunction_("colour_blend", [
            "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(colour1, colour2, ratio):",
            "  r1, r2 = int(colour1[1:3], 16), int(colour2[1:3], 16)",
            "  g1, g2 = int(colour1[3:5], 16), int(colour2[3:5], 16)",
            "  b1, b2 = int(colour1[5:7], 16), int(colour2[5:7], 16)",
            "  ratio = min(1, max(0, ratio))",
            "  r = round(r1 * (1 - ratio) + r2 * ratio)",
            "  g = round(g1 * (1 - ratio) + g2 * ratio)",
            "  b = round(b1 * (1 - ratio) + b2 * ratio)",
            "  return '#%02x%02x%02x' % (r, g, b)",
        ]),
            c = Blockly.Python.valueToCode(a, "COLOUR1", Blockly.Python.ORDER_NONE) || "'#000000'",
            d = Blockly.Python.valueToCode(a, "COLOUR2", Blockly.Python.ORDER_NONE) || "'#000000'";
        a = Blockly.Python.valueToCode(a, "RATIO", Blockly.Python.ORDER_NONE) || 0;
        return [b + "(" + c + ", " + d + ", " + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.lists = {};
    Blockly.Python.lists_create_empty = function (a) {
        return ["[]", Blockly.Python.ORDER_ATOMIC];
    };
    Blockly.Python.lists_create_with = function (a) {
        for (var b = Array(a.itemCount_), c = 0; c < a.itemCount_; c++) b[c] = Blockly.Python.valueToCode(a, "ADD" + c, Blockly.Python.ORDER_NONE) || "None";
        return ["[" + b.join(", ") + "]", Blockly.Python.ORDER_ATOMIC];
    };
    Blockly.Python.lists_repeat = function (a) {
        var b = Blockly.Python.valueToCode(a, "ITEM", Blockly.Python.ORDER_NONE) || "None";
        a = Blockly.Python.valueToCode(a, "NUM", Blockly.Python.ORDER_MULTIPLICATIVE) || "0";
        return ["[" + b + "] * " + a, Blockly.Python.ORDER_MULTIPLICATIVE];
    };
    Blockly.Python.lists_length = function (a) {
        return ["len(" + (Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "[]") + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.lists_isEmpty = function (a) {
        return ["not len(" + (Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "[]") + ")", Blockly.Python.ORDER_LOGICAL_NOT];
    };
    Blockly.Python.lists_indexOf = function (a) {
        var b = Blockly.Python.valueToCode(a, "FIND", Blockly.Python.ORDER_NONE) || "[]",
            c = Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "''";
        if (a.workspace.options.oneBasedIndex)
            var d = " 0",
                e = " + 1",
                f = "";
        else (d = " -1"), (e = ""), (f = " - 1");
        if ("FIRST" == a.getFieldValue("END"))
            return (
                (a = Blockly.Python.provideFunction_("first_index", ["def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(my_list, elem):", "  try: index = my_list.index(elem)" + e, "  except: index =" + d, "  return index"])),
                [a + "(" + c + ", " + b + ")", Blockly.Python.ORDER_FUNCTION_CALL]
            );
        a = Blockly.Python.provideFunction_("last_index", ["def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(my_list, elem):", "  try: index = len(my_list) - my_list[::-1].index(elem)" + f, "  except: index =" + d, "  return index"]);
        return [a + "(" + c + ", " + b + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.lists_getIndex = function (a) {
        var b = a.getFieldValue("MODE") || "GET",
            c = a.getFieldValue("WHERE") || "FROM_START",
            d = Blockly.Python.valueToCode(a, "VALUE", "RANDOM" == c ? Blockly.Python.ORDER_NONE : Blockly.Python.ORDER_MEMBER) || "[]";
        switch (c) {
            case "FIRST":
                if ("GET" == b) return [d + "[0]", Blockly.Python.ORDER_MEMBER];
                if ("GET_REMOVE" == b) return [d + ".pop(0)", Blockly.Python.ORDER_FUNCTION_CALL];
                if ("REMOVE" == b) return d + ".pop(0)\n";
                break;
            case "LAST":
                if ("GET" == b) return [d + "[-1]", Blockly.Python.ORDER_MEMBER];
                if ("GET_REMOVE" == b) return [d + ".pop()", Blockly.Python.ORDER_FUNCTION_CALL];
                if ("REMOVE" == b) return d + ".pop()\n";
                break;
            case "FROM_START":
                a = Blockly.Python.getAdjustedInt(a, "AT");
                if ("GET" == b) return [d + "[" + a + "]", Blockly.Python.ORDER_MEMBER];
                if ("GET_REMOVE" == b) return [d + ".pop(" + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
                if ("REMOVE" == b) return d + ".pop(" + a + ")\n";
                break;
            case "FROM_END":
                a = Blockly.Python.getAdjustedInt(a, "AT", 1, !0);
                if ("GET" == b) return [d + "[" + a + "]", Blockly.Python.ORDER_MEMBER];
                if ("GET_REMOVE" == b) return [d + ".pop(" + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
                if ("REMOVE" == b) return d + ".pop(" + a + ")\n";
                break;
            case "RANDOM":
                Blockly.Python.definitions_.import_random = "import random";
                if ("GET" == b) return ["random.choice(" + d + ")", Blockly.Python.ORDER_FUNCTION_CALL];
                d = Blockly.Python.provideFunction_("lists_remove_random_item", ["def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(myList):", "  x = int(random.random() * len(myList))", "  return myList.pop(x)"]) + "(" + d + ")";
                if ("GET_REMOVE" == b) return [d, Blockly.Python.ORDER_FUNCTION_CALL];
                if ("REMOVE" == b) return d + "\n";
        }
        throw Error("Unhandled combination (lists_getIndex).");
    };
    Blockly.Python.lists_setIndex = function (a) {
        var b = Blockly.Python.valueToCode(a, "LIST", Blockly.Python.ORDER_MEMBER) || "[]",
            c = a.getFieldValue("MODE") || "GET",
            d = a.getFieldValue("WHERE") || "FROM_START",
            e = Blockly.Python.valueToCode(a, "TO", Blockly.Python.ORDER_NONE) || "None";
        switch (d) {
            case "FIRST":
                if ("SET" == c) return b + "[0] = " + e + "\n";
                if ("INSERT" == c) return b + ".insert(0, " + e + ")\n";
                break;
            case "LAST":
                if ("SET" == c) return b + "[-1] = " + e + "\n";
                if ("INSERT" == c) return b + ".append(" + e + ")\n";
                break;
            case "FROM_START":
                a = Blockly.Python.getAdjustedInt(a, "AT");
                if ("SET" == c) return b + "[" + a + "] = " + e + "\n";
                if ("INSERT" == c) return b + ".insert(" + a + ", " + e + ")\n";
                break;
            case "FROM_END":
                a = Blockly.Python.getAdjustedInt(a, "AT", 1, !0);
                if ("SET" == c) return b + "[" + a + "] = " + e + "\n";
                if ("INSERT" == c) return b + ".insert(" + a + ", " + e + ")\n";
                break;
            case "RANDOM":
                Blockly.Python.definitions_.import_random = "import random";
                b.match(/^\w+$/) ? (a = "") : ((a = Blockly.Python.variableDB_.getDistinctName("tmp_list", Blockly.VARIABLE_CATEGORY_NAME)), (d = a + " = " + b + "\n"), (b = a), (a = d));
                d = Blockly.Python.variableDB_.getDistinctName("tmp_x", Blockly.VARIABLE_CATEGORY_NAME);
                a += d + " = int(random.random() * len(" + b + "))\n";
                if ("SET" == c) return a + (b + "[" + d + "] = " + e + "\n");
                if ("INSERT" == c) return a + (b + ".insert(" + d + ", " + e + ")\n");
        }
        throw Error("Unhandled combination (lists_setIndex).");
    };
    Blockly.Python.lists_getSublist = function (a) {
        var b = Blockly.Python.valueToCode(a, "LIST", Blockly.Python.ORDER_MEMBER) || "[]",
            c = a.getFieldValue("WHERE1"),
            d = a.getFieldValue("WHERE2");
        switch (c) {
            case "FROM_START":
                c = Blockly.Python.getAdjustedInt(a, "AT1");
                "0" == c && (c = "");
                break;
            case "FROM_END":
                c = Blockly.Python.getAdjustedInt(a, "AT1", 1, !0);
                break;
            case "FIRST":
                c = "";
                break;
            default:
                throw Error("Unhandled option (lists_getSublist)");
        }
        switch (d) {
            case "FROM_START":
                a = Blockly.Python.getAdjustedInt(a, "AT2", 1);
                break;
            case "FROM_END":
                a = Blockly.Python.getAdjustedInt(a, "AT2", 0, !0);
                Blockly.isNumber(String(a)) ? "0" == a && (a = "") : ((Blockly.Python.definitions_.import_sys = "import sys"), (a += " or sys.maxsize"));
                break;
            case "LAST":
                a = "";
                break;
            default:
                throw Error("Unhandled option (lists_getSublist)");
        }
        return [b + "[" + c + " : " + a + "]", Blockly.Python.ORDER_MEMBER];
    };
    Blockly.Python.lists_sort = function (a) {
        var b = Blockly.Python.valueToCode(a, "LIST", Blockly.Python.ORDER_NONE) || "[]",
            c = a.getFieldValue("TYPE");
        a = "1" === a.getFieldValue("DIRECTION") ? "False" : "True";
        return [
            Blockly.Python.provideFunction_("lists_sort", [
                "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(my_list, type, reverse):",
                "  def try_float(s):",
                "    try:",
                "      return float(s)",
                "    except:",
                "      return 0",
                "  key_funcs = {",
                '    "NUMERIC": try_float,',
                '    "TEXT": str,',
                '    "IGNORE_CASE": lambda s: str(s).lower()',
                "  }",
                "  key_func = key_funcs[type]",
                "  list_cpy = list(my_list)",
                "  return sorted(list_cpy, key=key_func, reverse=reverse)",
            ]) +
            "(" +
            b +
            ', "' +
            c +
            '", ' +
            a +
            ")",
            Blockly.Python.ORDER_FUNCTION_CALL,
        ];
    };
    Blockly.Python.lists_split = function (a) {
        var b = a.getFieldValue("MODE");
        if ("SPLIT" == b) (b = Blockly.Python.valueToCode(a, "INPUT", Blockly.Python.ORDER_MEMBER) || "''"), (a = Blockly.Python.valueToCode(a, "DELIM", Blockly.Python.ORDER_NONE)), (a = b + ".split(" + a + ")");
        else if ("JOIN" == b) (b = Blockly.Python.valueToCode(a, "INPUT", Blockly.Python.ORDER_NONE) || "[]"), (a = Blockly.Python.valueToCode(a, "DELIM", Blockly.Python.ORDER_MEMBER) || "''"), (a = a + ".join(" + b + ")");
        else throw Error("Unknown mode: " + b);
        return [a, Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.lists_reverse = function (a) {
        return ["list(reversed(" + (Blockly.Python.valueToCode(a, "LIST", Blockly.Python.ORDER_NONE) || "[]") + "))", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.logic = {};
    Blockly.Python.controls_if = function (a) {
        var b = 0,
            c = "";
        Blockly.Python.STATEMENT_PREFIX && (c += Blockly.Python.injectId(Blockly.Python.STATEMENT_PREFIX, a));
        do {
            var d = Blockly.Python.valueToCode(a, "IF" + b, Blockly.Python.ORDER_NONE) || "False";
            var e = Blockly.Python.statementToCode(a, "DO" + b) || Blockly.Python.PASS;
            Blockly.Python.STATEMENT_SUFFIX && (e = Blockly.Python.prefixLines(Blockly.Python.injectId(Blockly.Python.STATEMENT_SUFFIX, a), Blockly.Python.INDENT) + e);
            c += (0 == b ? "if " : "elif ") + d + ":\n" + e;
            ++b;
        } while (a.getInput("IF" + b));
        if (a.getInput("ELSE") || Blockly.Python.STATEMENT_SUFFIX)
            (e = Blockly.Python.statementToCode(a, "ELSE") || Blockly.Python.PASS),
                Blockly.Python.STATEMENT_SUFFIX && (e = Blockly.Python.prefixLines(Blockly.Python.injectId(Blockly.Python.STATEMENT_SUFFIX, a), Blockly.Python.INDENT) + e),
                (c += "else:\n" + e);
        return c;
    };
    Blockly.Python.controls_ifelse = Blockly.Python.controls_if;
    Blockly.Python.logic_compare = function (a) {
        var b = { EQ: "==", NEQ: "!=", LT: "<", LTE: "<=", GT: ">", GTE: ">=" }[a.getFieldValue("OP")],
            c = Blockly.Python.ORDER_RELATIONAL,
            d = Blockly.Python.valueToCode(a, "A", c) || "0";
        a = Blockly.Python.valueToCode(a, "B", c) || "0";
        return [d + " " + b + " " + a, c];
    };
    Blockly.Python.logic_operation = function (a) {
        var b = "AND" == a.getFieldValue("OP") ? "and" : "or",
            c = "and" == b ? Blockly.Python.ORDER_LOGICAL_AND : Blockly.Python.ORDER_LOGICAL_OR,
            d = Blockly.Python.valueToCode(a, "A", c);
        a = Blockly.Python.valueToCode(a, "B", c);
        if (d || a) {
            var e = "and" == b ? "True" : "False";
            d || (d = e);
            a || (a = e);
        } else a = d = "False";
        return [d + " " + b + " " + a, c];
    };
    Blockly.Python.logic_negate = function (a) {
        return ["not " + (Blockly.Python.valueToCode(a, "BOOL", Blockly.Python.ORDER_LOGICAL_NOT) || "True"), Blockly.Python.ORDER_LOGICAL_NOT];
    };
    Blockly.Python.logic_boolean = function (a) {
        return ["TRUE" == a.getFieldValue("BOOL") ? "True" : "False", Blockly.Python.ORDER_ATOMIC];
    };
    Blockly.Python.logic_null = function (a) {
        return ["None", Blockly.Python.ORDER_ATOMIC];
    };
    Blockly.Python.logic_ternary = function (a) {
        var b = Blockly.Python.valueToCode(a, "IF", Blockly.Python.ORDER_CONDITIONAL) || "False",
            c = Blockly.Python.valueToCode(a, "THEN", Blockly.Python.ORDER_CONDITIONAL) || "None";
        a = Blockly.Python.valueToCode(a, "ELSE", Blockly.Python.ORDER_CONDITIONAL) || "None";
        return [c + " if " + b + " else " + a, Blockly.Python.ORDER_CONDITIONAL];
    };
    Blockly.Python.loops = {};
    Blockly.Python.controls_repeat_ext = function (a) {
        var b = a.getField("TIMES") ? String(parseInt(a.getFieldValue("TIMES"), 10)) : Blockly.Python.valueToCode(a, "TIMES", Blockly.Python.ORDER_NONE) || "0";
        b = Blockly.isNumber(b) ? parseInt(b, 10) : "int(" + b + ")";
        var c = Blockly.Python.statementToCode(a, "DO");
        c = Blockly.Python.addLoopTrap(c, a) || Blockly.Python.PASS;
        return "for " + Blockly.Python.variableDB_.getDistinctName("count", Blockly.VARIABLE_CATEGORY_NAME) + " in range(" + b + "):\n" + c;
    };
    Blockly.Python.controls_repeat = Blockly.Python.controls_repeat_ext;
    Blockly.Python.controls_whileUntil = function (a) {
        var b = "UNTIL" == a.getFieldValue("MODE"),
            c = Blockly.Python.valueToCode(a, "BOOL", b ? Blockly.Python.ORDER_LOGICAL_NOT : Blockly.Python.ORDER_NONE) || "False",
            d = Blockly.Python.statementToCode(a, "DO");
        d = Blockly.Python.addLoopTrap(d, a) || Blockly.Python.PASS;
        b && (c = "not " + c);
        return "while " + c + ":\n" + d;
    };
    Blockly.Python.controls_for = function (a) {
        var b = Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME),
            c = Blockly.Python.valueToCode(a, "FROM", Blockly.Python.ORDER_NONE) || "0",
            d = Blockly.Python.valueToCode(a, "TO", Blockly.Python.ORDER_NONE) || "0",
            e = Blockly.Python.valueToCode(a, "BY", Blockly.Python.ORDER_NONE) || "1",
            f = Blockly.Python.statementToCode(a, "DO");
        f = Blockly.Python.addLoopTrap(f, a) || Blockly.Python.PASS;
        var n = "",
            k = function () {
                return Blockly.Python.provideFunction_("upRange", ["def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(start, stop, step):", "  while start <= stop:", "    yield start", "    start += abs(step)"]);
            },
            h = function () {
                return Blockly.Python.provideFunction_("downRange", ["def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(start, stop, step):", "  while start >= stop:", "    yield start", "    start -= abs(step)"]);
            };
        a = function (g, l, p) {
            return "(" + g + " <= " + l + ") and " + k() + "(" + g + ", " + l + ", " + p + ") or " + h() + "(" + g + ", " + l + ", " + p + ")";
        };
        if (Blockly.isNumber(c) && Blockly.isNumber(d) && Blockly.isNumber(e))
            (c = Number(c)),
                (d = Number(d)),
                (e = Math.abs(Number(e))),
                0 === c % 1 && 0 === d % 1 && 0 === e % 1
                    ? (c <= d ? (d++, (a = 0 == c && 1 == e ? d : c + ", " + d), 1 != e && (a += ", " + e)) : (d--, (a = c + ", " + d + ", -" + e)), (a = "range(" + a + ")"))
                    : ((a = c < d ? k() : h()), (a += "(" + c + ", " + d + ", " + e + ")"));
        else {
            var m = function (g, l) {
                Blockly.isNumber(g) ? (g = Number(g)) : g.match(/^\w+$/) ? (g = "float(" + g + ")") : ((l = Blockly.Python.variableDB_.getDistinctName(b + l, Blockly.VARIABLE_CATEGORY_NAME)), (n += l + " = float(" + g + ")\n"), (g = l));
                return g;
            };
            c = m(c, "_start");
            d = m(d, "_end");
            e = m(e, "_inc");
            "number" == typeof c && "number" == typeof d ? ((a = c < d ? k() : h()), (a += "(" + c + ", " + d + ", " + e + ")")) : (a = a(c, d, e));
        }
        return (n += "for " + b + " in " + a + ":\n" + f);
    };
    Blockly.Python.controls_forEach = function (a) {
        var b = Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME),
            c = Blockly.Python.valueToCode(a, "LIST", Blockly.Python.ORDER_RELATIONAL) || "[]",
            d = Blockly.Python.statementToCode(a, "DO");
        d = Blockly.Python.addLoopTrap(d, a) || Blockly.Python.PASS;
        return "for " + b + " in " + c + ":\n" + d;
    };
    Blockly.Python.controls_flow_statements = function (a) {
        var b = "";
        Blockly.Python.STATEMENT_PREFIX && (b += Blockly.Python.injectId(Blockly.Python.STATEMENT_PREFIX, a));
        Blockly.Python.STATEMENT_SUFFIX && (b += Blockly.Python.injectId(Blockly.Python.STATEMENT_SUFFIX, a));
        if (Blockly.Python.STATEMENT_PREFIX) {
            var c = Blockly.Constants.Loops.CONTROL_FLOW_IN_LOOP_CHECK_MIXIN.getSurroundLoop(a);
            c && !c.suppressPrefixSuffix && (b += Blockly.Python.injectId(Blockly.Python.STATEMENT_PREFIX, c));
        }
        switch (a.getFieldValue("FLOW")) {
            case "BREAK":
                return b + "break\n";
            case "CONTINUE":
                return b + "continue\n";
        }
        throw Error("Unknown flow statement.");
    };
    /*
     * Custom
     */
    Blockly.Python.pandas = {};
    Blockly.Python['pandas_read_csv'] = function (a) {
        Blockly.Python.definitions_.pandas = "import pandas as pd";
        // it makes compatible the block with both variable and string blocks
        if (String(a).split(" ").length > 3) {
            // string block input
            return ['pd.read_csv("' + String(a).split(" ")[3] + '")', Blockly.Python.ORDER_FUNCTION_CALL] //Original row: return ['pd.read_csv(' + String(a).split(" ")[2] + ')', Blockly.Python.ORDER_FUNCTION_CALL]
        } else {
            // variable block input
            return ['pd.read_csv(' + String(a).split(" ")[2] + ')', Blockly.Python.ORDER_FUNCTION_CALL];
        }
    }

    Blockly.Python["create_dict"] = function (a) {

        var b = 1,
            c = "{";
        do {
            var d = Blockly.Python.valueToCode(a, "KEY" + b, Blockly.Python.ORDER_NONE) || "";
            var e = Blockly.Python.valueToCode(a, "VAL" + b, Blockly.Python.ORDER_NONE) || "";
            Blockly.Python.STATEMENT_SUFFIX && (e = Blockly.Python.prefixLines(Blockly.Python.injectId(Blockly.Python.STATEMENT_SUFFIX, a), Blockly.Python.INDENT) + e);
            if (b > 1) {
                c += ",";
            }
            c += d + ":" + e;
            ++b;
        } while (a.getInput("KEY" + b));
        c += "}";
        if ((e != "") && (d != "")) {
            return [c, Blockly.Python.ORDER_FUNCTION_CALL];
        } else {
            return ["None", Blockly.Python.ORDER_FUNCTION_CALL];
        }
    }
    Blockly.Python["dict_append"] = function (a) {
        var e = ""
        var b = Blockly.Python.valueToCode(a, "DICTIONARY", Blockly.Python.ORDER_NONE) || "";
        var c = Blockly.Python.valueToCode(a, "KEY", Blockly.Python.ORDER_NONE) || "";
        var d = Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "";
        if ((b != "") && (c != "") && (d != "")) {
            e = b + "[" + c + "] = " + d;
        }
        return e;
    }

    Blockly.Python['seaborn_dataset'] = function (a) {
        Blockly.Python.definitions_.seaborn = "import seaborn as sns";
        VarData[a.inputList[0].fieldRow[1].value_] = 'sns.load_dataset("' + a.inputList[0].fieldRow[1].value_ + '")', Blockly.Python.ORDER_FUNCTION_CALL;
        return ['sns.load_dataset("' + a.inputList[0].fieldRow[1].value_ + '")', Blockly.Python.ORDER_FUNCTION_CALL]
    }
    Blockly.Python['skl_train_test_split'] = function (a) {
        Blockly.Python.definitions_.sklearn_test_train_split = "from sklearn.model_selection import train_test_split";
        var dataframe = Blockly.Python.valueToCode(a, "DATAFRAME", Blockly.Python.ORDER_NONE) || ""
        var train_X = Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME)
        var train_Y = Blockly.Python.variableDB_.getName(a.getFieldValue("VAR2"), Blockly.VARIABLE_CATEGORY_NAME)
        var test_X = Blockly.Python.variableDB_.getName(a.getFieldValue("VAR1"), Blockly.VARIABLE_CATEGORY_NAME)
        var test_Y = Blockly.Python.variableDB_.getName(a.getFieldValue("VAR3"), Blockly.VARIABLE_CATEGORY_NAME)
        var target = Blockly.Python.valueToCode(a, "TARGETVAR", Blockly.Python.ORDER_NONE)
        var TestSize = Blockly.Python.valueToCode(a, "TESTSIZE", Blockly.Python.ORDER_NONE)

        var codeString = '\n' + train_X + ', ' + test_X + ', ' + train_Y + ', ' + test_Y + '=train_test_split(' + dataframe + '.drop(columns = [' + target + ']),' + dataframe + '[' + target + ']' + ', test_size=' + TestSize + ', random_state=42)\n'
        var codeString2 = ""
        if (a.getFieldValue("SPLIT") == "dropNa") {
            codeString2 = 'def dropNa(' + train_X + ', ' + test_X + ', ' + train_Y + ', ' + test_Y + '):\n' +
                '     ' + train_X + ' = ' + train_X + '.dropna()\n' +
                '     ' + train_Y + " = " + train_Y + ".loc[" + train_X + ".index.values.tolist()]\n" +
                '     ' + test_X + " = " + test_X + ".dropna()\n" +
                '     ' + test_Y + " = " + test_Y + ".loc[" + test_X + ".index.values.tolist()]\n" +
                '     return ' + train_X + ', ' + test_X + ', ' + train_Y + ', ' + test_Y + '\n' +
                train_X + ', ' + test_X + ', ' + train_Y + ', ' + test_Y + " = " + "dropNa(" + train_X + ', ' + test_X + ', ' + train_Y + ', ' + test_Y + ")\n"

        }


        Blockly.Python.definitions_.pandas = "import pandas as pd";
        Blockly.Python.definitions_.encoder = "from sklearn.preprocessing import LabelEncoder, OneHotEncoder";
        Blockly.Python.definitions_.numpy = "import numpy as np"

        if (dataframe == "") {
            return ""
        }
        else {
            return codeString + codeString2
        }
    }


    Blockly.Python['pandas_drop_columns'] = function (a) {
        var columns = Blockly.Python.valueToCode(a, "COLUMN", Blockly.Python.ORDER_UNARY_SIGN)
        if (columns == "") {
            return ""
        }
        var DataFrame = Blockly.Python.valueToCode(a, "DATAFRAME", Blockly.Python.ORDER_UNARY_SIGN)
        if (a.getInputTargetBlock("COLUMN").outputConnection.getCheck() == "String") {
            return [DataFrame + ".drop([" + columns + "], axis = 1)", Blockly.Python.ORDER_ATOMIC];
        } if (a.getInputTargetBlock("COLUMN").outputConnection.getCheck() == "Array") {
            return [DataFrame + ".drop([" + columns + "], axis = 1)", Blockly.Python.ORDER_ATOMIC];
        } if (columns == "" || DataFrame == "") {
            return ["", Blockly.Python.ORDER_ATOMIC];
        }
    }

    Blockly.Python['pandas_sample'] = function (a) {
        var factor = Blockly.Python.valueToCode(a, "FACTOR", Blockly.Python.ORDER_UNARY_SIGN)
        if (factor == "") {
            return ""
        }
        var DataFrame = Blockly.Python.valueToCode(a, "DATAFRAME", Blockly.Python.ORDER_UNARY_SIGN)
        if (factor != "" || DataFrame != "") {
            return [DataFrame + ".sample(frac=" + factor + ", replace=True, random_state=123)", Blockly.Python.ORDER_ATOMIC];
        }
    }


    Blockly.Python['pandas_select_columns'] = function (a) {
        var columns = Blockly.Python.valueToCode(a, "COLUMN", Blockly.Python.ORDER_UNARY_SIGN)
        if (columns == "") {
            columns = "[]"
        }
        var DataFrame = Blockly.Python.valueToCode(a, "DATAFRAME", Blockly.Python.ORDER_UNARY_SIGN)
        return [DataFrame + "[" + columns + "]", Blockly.Python.ORDER_ATOMIC];
    }

    Blockly.Python['Classification_Report'] = function (a) {
        Blockly.Python.definitions_.classification_report = "from sklearn.metrics import classification_report";
        var Pred = Blockly.Python.valueToCode(a, "Pred", Blockly.Python.ORDER_UNARY_SIGN) || "";
        var True = Blockly.Python.valueToCode(a, "True", Blockly.Python.ORDER_UNARY_SIGN) || "";
        if ((Pred != "") && (True != "")) {
            return ["classification_report(" + True + ", " + Pred + ")", Blockly.Python.ORDER_FUNCTION_CALL];
        } else {
            return ["", Blockly.Python.ORDER_FUNCTION_CALL];
        }

    }
    Blockly.Python['R2_Report'] = function (a) {
        Blockly.Python.definitions_.r2_score = "from sklearn.metrics import r2_score";
        var Pred = Blockly.Python.valueToCode(a, "Pred", Blockly.Python.ORDER_UNARY_SIGN)
        var True = Blockly.Python.valueToCode(a, "True", Blockly.Python.ORDER_UNARY_SIGN)
        if ((Pred != "") && (True != "")) {
            return ["r2_score(" + True + ", " + Pred + ")", Blockly.Python.ORDER_FUNCTION_CALL];
        } else {
            return ["", Blockly.Python.ORDER_FUNCTION_CALL];
        }
    }
    Blockly.Python['Print'] = function (a) {
        var INPUT = Blockly.Python.valueToCode(a, "INPUT", Blockly.Python.ORDER_FUNCTION_CALL) || "''";
        var End = a.getFieldValue("END")

        if (End == "newLine") {
            return "print(" + INPUT + ")" + "\n";
        }
        if (End == "tab") {
            return "print(" + INPUT + ",end='\\t')" + "\n";
        }
        if (End == "space") {
            return "print(" + INPUT + ",end=' ')" + "\n";
        }
        if (End == "comma") {
            return "print(" + INPUT + ",end=',')" + "\n";
        }
    }

    Blockly.Python['pycaret_setup'] = function (a) {
        var input_data = Blockly.Python.valueToCode(a, "input_data", Blockly.Python.ORDER_NONE) || "";
        var input_column = Blockly.Python.valueToCode(a, "input_column", Blockly.Python.ORDER_NONE) || "";
        var algorithm = a.getFieldValue("algorithm");

        if (input_data == "") {
            return ""
        }
        if (algorithm == "Classification") {
            Blockly.Python.definitions_.pycaret_classification = "from pycaret.classification import *";
        }
        if (algorithm == "Regression") {
            Blockly.Python.definitions_.pycaret_regression = "from pycaret.regression import *";
        }
        return "setup(" + input_data + ", target = " + input_column + ")" + "\n";


    }
    Blockly.Python['pycaret_predict'] = function (a) {
        var input_model = Blockly.Python.valueToCode(a, "input_model", Blockly.Python.ORDER_NONE) || "";
        var input_data = Blockly.Python.valueToCode(a, "input_data", Blockly.Python.ORDER_NONE) || "";
        console.log(input_model)
        if (input_model == "") {
            return ["", Blockly.Python.ORDER_FUNCTION_CALL]
        }
        if (input_model != "" && input_data == "") {
            return ["predict_model(" + input_model + ")", Blockly.Python.ORDER_FUNCTION_CALL]
        }
        if (input_model != "" && input_data != "") {
            return ["predict_model(" + input_model + ", data=" + input_data + ")", Blockly.Python.ORDER_FUNCTION_CALL]
        }
    }
    Blockly.Python['pycaret_save'] = function (a) {

        var input_model = Blockly.Python.valueToCode(a, "input_model", Blockly.Python.ORDER_NONE) || "";
        var input_data = Blockly.Python.valueToCode(a, "input_data", Blockly.Python.ORDER_NONE) || "";
        if (input_model != "" || input_data != "") {
            return "save_model(" + input_model + "," + input_data + ")" + "\n";
        }
        else {
            return ""
        }
    }

    Blockly.Python['pycaret_plot_model'] = function (a) {

        var input_model = Blockly.Python.valueToCode(a, "input_model", Blockly.Python.ORDER_NONE) || "";
        var plot_data = a.getFieldValue("plot_data");
        if (input_model != "" || plot_data != "") {
            return "plot_model(" + input_model + ", plot = '" + plot_data + "')" + "\n";
        }
        else {
            return ""
        }
    }

    Blockly.Python['pycaret_blend_model'] = function (a) {
        var input_models = Blockly.Python.valueToCode(a, "input_models", Blockly.Python.ORDER_NONE) || "";
        var input_fold = Blockly.Python.valueToCode(a, "input_fold", Blockly.Python.ORDER_NONE) || "";
        var input_method = a.getFieldValue("input_method");
        if (input_models != "" && input_fold == "") {
            return ["blend_models(" + input_models + ", method = '" + input_method + "')", Blockly.Python.ORDER_FUNCTION_CALL]
        }
        if (input_models != "" && input_fold != "") {
            return ["blend_models(" + input_models + " , fold = '" + input_fold + "' , method = '" + input_method + "')", Blockly.Python.ORDER_FUNCTION_CALL]
        }
        else {
            return ""
        }
    }

    Blockly.Python['pycaret_ensemble_model'] = function (a) {
        var input_models = Blockly.Python.valueToCode(a, "input_models", Blockly.Python.ORDER_NONE) || "";
        var input_fold = Blockly.Python.valueToCode(a, "input_fold", Blockly.Python.ORDER_NONE) || "";
        var input_method = a.getFieldValue("input_method");
        if (input_models != "" && input_fold == "") {
            return ["ensemble_model(" + input_models + ", method = '" + input_method + "')", Blockly.Python.ORDER_FUNCTION_CALL]
        }
        if (input_models != "" && input_fold != "") {
            return ["ensemble_model(" + input_models + " , fold = '" + input_fold + "' , method = '" + input_method + "')", Blockly.Python.ORDER_FUNCTION_CALL]
        }
        else {
            return ""
        }
    }
    Blockly.Python['pycaret_load'] = function (a) {
        var input_model = Blockly.Python.valueToCode(a, "input_data", Blockly.Python.ORDER_NONE) || "";
        if (input_model != "") {
            return ["load_model(" + input_model + ")", Blockly.Python.ORDER_FUNCTION_CALL]

        }
        else {
            return ""
        }
    }
    Blockly.Python['pycaret_automl'] = function (a) {
        var optimizer = a.getFieldValue("optimizer");
        return ["automl(optimize = '" + optimizer + "')", Blockly.Python.ORDER_FUNCTION_CALL]
    }
    Blockly.Python['pycaret_classifier'] = function (a) {
        var model = a.getFieldValue("model");
        return ["create_model('" + model + "')", Blockly.Python.ORDER_FUNCTION_CALL]
    }
    Blockly.Python['pycaret_regressor'] = function (a) {
        var model = a.getFieldValue("model");
        return ["create_model('" + model + "')", Blockly.Python.ORDER_FUNCTION_CALL]
    }
    Blockly.Python['Input'] = function (a) {
        var INPUT = Blockly.Python.valueToCode(a, "INPUT", Blockly.Python.ORDER_NONE) || "''";
        return ["input(" + INPUT + ")", Blockly.Python.ORDER_FUNCTION_CALL]
    }
    Blockly.Python['pandas_set_columns'] = function (a) {
        var columns = Blockly.Python.valueToCode(a, "COLUMN", Blockly.Python.ORDER_UNARY_SIGN)
        if (columns == "") {
            columns = "[]"
        }
        var DATAFRAME_IN = Blockly.Python.valueToCode(a, "DATAFRAME_IN", Blockly.Python.ORDER_UNARY_SIGN)
        var DATAFRAME_OUT = Blockly.Python.valueToCode(a, "DATAFRAME_OUT", Blockly.Python.ORDER_UNARY_SIGN)
        if (DATAFRAME_IN != "" || DATAFRAME_OUT != "" || columns != "") {
            return DATAFRAME_OUT + "[" + columns + "]=" + DATAFRAME_IN + "\n";
        }
        else {
            return ""
        }
    }




    Blockly.Python['dataframe_Filter'] = function (a) {
        var b = { EQ: "==", NEQ: "!=", LT: "<", LTE: "<=", GT: ">", GTE: ">=" }[a.getFieldValue("OP")];
        var c = Blockly.Python.ORDER_RELATIONAL;
        var d = Blockly.Python.valueToCode(a, "A", c) || "";
        var e = Blockly.Python.valueToCode(a, "C", c) || "";
        a = Blockly.Python.valueToCode(a, "B", c) || "";
        if (d == "" || e == "" || a == "") {
            return ["", Blockly.Python.ORDER_NONE]
        }

        return [e + "[" + d + " " + b + " " + a + "]", Blockly.Python.ORDER_FUNCTION_CALL];
    };


    Blockly.Python['dataframe_Map'] = function (a) {
        var c = Blockly.Python.ORDER_NONE;
        var b = Blockly.Python.valueToCode(a, "Map", c) || "";
        var d = Blockly.Python.valueToCode(a, "Series", c) || "";
        if (b == "" || d == "") {
            return ["", Blockly.Python.ORDER_NONE]
        }

        return [d + ".map(" + b + ")", Blockly.Python.ORDER_ATOMIC];
    };


    Blockly.Python['CLR_XGBoost'] = function (a) {
        Blockly.Python.definitions_.XGBClassifier = "from xgboost import XGBClassifier";
        var codeString = ""

        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += "XGBClassifier(**" + Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) + ")"
        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += "XGBClassifier()"
        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ")"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) != "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE)
                + ", eval_set = [(" + Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) + ")"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE)
                + ".predict("
                + Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) + ")"


        }
        return ([codeString, Blockly.Python.ORDER_FUNCTION_CALL])

    }

    Blockly.Python['REG_LinearRegression'] = function (a) {
        Blockly.Python.definitions_.LinearRegression = "from sklearn.linear_model import LinearRegression";

        var HandleCatagoricalData = Blockly.Python.provideFunction_("REG_LinearRegression", [
            'class HandleCatagoricalData():\n' +
            '   def __init__(self,method="labelEncoding",factor=0):\n' +
            '       self.method = method\n' +
            '       self.factor = factor\n' +
            '   def fit(self, X, y):\n' +
            '       if self.method == "labelEncoding":\n' +
            '         X = pd.DataFrame(data=X)\n' +
            '         y = pd.DataFrame(data=y)\n' +
            '         self.LE = LabelEncoder()\n' +
            '         for column in X:\n' +
            '           if X[column].dtype == np.object:\n' +
            '             X[column]=X[column].astype("category")\n' +
            '           if X[column].dtype.name == "category":\n' +
            '             X[column] = self.LE.fit_transform(X[column])\n' +
            '         X = X.to_numpy()\n' +
            '         y = y.to_numpy()\n' +
            '         return self\n' +
            '   def transform(self, X):\n' +
            '       X = pd.DataFrame(data=X)\n' +
            '       for column in X:\n' +
            '         if X[column].dtype == np.object:\n' +
            '           X[column]=X[column].astype("category")\n' +
            '         if X[column].dtype.name == "category":\n' +
            '           X[column] = self.LE.fit_transform(X[column])\n' +
            '       X = X.to_numpy()\n' +
            '       return X\n'
        ])

        var codeString = ""
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += "Pipeline([('encoding', HandleCatagoricalData('labelEncoding')), ('scaler', StandardScaler()), ('LR', LinearRegression(**" + Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) + "))])"
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"
        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += 'Pipeline([("encoding", HandleCatagoricalData("labelEncoding")), ("scaler", StandardScaler()), ("LR", LinearRegression())])'
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"

        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ")"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) != "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE)
                + ", eval_set = [(" + Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) + ")"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE)
                + ".predict("
                + Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) + ")"


        }
        return ([codeString, Blockly.Python.ORDER_FUNCTION_CALL])

    }

    Blockly.Python['REG_XGBRegressor'] = function (a) {
        Blockly.Python.definitions_.XGBRegressor = "from xgboost import XGBRegressor";

        var HandleCatagoricalData = Blockly.Python.provideFunction_("REG_XGBRegressor", [
            'class HandleCatagoricalData():\n' +
            '   def __init__(self,method="labelEncoding",factor=0):\n' +
            '       self.method = method\n' +
            '       self.factor = factor\n' +
            '   def fit(self, X, y):\n' +
            '       if self.method == "labelEncoding":\n' +
            '         X = pd.DataFrame(data=X)\n' +
            '         y = pd.DataFrame(data=y)\n' +
            '         self.LE = LabelEncoder()\n' +
            '         for column in X:\n' +
            '           if X[column].dtype == np.object:\n' +
            '             X[column]=X[column].astype("category")\n' +
            '           if X[column].dtype.name == "category":\n' +
            '             X[column] = self.LE.fit_transform(X[column])\n' +
            '         X = X.to_numpy()\n' +
            '         y = y.to_numpy()\n' +
            '         return self\n' +
            '   def transform(self, X):\n' +
            '       X = pd.DataFrame(data=X)\n' +
            '       for column in X:\n' +
            '         if X[column].dtype == np.object:\n' +
            '           X[column]=X[column].astype("category")\n' +
            '         if X[column].dtype.name == "category":\n' +
            '           X[column] = self.LE.fit_transform(X[column])\n' +
            '       X = X.to_numpy()\n' +
            '       return X\n'
        ])


        var codeString = ""
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += "Pipeline([('encoding', HandleCatagoricalData('labelEncoding')), ('scaler', StandardScaler()), ('XGB', XGBRegressor(**" + Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) + "))])"
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"
        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += 'Pipeline([("encoding", HandleCatagoricalData("labelEncoding")), ("scaler", StandardScaler()), ("XGB", XGBRegressor())])'
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"

        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ")"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) != "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE)
                + ", eval_set = [(" + Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) + ")"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE)
                + ".predict("
                + Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) + ")"


        }
        return ([codeString, Blockly.Python.ORDER_FUNCTION_CALL])

    }
    Blockly.Python['CLR_LogisticRegression'] = function (a) {
        Blockly.Python.definitions_.LogisticRegression = "from sklearn.linear_model import LogisticRegression";

        var HandleCatagoricalData = Blockly.Python.provideFunction_("CLR_LogisticRegression", [
            'class HandleCatagoricalData():\n' +
            '   def __init__(self,method="labelEncoding",factor=0):\n' +
            '       self.method = method\n' +
            '       self.factor = factor\n' +
            '   def fit(self, X, y):\n' +
            '       if self.method == "labelEncoding":\n' +
            '         X = pd.DataFrame(data=X)\n' +
            '         y = pd.DataFrame(data=y)\n' +
            '         self.LE = LabelEncoder()\n' +
            '         for column in X:\n' +
            '           if X[column].dtype == np.object:\n' +
            '             X[column]=X[column].astype("category")\n' +
            '           if X[column].dtype.name == "category":\n' +
            '             X[column] = self.LE.fit_transform(X[column])\n' +
            '         X = X.to_numpy()\n' +
            '         y = y.to_numpy()\n' +
            '         return self\n' +
            '   def transform(self, X):\n' +
            '       X = pd.DataFrame(data=X)\n' +
            '       for column in X:\n' +
            '         if X[column].dtype == np.object:\n' +
            '           X[column]=X[column].astype("category")\n' +
            '         if X[column].dtype.name == "category":\n' +
            '           X[column] = self.LE.fit_transform(X[column])\n' +
            '       X = X.to_numpy()\n' +
            '       return X\n'
        ])
        var codeString = ""

        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += 'Pipeline([("encoding", HandleCatagoricalData("labelEncoding")), ("scaler", StandardScaler()), ("LR",LogisticRegression(**' + Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) + '))])'
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"
        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += 'Pipeline([("encoding", HandleCatagoricalData("labelEncoding")), ("scaler", StandardScaler()), ("LR", LogisticRegression())])'
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"
        }

        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ")"

        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) != "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ") # Eval TBD"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE)
                + ".predict("
                + Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) + ")"


        }
        return ([codeString, Blockly.Python.ORDER_FUNCTION_CALL])

    }


    Blockly.Python['CLR_NaiveBayes'] = function (a) {
        Blockly.Python.definitions_.GaussianNB = "from sklearn.naive_bayes import GaussianNB";

        var HandleCatagoricalData = Blockly.Python.provideFunction_("CLR_NaiveBayes", [
            'class HandleCatagoricalData():\n' +
            '   def __init__(self,method="labelEncoding",factor=0):\n' +
            '       self.method = method\n' +
            '       self.factor = factor\n' +
            '   def fit(self, X, y):\n' +
            '       if self.method == "labelEncoding":\n' +
            '         X = pd.DataFrame(data=X)\n' +
            '         y = pd.DataFrame(data=y)\n' +
            '         self.LE = LabelEncoder()\n' +
            '         for column in X:\n' +
            '           if X[column].dtype == np.object:\n' +
            '             X[column]=X[column].astype("category")\n' +
            '           if X[column].dtype.name == "category":\n' +
            '             X[column] = self.LE.fit_transform(X[column])\n' +
            '         X = X.to_numpy()\n' +
            '         y = y.to_numpy()\n' +
            '         return self\n' +
            '   def transform(self, X):\n' +
            '       X = pd.DataFrame(data=X)\n' +
            '       for column in X:\n' +
            '         if X[column].dtype == np.object:\n' +
            '           X[column]=X[column].astype("category")\n' +
            '         if X[column].dtype.name == "category":\n' +
            '           X[column] = self.LE.fit_transform(X[column])\n' +
            '       X = X.to_numpy()\n' +
            '       return X\n'
        ])

        var codeString = ""

        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += 'Pipeline([("encoding", HandleCatagoricalData("labelEncoding")), ("scaler", StandardScaler()), ("GNB",GaussianNB())])'
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"
        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += 'Pipeline([("encoding", HandleCatagoricalData("labelEncoding")), ("scaler", StandardScaler()), ("GNB",GaussianNB(**' + Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) + "))])"
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"
        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ")"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) != "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ") # Eval TBD"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE)
                + ".predict("
                + Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) + ")"


        }
        return [codeString, Blockly.Python.ORDER_FUNCTION_CALL]

    }
    Blockly.Python['CLR_KNN'] = function (a) {
        Blockly.Python.definitions_.KNeighborsClassifier = "from sklearn.neighbors import KNeighborsClassifier";


        var HandleCatagoricalData = Blockly.Python.provideFunction_("CLR_KNN", [
            'class HandleCatagoricalData():\n' +
            '   def __init__(self,method="labelEncoding",factor=0):\n' +
            '       self.method = method\n' +
            '       self.factor = factor\n' +
            '   def fit(self, X, y):\n' +
            '       if self.method == "labelEncoding":\n' +
            '         X = pd.DataFrame(data=X)\n' +
            '         y = pd.DataFrame(data=y)\n' +
            '         self.LE = LabelEncoder()\n' +
            '         for column in X:\n' +
            '           if X[column].dtype == np.object:\n' +
            '             X[column]=X[column].astype("category")\n' +
            '           if X[column].dtype.name == "category":\n' +
            '             X[column] = self.LE.fit_transform(X[column])\n' +
            '         X = X.to_numpy()\n' +
            '         y = y.to_numpy()\n' +
            '         return self\n' +
            '   def transform(self, X):\n' +
            '       X = pd.DataFrame(data=X)\n' +
            '       for column in X:\n' +
            '         if X[column].dtype == np.object:\n' +
            '           X[column]=X[column].astype("category")\n' +
            '         if X[column].dtype.name == "category":\n' +
            '           X[column] = self.LE.fit_transform(X[column])\n' +
            '       X = X.to_numpy()\n' +
            '       return X\n'
        ])

        var codeString = ""

        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += 'Pipeline([("encoding", HandleCatagoricalData("labelEncoding")), ("scaler", StandardScaler()), ("KNN",KNeighborsClassifier())])'
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"
        }

        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += 'Pipeline([("encoding", HandleCatagoricalData("labelEncoding")), ("scaler", StandardScaler()), ("KNN",KNeighborsClassifier(**' + Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) + "))])"
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"
        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ")"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) != "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ") # Eval TBD"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE)
                + ".predict("
                + Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) + ")"


        }
        return [codeString, Blockly.Python.ORDER_FUNCTION_CALL]

    }
    Blockly.Python['CLR_DecisionTree'] = function (a) {
        Blockly.Python.definitions_.tree = "from sklearn import tree";

        var HandleCatagoricalData = Blockly.Python.provideFunction_("CLR_DecisionTree", [
            'class HandleCatagoricalData():\n' +
            '   def __init__(self,method="labelEncoding",factor=0):\n' +
            '       self.method = method\n' +
            '       self.factor = factor\n' +
            '   def fit(self, X, y):\n' +
            '       if self.method == "labelEncoding":\n' +
            '         X = pd.DataFrame(data=X)\n' +
            '         y = pd.DataFrame(data=y)\n' +
            '         self.LE = LabelEncoder()\n' +
            '         for column in X:\n' +
            '           if X[column].dtype == np.object:\n' +
            '             X[column]=X[column].astype("category")\n' +
            '           if X[column].dtype.name == "category":\n' +
            '             X[column] = self.LE.fit_transform(X[column])\n' +
            '         X = X.to_numpy()\n' +
            '         y = y.to_numpy()\n' +
            '         return self\n' +
            '   def transform(self, X):\n' +
            '       X = pd.DataFrame(data=X)\n' +
            '       for column in X:\n' +
            '         if X[column].dtype == np.object:\n' +
            '           X[column]=X[column].astype("category")\n' +
            '         if X[column].dtype.name == "category":\n' +
            '           X[column] = self.LE.fit_transform(X[column])\n' +
            '       X = X.to_numpy()\n' +
            '       return X\n'
        ])


        var codeString = ""

        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += 'Pipeline([("encoding", HandleCatagoricalData("labelEncoding")), ("scaler", StandardScaler()), ("Dtree",tree.DecisionTreeClassifier(**' + Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) + "))])"
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"
        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += 'Pipeline([("encoding", HandleCatagoricalData("labelEncoding")), ("scaler", StandardScaler()), ("Dtree",tree.DecisionTreeClassifier())])'
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"
        }

        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ")"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) != "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ") # Eval TBD"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE)
                + ".predict("
                + Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) + ")"


        }
        return [codeString, Blockly.Python.ORDER_FUNCTION_CALL]

    }
    Blockly.Python['CLR_SVM'] = function (a) {
        Blockly.Python.definitions_.SVC = "from sklearn.svm import SVC";

        var HandleCatagoricalData = Blockly.Python.provideFunction_("CLR_SVM", [
            'class HandleCatagoricalData():\n' +
            '   def __init__(self,method="labelEncoding",factor=0):\n' +
            '       self.method = method\n' +
            '       self.factor = factor\n' +
            '   def fit(self, X, y):\n' +
            '       if self.method == "labelEncoding":\n' +
            '         X = pd.DataFrame(data=X)\n' +
            '         y = pd.DataFrame(data=y)\n' +
            '         self.LE = LabelEncoder()\n' +
            '         for column in X:\n' +
            '           if X[column].dtype == np.object:\n' +
            '             X[column]=X[column].astype("category")\n' +
            '           if X[column].dtype.name == "category":\n' +
            '             X[column] = self.LE.fit_transform(X[column])\n' +
            '         X = X.to_numpy()\n' +
            '         y = y.to_numpy()\n' +
            '         return self\n' +
            '   def transform(self, X):\n' +
            '       X = pd.DataFrame(data=X)\n' +
            '       for column in X:\n' +
            '         if X[column].dtype == np.object:\n' +
            '           X[column]=X[column].astype("category")\n' +
            '         if X[column].dtype.name == "category":\n' +
            '           X[column] = self.LE.fit_transform(X[column])\n' +
            '       X = X.to_numpy()\n' +
            '       return X\n'
        ])

        var codeString = ""

        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += 'Pipeline([("encoding", HandleCatagoricalData("labelEncoding")), ("scaler", StandardScaler()), ("SVC", SVC(gamma="auto"))])'
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"

        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += 'Pipeline([("encoding", HandleCatagoricalData("labelEncoding")), ("scaler", StandardScaler()), ("SVC", SVC(gamma="auto"))])'
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"
        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ")"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) != "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ") # Eval TBD"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE)
                + ".predict("
                + Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) + ")"


        }
        return [codeString, Blockly.Python.ORDER_FUNCTION_CALL]

    }

    Blockly.Python['CLR_RandomForest'] = function (a) {
        Blockly.Python.definitions_.RandomForestClassifier = "from sklearn.ensemble import RandomForestClassifier";

        var HandleCatagoricalData = Blockly.Python.provideFunction_("CLR_RandomForest", [
            'class HandleCatagoricalData():\n' +
            '   def __init__(self,method="labelEncoding",factor=0):\n' +
            '       self.method = method\n' +
            '       self.factor = factor\n' +
            '   def fit(self, X, y):\n' +
            '       if self.method == "labelEncoding":\n' +
            '         X = pd.DataFrame(data=X)\n' +
            '         y = pd.DataFrame(data=y)\n' +
            '         self.LE = LabelEncoder()\n' +
            '         for column in X:\n' +
            '           if X[column].dtype == np.object:\n' +
            '             X[column]=X[column].astype("category")\n' +
            '           if X[column].dtype.name == "category":\n' +
            '             X[column] = self.LE.fit_transform(X[column])\n' +
            '         X = X.to_numpy()\n' +
            '         y = y.to_numpy()\n' +
            '         return self\n' +
            '   def transform(self, X):\n' +
            '       X = pd.DataFrame(data=X)\n' +
            '       for column in X:\n' +
            '         if X[column].dtype == np.object:\n' +
            '           X[column]=X[column].astype("category")\n' +
            '         if X[column].dtype.name == "category":\n' +
            '           X[column] = self.LE.fit_transform(X[column])\n' +
            '       X = X.to_numpy()\n' +
            '       return X\n'
        ])

        var codeString = ""

        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += 'Pipeline([("encoding", HandleCatagoricalData("labelEncoding")), ("scaler", StandardScaler()), ("RFC", RandomForestClassifier())])'
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"
        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += 'Pipeline([("encoding", HandleCatagoricalData("labelEncoding")), ("scaler", StandardScaler()), ("RFC", RandomForestClassifier(**' + Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) + ')'
            Blockly.Python.definitions_.pipeline = "from sklearn.pipeline import Pipeline"
            Blockly.Python.definitions_.StandardScaler = "from sklearn.preprocessing import StandardScaler"
        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ")"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) != "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) + ".fit(" + Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE)
                + "," + Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) + ") # Eval TBD"


        }
        if (Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) != "" &&
            Blockly.Python.valueToCode(a, "PARAMS", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YTRAIN", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "XVALID", Blockly.Python.ORDER_NONE) == "" &&
            Blockly.Python.valueToCode(a, "YVALID", Blockly.Python.ORDER_NONE) == "") {
            codeString += Blockly.Python.valueToCode(a, "TMODEL", Blockly.Python.ORDER_NONE)
                + ".predict("
                + Blockly.Python.valueToCode(a, "XTEST", Blockly.Python.ORDER_NONE) + ")"


        }



        return [codeString, Blockly.Python.ORDER_FUNCTION_CALL]

    }

    Blockly.Python.math = {};
    Blockly.Python.addReservedWords("math,random,Number");
    Blockly.Python.math_number = function (a) {
        a = Number(a.getFieldValue("NUM"));

        if (Infinity == a) {
            a = 'float("inf")';
            var b = Blockly.Python.ORDER_FUNCTION_CALL;
        } else -Infinity == a ? ((a = '-float("inf")'), (b = Blockly.Python.ORDER_UNARY_SIGN)) : (b = 0 > a ? Blockly.Python.ORDER_UNARY_SIGN : Blockly.Python.ORDER_ATOMIC);
        return [a, b];
    };
    Blockly.Python.math_arithmetic = function (a) {
        var b = {
            ADD: [" + ", Blockly.Python.ORDER_ADDITIVE],
            MINUS: [" - ", Blockly.Python.ORDER_ADDITIVE],
            MULTIPLY: [" * ", Blockly.Python.ORDER_MULTIPLICATIVE],
            DIVIDE: [" / ", Blockly.Python.ORDER_MULTIPLICATIVE],
            POWER: [" ** ", Blockly.Python.ORDER_EXPONENTIATION],
        }[a.getFieldValue("OP")],
            c = b[0];
        b = b[1];
        var d = Blockly.Python.valueToCode(a, "A", b) || "0";
        a = Blockly.Python.valueToCode(a, "B", b) || "0";
        return [d + c + a, b];
    };
    Blockly.Python.math_single = function (a) {
        var b = a.getFieldValue("OP");
        if ("NEG" == b) {
            var c = Blockly.Python.valueToCode(a, "NUM", Blockly.Python.ORDER_UNARY_SIGN) || "0";
            return ["-" + c, Blockly.Python.ORDER_UNARY_SIGN];
        }
        Blockly.Python.definitions_.import_math = "import math";
        a = "SIN" == b || "COS" == b || "TAN" == b ? Blockly.Python.valueToCode(a, "NUM", Blockly.Python.ORDER_MULTIPLICATIVE) || "0" : Blockly.Python.valueToCode(a, "NUM", Blockly.Python.ORDER_NONE) || "0";
        switch (b) {
            case "ABS":
                c = "math.fabs(" + a + ")";
                break;
            case "ROOT":
                c = "math.sqrt(" + a + ")";
                break;
            case "LN":
                c = "math.log(" + a + ")";
                break;
            case "LOG10":
                c = "math.log10(" + a + ")";
                break;
            case "EXP":
                c = "math.exp(" + a + ")";
                break;
            case "POW10":
                c = "math.pow(10," + a + ")";
                break;
            case "ROUND":
                c = "round(" + a + ")";
                break;
            case "ROUNDUP":
                c = "math.ceil(" + a + ")";
                break;
            case "ROUNDDOWN":
                c = "math.floor(" + a + ")";
                break;
            case "SIN":
                c = "math.sin(" + a + " / 180.0 * math.pi)";
                break;
            case "COS":
                c = "math.cos(" + a + " / 180.0 * math.pi)";
                break;
            case "TAN":
                c = "math.tan(" + a + " / 180.0 * math.pi)";
        }
        if (c) return [c, Blockly.Python.ORDER_FUNCTION_CALL];
        switch (b) {
            case "ASIN":
                c = "math.asin(" + a + ") / math.pi * 180";
                break;
            case "ACOS":
                c = "math.acos(" + a + ") / math.pi * 180";
                break;
            case "ATAN":
                c = "math.atan(" + a + ") / math.pi * 180";
                break;
            default:
                throw Error("Unknown math operator: " + b);
        }
        return [c, Blockly.Python.ORDER_MULTIPLICATIVE];
    };
    Blockly.Python.math_constant = function (a) {
        var b = {
            PI: ["math.pi", Blockly.Python.ORDER_MEMBER],
            E: ["math.e", Blockly.Python.ORDER_MEMBER],
            GOLDEN_RATIO: ["(1 + math.sqrt(5)) / 2", Blockly.Python.ORDER_MULTIPLICATIVE],
            SQRT2: ["math.sqrt(2)", Blockly.Python.ORDER_MEMBER],
            SQRT1_2: ["math.sqrt(1.0 / 2)", Blockly.Python.ORDER_MEMBER],
            INFINITY: ["float('inf')", Blockly.Python.ORDER_ATOMIC],
        };
        a = a.getFieldValue("CONSTANT");
        "INFINITY" != a && (Blockly.Python.definitions_.import_math = "import math");
        return b[a];
    };
    Blockly.Python.math_number_property = function (a) {
        var b = Blockly.Python.valueToCode(a, "NUMBER_TO_CHECK", Blockly.Python.ORDER_MULTIPLICATIVE) || "0",
            c = a.getFieldValue("PROPERTY");
        if ("PRIME" == c)
            return (
                (Blockly.Python.definitions_.import_math = "import math"),
                (Blockly.Python.definitions_.from_numbers_import_Number = "from numbers import Number"),
                [
                    Blockly.Python.provideFunction_("math_isPrime", [
                        "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(n):",
                        "  # https://en.wikipedia.org/wiki/Primality_test#Naive_methods",
                        "  # If n is not a number but a string, try parsing it.",
                        "  if not isinstance(n, Number):",
                        "    try:",
                        "      n = float(n)",
                        "    except:",
                        "      return False",
                        "  if n == 2 or n == 3:",
                        "    return True",
                        "  # False if n is negative, is 1, or not whole, or if n is divisible by 2 or 3.",
                        "  if n <= 1 or n % 1 != 0 or n % 2 == 0 or n % 3 == 0:",
                        "    return False",
                        "  # Check all the numbers of form 6k +/- 1, up to sqrt(n).",
                        "  for x in range(6, int(math.sqrt(n)) + 2, 6):",
                        "    if n % (x - 1) == 0 or n % (x + 1) == 0:",
                        "      return False",
                        "  return True",
                    ]) +
                    "(" +
                    b +
                    ")",
                    Blockly.Python.ORDER_FUNCTION_CALL,
                ]
            );
        switch (c) {
            case "EVEN":
                var d = b + " % 2 == 0";
                break;
            case "ODD":
                d = b + " % 2 == 1";
                break;
            case "WHOLE":
                d = b + " % 1 == 0";
                break;
            case "POSITIVE":
                d = b + " > 0";
                break;
            case "NEGATIVE":
                d = b + " < 0";
                break;
            case "DIVISIBLE_BY":
                a = Blockly.Python.valueToCode(a, "DIVISOR", Blockly.Python.ORDER_MULTIPLICATIVE);
                if (!a || "0" == a) return ["False", Blockly.Python.ORDER_ATOMIC];
                d = b + " % " + a + " == 0";
        }
        return [d, Blockly.Python.ORDER_RELATIONAL];
    };
    Blockly.Python.math_change = function (a) {
        Blockly.Python.definitions_.from_numbers_import_Number = "from numbers import Number";
        var b = Blockly.Python.valueToCode(a, "DELTA", Blockly.Python.ORDER_ADDITIVE) || "0";
        a = Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME);
        return a + " = (" + a + " if isinstance(" + a + ", Number) else 0) + " + b + "\n";
    };
    Blockly.Python.math_round = Blockly.Python.math_single;
    Blockly.Python.math_trig = Blockly.Python.math_single;
    Blockly.Python.math_on_list = function (a) {
        var b = a.getFieldValue("OP");
        a = Blockly.Python.valueToCode(a, "LIST", Blockly.Python.ORDER_NONE) || "[]";
        switch (b) {
            case "SUM":
                b = "sum(" + a + ")";
                break;
            case "MIN":
                b = "min(" + a + ")";
                break;
            case "MAX":
                b = "max(" + a + ")";
                break;
            case "AVERAGE":
                Blockly.Python.definitions_.from_numbers_import_Number = "from numbers import Number";
                b = Blockly.Python.provideFunction_("math_mean", [
                    "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(myList):",
                    "  localList = [e for e in myList if isinstance(e, Number)]",
                    "  if not localList: return",
                    "  return float(sum(localList)) / len(localList)",
                ]);
                b = b + "(" + a + ")";
                break;
            case "MEDIAN":
                Blockly.Python.definitions_.from_numbers_import_Number = "from numbers import Number";
                b = Blockly.Python.provideFunction_("math_median", [
                    "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(myList):",
                    "  localList = sorted([e for e in myList if isinstance(e, Number)])",
                    "  if not localList: return",
                    "  if len(localList) % 2 == 0:",
                    "    return (localList[len(localList) // 2 - 1] + localList[len(localList) // 2]) / 2.0",
                    "  else:",
                    "    return localList[(len(localList) - 1) // 2]",
                ]);
                b = b + "(" + a + ")";
                break;
            case "MODE":
                b = Blockly.Python.provideFunction_("math_modes", [
                    "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(some_list):",
                    "  modes = []",
                    "  # Using a lists of [item, count] to keep count rather than dict",
                    '  # to avoid "unhashable" errors when the counted item is itself a list or dict.',
                    "  counts = []",
                    "  maxCount = 1",
                    "  for item in some_list:",
                    "    found = False",
                    "    for count in counts:",
                    "      if count[0] == item:",
                    "        count[1] += 1",
                    "        maxCount = max(maxCount, count[1])",
                    "        found = True",
                    "    if not found:",
                    "      counts.append([item, 1])",
                    "  for counted_item, item_count in counts:",
                    "    if item_count == maxCount:",
                    "      modes.append(counted_item)",
                    "  return modes",
                ]);
                b = b + "(" + a + ")";
                break;
            case "STD_DEV":
                Blockly.Python.definitions_.import_math = "import math";
                b = Blockly.Python.provideFunction_("math_standard_deviation", [
                    "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(numbers):",
                    "  n = len(numbers)",
                    "  if n == 0: return",
                    "  mean = float(sum(numbers)) / n",
                    "  variance = sum((x - mean) ** 2 for x in numbers) / n",
                    "  return math.sqrt(variance)",
                ]);
                b = b + "(" + a + ")";
                break;
            case "RANDOM":
                Blockly.Python.definitions_.import_random = "import random";
                b = "random.choice(" + a + ")";
                break;
            default:
                throw Error("Unknown operator: " + b);
        }
        return [b, Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.math_modulo = function (a) {
        var b = Blockly.Python.valueToCode(a, "DIVIDEND", Blockly.Python.ORDER_MULTIPLICATIVE) || "0";
        a = Blockly.Python.valueToCode(a, "DIVISOR", Blockly.Python.ORDER_MULTIPLICATIVE) || "0";
        return [b + " % " + a, Blockly.Python.ORDER_MULTIPLICATIVE];
    };
    Blockly.Python.math_constrain = function (a) {
        var b = Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "0",
            c = Blockly.Python.valueToCode(a, "LOW", Blockly.Python.ORDER_NONE) || "0";
        a = Blockly.Python.valueToCode(a, "HIGH", Blockly.Python.ORDER_NONE) || "float('inf')";
        return ["min(max(" + b + ", " + c + "), " + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.math_random_int = function (a) {
        Blockly.Python.definitions_.import_random = "import random";
        var b = Blockly.Python.valueToCode(a, "FROM", Blockly.Python.ORDER_NONE) || "0";
        a = Blockly.Python.valueToCode(a, "TO", Blockly.Python.ORDER_NONE) || "0";
        return ["random.randint(" + b + ", " + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.math_random_float = function (a) {
        Blockly.Python.definitions_.import_random = "import random";
        return ["random.random()", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.math_atan2 = function (a) {
        Blockly.Python.definitions_.import_math = "import math";
        var b = Blockly.Python.valueToCode(a, "X", Blockly.Python.ORDER_NONE) || "0";
        return ["math.atan2(" + (Blockly.Python.valueToCode(a, "Y", Blockly.Python.ORDER_NONE) || "0") + ", " + b + ") / math.pi * 180", Blockly.Python.ORDER_MULTIPLICATIVE];
    };
    Blockly.Python.procedures = {};
    Blockly.Python.procedures_defreturn = function (a) {
        for (var b = [], c, d = a.workspace, e = Blockly.Variables.allUsedVarModels(d) || [], f = 0; (c = e[f]); f++)
            (c = c.name), -1 == a.getVars().indexOf(c) && b.push(Blockly.Python.variableDB_.getName(c, Blockly.VARIABLE_CATEGORY_NAME));
        e = Blockly.Variables.allDeveloperVariables(d);
        for (f = 0; f < e.length; f++) b.push(Blockly.Python.variableDB_.getName(e[f], Blockly.Names.DEVELOPER_VARIABLE_TYPE));
        b = b.length ? Blockly.Python.INDENT + "global " + b.join(", ") + "\n" : "";
        d = Blockly.Python.variableDB_.getName(a.getFieldValue("NAME"), Blockly.PROCEDURE_CATEGORY_NAME);
        c = "";
        Blockly.Python.STATEMENT_PREFIX && (c += Blockly.Python.injectId(Blockly.Python.STATEMENT_PREFIX, a));
        Blockly.Python.STATEMENT_SUFFIX && (c += Blockly.Python.injectId(Blockly.Python.STATEMENT_SUFFIX, a));
        c && (c = Blockly.Python.prefixLines(c, Blockly.Python.INDENT));
        var n = "";
        Blockly.Python.INFINITE_LOOP_TRAP && (n = Blockly.Python.prefixLines(Blockly.Python.injectId(Blockly.Python.INFINITE_LOOP_TRAP, a), Blockly.Python.INDENT));
        var k = Blockly.Python.statementToCode(a, "STACK"),
            h = Blockly.Python.valueToCode(a, "RETURN", Blockly.Python.ORDER_NONE) || "",
            m = "";
        k && h && (m = c);
        h ? (h = Blockly.Python.INDENT + "return " + h + "\n") : k || (k = Blockly.Python.PASS);
        var g = [];
        e = a.getVars();
        for (f = 0; f < e.length; f++) g[f] = Blockly.Python.variableDB_.getName(e[f], Blockly.VARIABLE_CATEGORY_NAME);
        b = "def " + d + "(" + g.join(", ") + "):\n" + b + c + n + k + m + h;
        b = Blockly.Python.scrub_(a, b);
        Blockly.Python.definitions_["%" + d] = b;
        return null;
    };
    Blockly.Python.procedures_defnoreturn = Blockly.Python.procedures_defreturn;
    Blockly.Python.procedures_callreturn = function (a) {
        for (var b = Blockly.Python.variableDB_.getName(a.getFieldValue("NAME"), Blockly.PROCEDURE_CATEGORY_NAME), c = [], d = a.getVars(), e = 0; e < d.length; e++)
            c[e] = Blockly.Python.valueToCode(a, "ARG" + e, Blockly.Python.ORDER_NONE) || "None";
        return [b + "(" + c.join(", ") + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.procedures_callnoreturn = function (a) {
        return Blockly.Python.procedures_callreturn(a)[0] + "\n";
    };
    Blockly.Python.procedures_ifreturn = function (a) {
        var b = "if " + (Blockly.Python.valueToCode(a, "CONDITION", Blockly.Python.ORDER_NONE) || "False") + ":\n";
        Blockly.Python.STATEMENT_SUFFIX && (b += Blockly.Python.prefixLines(Blockly.Python.injectId(Blockly.Python.STATEMENT_SUFFIX, a), Blockly.Python.INDENT));
        a.hasReturnValue_ ? ((a = Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "None"), (b += Blockly.Python.INDENT + "return " + a + "\n")) : (b += Blockly.Python.INDENT + "return\n");
        return b;
    };
    Blockly.Python.texts = {};
    Blockly.Python.text = function (a) {
        return [Blockly.Python.quote_(a.getFieldValue("TEXT")), Blockly.Python.ORDER_ATOMIC];
    };
    Blockly.Python.text_multiline = function (a) {
        a = Blockly.Python.multiline_quote_(a.getFieldValue("TEXT"));
        var b = -1 != a.indexOf("+") ? Blockly.Python.ORDER_ADDITIVE : Blockly.Python.ORDER_ATOMIC;
        return [a, b];
    };
    Blockly.Python.text.forceString_ = function (a) {
        return Blockly.Python.text.forceString_.strRegExp.test(a) ? [a, Blockly.Python.ORDER_ATOMIC] : ["str(" + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.text.forceString_.strRegExp = /^\s*'([^']|\\')*'\s*$/;
    Blockly.Python.text_join = function (a) {
        switch (a.itemCount_) {
            case 0:
                return ["''", Blockly.Python.ORDER_ATOMIC];
            case 1:
                return (a = Blockly.Python.valueToCode(a, "ADD0", Blockly.Python.ORDER_NONE) || "''"), Blockly.Python.text.forceString_(a);
            case 2:
                var b = Blockly.Python.valueToCode(a, "ADD0", Blockly.Python.ORDER_NONE) || "''";
                a = Blockly.Python.valueToCode(a, "ADD1", Blockly.Python.ORDER_NONE) || "''";
                a = Blockly.Python.text.forceString_(b)[0] + " + " + Blockly.Python.text.forceString_(a)[0];
                return [a, Blockly.Python.ORDER_ADDITIVE];
            default:
                b = [];
                for (var c = 0; c < a.itemCount_; c++) b[c] = Blockly.Python.valueToCode(a, "ADD" + c, Blockly.Python.ORDER_NONE) || "''";
                a = Blockly.Python.variableDB_.getDistinctName("x", Blockly.VARIABLE_CATEGORY_NAME);
                a = "''.join([str(" + a + ") for " + a + " in [" + b.join(", ") + "]])";
                return [a, Blockly.Python.ORDER_FUNCTION_CALL];
        }
    };
    Blockly.Python.text_append = function (a) {
        var b = Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME);
        a = Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_NONE) || "''";
        return b + " = str(" + b + ") + " + Blockly.Python.text.forceString_(a)[0] + "\n";
    };
    Blockly.Python.text_length = function (a) {
        return ["len(" + (Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "''") + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.text_isEmpty = function (a) {
        return ["not len(" + (Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "''") + ")", Blockly.Python.ORDER_LOGICAL_NOT];
    };
    Blockly.Python.text_isEmpty2 = function (a) {
        return ["not len(" + (Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "''") + ")x", Blockly.Python.ORDER_LOGICAL_NOT];
    };
    Blockly.Python.text_indexOf = function (a) {
        var b = "FIRST" == a.getFieldValue("END") ? "find" : "rfind",
            c = Blockly.Python.valueToCode(a, "FIND", Blockly.Python.ORDER_NONE) || "''";
        b = (Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_MEMBER) || "''") + "." + b + "(" + c + ")";
        return a.workspace.options.oneBasedIndex ? [b + " + 1", Blockly.Python.ORDER_ADDITIVE] : [b, Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.text_charAt = function (a) {
        var b = a.getFieldValue("WHERE") || "FROM_START",
            c = Blockly.Python.valueToCode(a, "VALUE", "RANDOM" == b ? Blockly.Python.ORDER_NONE : Blockly.Python.ORDER_MEMBER) || "''";
        switch (b) {
            case "FIRST":
                return [c + "[0]", Blockly.Python.ORDER_MEMBER];
            case "LAST":
                return [c + "[-1]", Blockly.Python.ORDER_MEMBER];
            case "FROM_START":
                return (a = Blockly.Python.getAdjustedInt(a, "AT")), [c + "[" + a + "]", Blockly.Python.ORDER_MEMBER];
            case "FROM_END":
                return (a = Blockly.Python.getAdjustedInt(a, "AT", 1, !0)), [c + "[" + a + "]", Blockly.Python.ORDER_MEMBER];
            case "RANDOM":
                return (
                    (Blockly.Python.definitions_.import_random = "import random"),
                    [
                        Blockly.Python.provideFunction_("text_random_letter", ["def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(text):", "  x = int(random.random() * len(text))", "  return text[x];"]) + "(" + c + ")",
                        Blockly.Python.ORDER_FUNCTION_CALL,
                    ]
                );
        }
        throw Error("Unhandled option (text_charAt).");
    };
    Blockly.Python.text_getSubstring = function (a) {
        var b = a.getFieldValue("WHERE1"),
            c = a.getFieldValue("WHERE2"),
            d = Blockly.Python.valueToCode(a, "STRING", Blockly.Python.ORDER_MEMBER) || "''";
        switch (b) {
            case "FROM_START":
                b = Blockly.Python.getAdjustedInt(a, "AT1");
                "0" == b && (b = "");
                break;
            case "FROM_END":
                b = Blockly.Python.getAdjustedInt(a, "AT1", 1, !0);
                break;
            case "FIRST":
                b = "";
                break;
            default:
                throw Error("Unhandled option (text_getSubstring)");
        }
        switch (c) {
            case "FROM_START":
                a = Blockly.Python.getAdjustedInt(a, "AT2", 1);
                break;
            case "FROM_END":
                a = Blockly.Python.getAdjustedInt(a, "AT2", 0, !0);
                Blockly.isNumber(String(a)) ? "0" == a && (a = "") : ((Blockly.Python.definitions_.import_sys = "import sys"), (a += " or sys.maxsize"));
                break;
            case "LAST":
                a = "";
                break;
            default:
                throw Error("Unhandled option (text_getSubstring)");
        }
        return [d + "[" + b + " : " + a + "]", Blockly.Python.ORDER_MEMBER];
    };
    Blockly.Python.text_changeCase = function (a) {
        var b = { UPPERCASE: ".upper()", LOWERCASE: ".lower()", TITLECASE: ".title()" }[a.getFieldValue("CASE")];
        return [(Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_MEMBER) || "''") + b, Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.text_trim = function (a) {
        var b = { LEFT: ".lstrip()", RIGHT: ".rstrip()", BOTH: ".strip()" }[a.getFieldValue("MODE")];
        return [(Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_MEMBER) || "''") + b, Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.text_print = function (a) {
        return "print(" + (Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_NONE) || "''") + ")\n";
    };
    Blockly.Python.text_prompt_ext = function (a) {
        var b = Blockly.Python.provideFunction_("text_prompt", ["def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(msg):", "  try:", "    return raw_input(msg)", "  except NameError:", "    return input(msg)"]),
            c = a.getField("TEXT") ? Blockly.Python.quote_(a.getFieldValue("TEXT")) : Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_NONE) || "''";
        b = b + "(" + c + ")";
        "NUMBER" == a.getFieldValue("TYPE") && (b = "float(" + b + ")");
        return [b, Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.text_prompt = Blockly.Python.text_prompt_ext;
    Blockly.Python.text_count = function (a) {
        var b = Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_MEMBER) || "''";
        a = Blockly.Python.valueToCode(a, "SUB", Blockly.Python.ORDER_NONE) || "''";
        return [b + ".count(" + a + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    };
    Blockly.Python.text_replace = function (a) {
        var b = Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_MEMBER) || "''",
            c = Blockly.Python.valueToCode(a, "FROM", Blockly.Python.ORDER_NONE) || "''";
        a = Blockly.Python.valueToCode(a, "TO", Blockly.Python.ORDER_NONE) || "''";
        return [b + ".replace(" + c + ", " + a + ")", Blockly.Python.ORDER_MEMBER];
    };
    Blockly.Python.text_reverse = function (a) {
        return [(Blockly.Python.valueToCode(a, "TEXT", Blockly.Python.ORDER_MEMBER) || "''") + "[::-1]", Blockly.Python.ORDER_MEMBER];
    };
    Blockly.Python.variables = {};
    Blockly.Python.variables_get = function (a) {
        return [Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME), Blockly.Python.ORDER_ATOMIC];
    };

    Blockly.Python.variables_set = function (a) {

        var b = Blockly.Python.valueToCode(a, "VALUE", Blockly.Python.ORDER_NONE) || "0";
        if (a.getInputTargetBlock() != null){

            if (a.getInputTargetBlock("VALUE").outputConnection.getCheck() == "DataFrame") {
                VarData[Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME)] = b;
            }

        }
        return Blockly.Python.variableDB_.getName(a.getFieldValue("VAR"), Blockly.VARIABLE_CATEGORY_NAME) + " = " + b + "\n";
    };
    Blockly.Python.variablesDynamic = {};
    Blockly.Python.variables_get_dynamic = Blockly.Python.variables_get;
    Blockly.Python.variables_set_dynamic = Blockly.Python.variables_set;

    Blockly.Python.intersectionalBias = function (a) {
        var df = Blockly.Python.valueToCode(a, "DATAFRAME", Blockly.Python.ORDER_NONE);
        Blockly.Python.definitions_.etiq_core = "from etiq_core import *;";
        Blockly.Python.definitions_.opendatasets = "import opendatasets as od";
        Blockly.Python.definitions_.pandas = "import pandas as pd";
        Blockly.Python.definitions_.numpy = "import numpy as np";
        Blockly.Python.definitions_.warnings = "import warnings";
        Blockly.Python.definitions_.pprint = "import pprint";
        Blockly.Python.definitions_.deepcopy = "from copy import deepcopy";
        Blockly.Python.definitions_.matplotlib_pyplot = "import matplotlib.pyplot as plt";
        Blockly.Python.definitions_.seaborn = "import seaborn as sns";
        Blockly.Python.definitions_.scipy = "import scipy.stats as st";
        Blockly.Python.definitions_.re = "import re";
        Blockly.Python.definitions_.datetime = "import datetime";
        Blockly.Python.definitions_.import_math = "import math";
        Blockly.Python.definitions_.interactiveShell = "from IPython.core.interactiveshell import InteractiveShell";
        Blockly.Python.definitions_.is_string_dtype = "from pandas.api.types import is_string_dtype";
        Blockly.Python.definitions_.pythonwarnings = "import warnings";
        Blockly.Python.definitions_.pythonlogging = "import logging";
        var dropnan = 0
        if (a.getFieldValue("SPLIT") == "dropNa") {
            dropnan = 1
        }
        var biased_cols = Blockly.Python.valueToCode(a, "BIASEDCOLS", Blockly.Python.ORDER_NONE);
        var privileged_cols = Blockly.Python.valueToCode(a, "PRIVILEGEDCOLS", Blockly.Python.ORDER_NONE);
        var pos_outcome = Blockly.Python.valueToCode(a, "POSOUTCOME", Blockly.Python.ORDER_NONE);
        var b = Blockly.Python.provideFunction_("check_intersectional_bias", [
            "def " + Blockly.Python.FUNCTION_NAME_PLACEHOLDER_ + "(dataset, dropnan, biased_cols, privileged_cols, pos_outcome):",
            "\n",
            "    # Setting display off warning and info messages",
            "    warnings.filterwarnings(\"ignore\")",
            "    logger = logging.getLogger(\"etiq_core\")",
            "    logger.setLevel(level = logging.CRITICAL)",
            "\n",
            "    def get_debias_params(protected, privileged, unprivileged, positive_label, negative_label):",
            "        return BiasParams(protected=protected, privileged=privileged, unprivileged=unprivileged,\n" +
            "                        positive_outcome_label=positive_label, negative_outcome_label=negative_label) ",
            "\n",
            "    transforms = [Dropna, EncodeLabels]",
            "    metrics_bonus = [accuracy,  equal_opportunity,demographic_parity, equal_odds_tpr, equal_odds_tnr,\n" +
            "        true_neg_rate, true_pos_rate, individual_fairness, individual_fairness_cf]",
            "    metrics_initial = [accuracy,  equal_opportunity,demographic_parity, equal_odds_tnr, individual_fairness]",
            "    metrics_short = [accuracy, demographic_parity, equal_opportunity, individual_fairness]",
            "    metrics_sshort = [accuracy, demographic_parity, equal_opportunity]",
            "    metrics_list = ['accuracy','demographic_parity','equal_opportunity', 'individual_fairness']",
            "    metrics_list_short = ['accuracy','demographic_parity','equal_opportunity']",
            "    # Wrapper to avoid having to call the clean classifier, dl and pipe, returns metrics",
            "    def etiq_wrapper_run(data, debias_params, cont_val, cat_val, p_feature, metrics):",
            "        xgb = DefaultXGBoostClassifier()",
            "        dl = DatasetLoader(data=data, label=p_feature, transforms=transforms, bias_params=debias_params,\n" +
            "                        train_valid_test_splits=[0.8, 0.1, 0.1], cat_col=cat_vars,\n" +
            "                        cont_col=cont_vars, names_col = data.columns.values);",
            "        pipeline_initial = DataPipeline(dataset_loader=dl, model=xgb, metrics=metrics);",
            "        pipeline_initial.run();",
            "        metrics = pipeline_initial.get_protected_metrics();",
            "        return metrics",
            "\n",
            "    # Insert into the given dataset the column obtained by intersecting protected1 and protected2, drop the two original columns if drop is true",
            "    def get_intersection(data, protected1, protected2, drop = True):",
            "        column_name = protected1 + \"_\" + protected2",
            "        data[column_name] = data[protected1] + \"_\" + data[protected2]",
            "        if(drop): data = data.drop([protected1, protected2],axis=1)",
            "        return data",
            "\n",
            "    # Create a dataframe from metrics_result of two rows (privileged and unprivileged), the columns are the metrics in debias_params (set globally)",
            "    def get_df_from_metrics(metrics_result):",
            "        m = deepcopy(metrics_result)",
            "        item = m.popitem()",
            "        if(item[1] is not None):",
            "            l = item[1]",
            "            d = {'privilege':['privileged', 'unprivileged']}",
            "            d['class'] = [debias_params.privileged, debias_params.unprivileged]",
            "            for x in l:",
            "                ppitem = x.popitem()",
            "                d[ppitem[0]] = [ppitem[1][1], ppitem[1][3]]",
            "            df = pd.DataFrame(data = d)",
            "            return df",
            "        else:",
            "            return null",
            "\n",
            "    # Create a dataframe from metrics_result with one row for metrics in metrics_in, columns are the parameters in biasParams_in and one column",
            "    # for the calculated disparity as a ratio",
            "    def get_disparity_df(metrics_result, biasParams_in, metrics_in):",
            "        m = deepcopy(metrics_result)",
            "        item = m.popitem()",
            "        if(item[1] is not None):",
            "            l = item[1]",
            "            d = {'metric': ['group'], 'privileged': [biasParams_in.privileged], 'unprivileged': [biasParams_in.unprivileged], 'disparity': ['']}",
            "            for x in l:",
            "                ppitem = x.popitem()",
            "                if(ppitem[0] in metrics_in):",
            "                    d['metric'].append(ppitem[0])",
            "                    d['privileged'].append(ppitem[1][1])",
            "                    d['unprivileged'].append(ppitem[1][3])",
            "                    d['disparity'].append(ppitem[1][3] / ppitem[1][1])",
            "            df = pd.DataFrame(data = d)",
            "            df = df.set_index('metric')",
            "            return df",
            "        else:",
            "            return null",
            "\n",
            "    # Intersects feature1 and feature2 in dataset data. Calculate the EDF on the p_feature of the entries in the subgroups obtained by joining",
            "    # attributes1 and attributes2. If in_place modifies d (intersects the columns but does NOT delete the originals)",
            "    # I intersect f1 and f2, I choose which subgroups of the features I want to examine (e.g. I intersect Sex and Race, I choose 'White, Black' and",
            "    # 'Male, Female' to search for elements in \"White_Male\", \"White_Female\", \"Black_Male\" and \" Black_Female\")",
            "    def get_edf_df(data, feature1, feature2, attributes1, attributes2, p_feature, in_place = True):",
            "        d = data",
            "        if not in_place: d = data.deepcopy(data)",
            "        subg = feature1+'_'+feature2",
            "        intersections = []",
            "        for a1 in attributes1:",
            "            for a2 in attributes2:",
            "                if a1 != a2: intersections.append(a1+'_'+a2)",
            "        d = get_intersection(d, feature1, feature2, drop = False)",
            "        result = {'group1': [], 'group2': []}",
            "        for g in intersections:",
            "            for other in intersections:",
            "                if g != other:",
            "                    result['group1'].append(g)",
            "                    result['group2'].append(other)",
            "                    #for s in subgs:",
            "                    if 'disparity' not in result: result['disparity'] = []",
            "                    if g in d[subg].unique() and other in d[subg].unique():",
            "                        p = d.groupby(subg).sum()",
            "                        Nys_i = p.at[g, p_feature]",
            "                        Ns_i = len(d[d[subg] == g])",
            "                        Nys_j = p.at[other, p_feature]",
            "                        Ns_j = len(d[d[subg] == other])",
            "                        result['disparity'].append((Nys_i / Ns_i) * (Ns_j / Nys_j))",
            "                    else: result['disparity'].append('')",
            "        df = pd.DataFrame(data = result)",
            "        if not in_place: del d",
            "        return df",
            "\n",
            "    # Extracts the n pairs with greatest difference of EDF from edf obtained from get_edf_df",
            "    def read_edf(edf, n = 1):",
            "        groups = []",
            "        wedf = edf",
            "        if n > 1:",
            "            wedf = edf.copy()",
            "        for i in range(n):",
            "            idx = wedf['disparity'].idxmax()",
            "        val = wedf['disparity'].max()",
            "        groups.append((wedf.at[idx, 'group1'], wedf.at[idx, 'group2'], val))",
            "        if n > 1:",
            "            wedf.drop([idx], axis = 0, inplace = True)",
            "        return groups",
            "\n",
            "    # Create a dataframe from dataset data with modal values and their occurrences of features in features for positive_outcome outcomes",
            "    # and negative_outcome outcomes of the p_feature",
            "    def get_mode_df(data, features, p_feature, positive_outcome, negative_outcome):",
            "        d = {'feature': [],",
            "            'mode_pos': [], 'mode_occ_pos': [], 'total_mode_occ_pos': [],",
            "            'mode_neg': [], 'mode_occ_neg': [], 'total_mode_occ_neg': []}",
            "        for ft in features:",
            "            pos = data[data[p_feature] == positive_outcome].groupby(ft).size()",
            "            neg = data[data[p_feature] == negative_outcome].groupby(ft).size()",
            "            d['feature'].append(ft)",
            "            d['mode_pos'].append(pos.idxmax())",
            "            d['mode_occ_pos'].append(pos.max())",
            "            d['total_mode_occ_pos'].append(len(data[data[ft] == pos.idxmax()]))",
            "            d['mode_neg'].append(neg.idxmax())",
            "            d['mode_occ_neg'].append(neg.max())",
            "            d['total_mode_occ_neg'].append(len(data[data[ft] == neg.idxmax()]))",
            "        df = pd.DataFrame(data = d)",
            "        df = df.set_index('feature')",
            "        return df",
            "\n",
            "    # Like get_mode_df, but instead of the modal value, the value with the greatest ratio between occurrences and total cardinality",
            "    def get_ratio_df(data, features, p_feature, positive_outcome, negative_outcome):",
            "        d = {'feature': [],\n" +
            "            'max_ratio_pos': [], 'max_ratio_occ_pos': [], 'max_ratio_tot_occ_pos': [],\n" +
            "            'max_ratio_neg': [], 'max_ratio_occ_neg':[], 'max_ratio_tot_occ_neg':[]}",
            "        for ft in features:",
            "            pos = data[data[p_feature] == positive_outcome].groupby(ft).size()",
            "            neg = data[data[p_feature] == negative_outcome].groupby(ft).size()",
            "            d['feature'].append(ft)",
            "            ratios = {}",
            "            for i, v in enumerate(pos):",
            "                n = len(data[data[ft] == pos.index[i]])",
            "                ratios[pos.index[i]] = v / n",
            "            pos_ratios = sorted(ratios.items(), key = lambda x : x[1], reverse = True)",
            "            cat, val = pos_ratios[0]",
            "            max_i = (cat, round(val, 2))",
            "            d['max_ratio_pos'].append(max_i)",
            "            d['max_ratio_occ_pos'].append(pos[max_i[0]])",
            "            d['max_ratio_tot_occ_pos'].append(len(data[data[ft] == max_i[0]]))",
            "            ratios = {}",
            "            for i, v in enumerate(neg):",
            "                n = len(data[data[ft] == neg.index[i]])",
            "                ratios[neg.index[i]] = v / n",
            "            neg_ratios = sorted(ratios.items(), key = lambda x : x[1], reverse = True)",
            "            cat, val = neg_ratios[0]",
            "            max_i = (cat, round(val, 2))",
            "            d['max_ratio_neg'].append(max_i)",
            "            d['max_ratio_occ_neg'].append(neg[max_i[0]])",
            "            d['max_ratio_tot_occ_neg'].append(len(data[data[ft] == max_i[0]]))",
            "        df = pd.DataFrame(data = d)",
            "        df = df.set_index('feature')",
            "        return df",
            "\n",
            "    # Merge of the two functions above",
            "    def get_mode_ratio_df(data, features, p_feature, positive_outcome, negative_outcome):",
            "        d = {'feature': [],\n" +
            "            'mode_pos': [], 'mode_occ_pos': [], 'total_mode_occ_pos': [], 'max_ratio_pos': [], 'max_ratio_occ_pos': [], 'max_ratio_tot_occ_pos': [],\n" +
            "            'mode_neg': [], 'mode_occ_neg': [], 'total_mode_occ_neg': [], 'max_ratio_neg': [], 'max_ratio_occ_neg':[], 'max_ratio_tot_occ_neg':[]}",
            "        for ft in features:",
            "            pos = data[data[p_feature] == positive_outcome].groupby(ft).size()",
            "            neg = data[data[p_feature] == negative_outcome].groupby(ft).size()",
            "            d['feature'].append(ft)",
            "            d['mode_pos'].append(pos.idxmax())",
            "            d['mode_occ_pos'].append(pos.max())",
            "            d['total_mode_occ_pos'].append(len(data[data[ft] == pos.idxmax()]))",
            "            ratios = {}",
            "            for i, v in enumerate(pos):",
            "                n = len(data[data[ft] == pos.index[i]])",
            "                ratios[pos.index[i]] = v / n",
            "            pos_ratios = sorted(ratios.items(), key = lambda x : x[1], reverse = True)",
            "            cat, val = pos_ratios[0]",
            "            max_i = (cat, round(val, 2))",
            "            d['max_ratio_pos'].append(max_i)",
            "            d['max_ratio_occ_pos'].append(pos[max_i[0]])",
            "            d['max_ratio_tot_occ_pos'].append(len(data[data[ft] == max_i[0]]))",
            "            d['mode_neg'].append(neg.idxmax())",
            "            d['mode_occ_neg'].append(neg.max())",
            "            d['total_mode_occ_neg'].append(len(data[data[ft] == neg.idxmax()]))",
            "            ratios = {}",
            "            for i, v in enumerate(neg):",
            "                n = len(data[data[ft] == neg.index[i]])",
            "                ratios[neg.index[i]] = v / n",
            "            neg_ratios = sorted(ratios.items(), key = lambda x : x[1], reverse = True)",
            "            cat, val = neg_ratios[0]",
            "            max_i = (cat, round(val, 2))",
            "            d['max_ratio_neg'].append(max_i)",
            "            d['max_ratio_occ_neg'].append(neg[max_i[0]])",
            "            d['max_ratio_tot_occ_neg'].append(len(data[data[ft] == max_i[0]]))",
            "        df = pd.DataFrame(data = d)",
            "        df = df.set_index('feature')",
            "        return df",
            "\n",
            "    # Returns a pair of dicts, the first for occurrences of positive_outcome of the p_feature and the second for occurrences",
            "    # of negative_outcome. Each dict contains, for each feature in features, the number of times a value has been modal for at least",
            "    # one of the samples",
            "    def get_maxOccurrences_in_samples(samples, features, p_feature, positive_outcome, negative_outcome):",
            "        results_pos = {}",
            "        results_neg = {}",
            "        for i in range(len(samples)):",
            "            df = get_mode_ratio_df(data = samples[i], features = features, p_feature = p_feature ,\n" +
            "                positive_outcome = positive_outcome, negative_outcome = negative_outcome)",
            "            for ind in df.index:",
            "                ft = ind",
            "                if ft not in results_pos: results_pos[ft] = {}",
            "                val = df.at[ind, 'mode_pos']",
            "                if val not in results_pos[ft]: results_pos[ft][val] = 0",
            "                results_pos[ft][val] += 1",
            "                if ft not in results_neg: results_neg[ft] = {}",
            "                val = df.at[ind, 'mode_neg']",
            "                if val not in results_neg[ft]: results_neg[ft][val] = 0",
            "                results_neg[ft][val] += 1",
            "        return (results_pos, results_neg)",
            "\n",
            "    # As above but with reports",
            "    def get_maxOccurrences_ratio_in_samples(samples, features, p_feature, positive_outcome, negative_outcome):",
            "        results_pos = {}",
            "        results_neg = {}",
            "        for i in range(len(samples)):",
            "            df = get_mode_ratio_df(data = samples[i], features = features, p_feature = p_feature,\n" +
            "                positive_outcome = positive_outcome, negative_outcome = negative_outcome)",
            "            for ind in df.index:",
            "                ft = ind",
            "                if ft not in results_pos: results_pos[ft] = {}",
            "                val, k = df.at[ind, 'max_ratio_pos']",
            "                if val not in results_pos[ft]: results_pos[ft][val] = 0",
            "                results_pos[ft][val] += 1",
            "                if ft not in results_neg: results_neg[ft] = {}",
            "                val, k = df.at[ind, 'max_ratio_neg']",
            "                if val not in results_neg[ft]: results_neg[ft][val] = 0",
            "                results_neg[ft][val] += 1",
            "        return (results_pos, results_neg)",
            "\n",
            "    # Not used(?)",
            "    def get_intersections_count(samples, features1, features2, attributes1, attributes2):",
            "        results = {}",
            "        subgs = []",
            "        for f1 in features1:",
            "            for f2 in features2:",
            "                if f1 != f2: subgs.append(f1+'_'+f2)",
            "        intersections = []",
            "        for a1 in attributes1:",
            "            for a2 in attributes2:",
            "                if a1 != a2: intersections.append(a1+'_'+a2)",
            "        for sample in samples:",
            "            for f1 in features1:",
            "                for f2 in features2:",
            "                    if f1 != f2:",
            "                        sample = get_intersection(sample, f1, f2, drop = False)",
            "        for g in subgs:",
            "            for t in intersections:",
            "                n = len(sample[sample[g] == t])",
            "                if n > 0:",
            "                    if g not in results: results[g] = {}",
            "                    if t not in results[g]: results[g][t] = 0",
            "                    results[g][t] += n",
            "        return results",
            "\n",
            "    # Dict with modal feature values for the feature's value (bad name for var, sorry)",
            "    # the usage examples in the rest of the notebook are far more helpful than the explanation",
            "    def get_values_of(samples, feature, value, features):",
            "        result = {}",
            "        for sample in samples:",
            "            subset = sample[sample[feature] == value]",
            "        for ft in features:",
            "            if ft not in result: result[ft] = None",
            "            count = subset.groupby(ft).size()",
            "            if len(count) > 0: result[ft] = count.idxmax()",
            "        return result",
            "\n",
            "    # Same as above, but filter by the outcome of the p_feature",
            "    def get_values_of_outcome(samples, feature, value, features, p_feature, outcome):",
            "        result = {}",
            "        for sample in samples:",
            "            subset = sample[(sample[feature] == value) & (sample[p_feature] == outcome)]",
            "            for ft in features:",
            "                if ft not in result: result[ft] = None",
            "                count = subset.groupby(ft).size()",
            "                if len(count) > 0: result[ft] = count.idxmax()",
            "        return result",
            "\n",
            "    # Removes the feature most closely related to the p_feature among the features in relevant_features",
            "    # Returns a pair with the data changed and the index removed",
            "    def remove_max_corr(data, relevant_features, p_feature):",
            "        corr = data.corr().abs()",
            "        corr.drop([p_feature], axis = 0, inplace = True)",
            "        for i in corr.index:",
            "            if i not in relevant_features:",
            "                corr.drop([i], axis = 0, inplace = True)",
            "        idx = corr[p_feature].idxmax()",
            "        data = data.drop([idx], axis = 1)",
            "        return (data, idx)",
            "\n",
            "    # As above but repeated n times",
            "    # Returns a pair with data and indexes removed",
            "    def iterative_correlation_removal(n, data, relevant_features, p_feature):",
            "        removed = []",
            "        for i in range(n):",
            "            data, r = remove_max_corr(data, relevant_features, p_feature)",
            "            removed.append(r)",
            "        return data, removed",
            "\n",
            "    # Iterates the process of removing a feature related to p_feature n times. If reinsert = false the result is cumulative,",
            "    # otherwise I reinsert at each step and calculate the next in order of correlation",
            "    # Returns a dict with disparity changes",
            "    def disparity_change(data, n, reinsert, relevant_features, p_feature, debias_params, cont_vars, cat_vars, metrics):",
            "        old = {}",
            "        result = {}",
            "        metrics_list = []",
            "        columns = {}",
            "        for m in metrics:",
            "            metrics_list.append(m.__name__)",
            "        metrics_in = get_disparity_df(etiq_wrapper_run(data, debias_params, cont_vars, cat_vars, p_feature, metrics),\n" +
            "            debias_params, metrics_list)",
            "        for m in metrics_list:",
            "            old[m] = metrics_in.loc[m]['disparity']",
            "        corr = data.corr().abs()",
            "        corr.drop([p_feature], axis = 0, inplace = True)",
            "        for i in corr.index:",
            "            if i not in relevant_features:",
            "                corr.drop([i], axis = 0, inplace = True)",
            "        for i in range(n):",
            "            idx = corr[p_feature].idxmax()",
            "            corr.drop([idx], axis = 0, inplace = True)",
            "            column = data[idx]",
            "            columns[idx] = column",
            "            data.drop([idx], axis = 1, inplace = True)",
            "            cont_vars = list(set(cont_vars) - set([idx]))",
            "            xgb = DefaultXGBoostClassifier()",
            "            dl = DatasetLoader(data=data, label=p_feature, transforms=transforms, bias_params=debias_params,\n" +
            "                train_valid_test_splits=[0.8, 0.1, 0.1], cat_col=cat_vars,\n" +
            "                cont_col=cont_vars, names_col = data.columns.values);",
            "            pipeline_initial = DataPipeline(dataset_loader=dl, model=xgb, metrics=metrics);",
            "            pipeline_initial.run();",
            "            metr = pipeline_initial.get_protected_metrics();",
            "            metrics_out = get_disparity_df(metr, debias_params, metrics_list)",
            "            #metrics_out = get_disparity_df(etiq_wrapper_run(data, debias_params, cont_vars, cat_vars, p_feature, metrics),",
            "            #                              debias_params, metrics_list)",
            "            if idx not in result: result[idx] = {}",
            "            for m in metrics_list:",
            "                new = metrics_out.loc[m]['disparity']",
            "                result[idx][m] = new - old[m]",
            "            if reinsert:",
            "                cont_vars.append(idx)",
            "                data[idx] = column",
            "        if not reinsert:",
            "            for c in columns:",
            "                data[c] = columns[c]",
            "        return result",
            "\n",
            "    # From the above function it extracts the features whose removal modifies the value of p_feature the most",
            "    def disparity_change_get_max(result):",
            "        out = {}",
            "        for ft in result:",
            "            for m in result[ft]:",
            "                if m not in out: out[m] = (ft, result[ft][m], ft, result[ft][m])",
            "                if result[ft][m] < out[m][1]: out[m] = (ft, result[ft][m], out[m][2], out[m][3])",
            "                if result[ft][m] > out[m][3]: out[m] = (out[m][0], out[m][1], ft, result[ft][m])",
            "        return out",
            "\n",
            "    def to_num(x):",
            "        threshold = dataset[privileged_cols].unique().tolist()",
            "        if (x == threshold[0]):",
            "            return 1",
            "        else:",
            "            return 0",
            "\n",
            "    # Detecting dataset NaN values",
            "    if dropnan == 1:",
            "        valuesToCheck = \"?\\/-\"",
            "        for elem in valuesToCheck:",
            "            if elem in dataset.values:",
            "                dataset.replace(elem, np.nan)",
            "        dataset.dropna()",
            "\n",
            "    # Convert \'date of birth\' or similar columns in \'Age\' column",
            "    def fix_age(x):",
            "        if x <= 0:",
            "            x += 99",
            "        return x",
            "\n",
            "    def to_age(dataset_to_transform, label_to_transform):",
            "        now = datetime.date.today() # calcola data odierna",
            "        dob_copy = dataset_to_transform[label_to_transform] # copia del campo DOB",
            "        dob_copy = pd.to_datetime(dob_copy, format = '%m/%d/%y') # imposta il formato corretto",
            "        date_now = pd.to_datetime(now)",
            "        dataset_to_transform[\"Age\"] = (date_now - dob_copy)/np.timedelta64(1,'Y') # la differenza tra le due date, espressa in anni",
            "        dataset_to_transform[\"Age\"] = dataset_to_transform[\"Age\"].astype(int) # imposta il tipo di dato del campo come intero",
            "        dataset_to_transform['Age'] = dataset_to_transform['Age'].apply(fix_age) # serve per correggere un errore del parser di python nella funzione di conversione",
            "        # to_datetime: gli anni con valori < 69 venivano attribuiti al 1900 mentre quelli >= 69 al 2000, sfasando l'età di 99 anni",
            "\n",
            "    dataset_labels = []",
            "    for elem in dataset.columns:",
            "        dataset_labels.append(str(elem))",
            "    if \"DOB\" in dataset_labels:",
            "        to_age(dataset, \"DOB\")",
            "    match_birth = []",
            "    for label in dataset_labels:",
            "        if len(re.findall(\"birth\", label, re.IGNORECASE)) > 0:",
            "            match_birth.append(label)",
            "    if len(match_birth) > 0:",
            "        to_age(dataset, match_birth[0])",
            "\n",
            "    # Clean columns from space characters at the beginning and at the end of the string",
            "    for elem in dataset.columns:",
            "        elem = elem.strip()",
            "\n",
            "    # Check that the input biased columns are in dataset",
            "    error_message = 1",
            "    count_bias_cols = 0",
            "    for elem in dataset.columns:",
            "        for label in biased_cols:",
            "            if label == elem:",
            "                count_bias_cols += 1",
            "    if count_bias_cols == 0:",
            "        raise Exception(\"The specified biased columns are not in the dataset\")",
            "    elif count_bias_cols == 1:",
            "        raise Exception(\"One specified biased column is not in the dataset\")",
            "\n",
            "    # Here start the real bias analysis",
            "    result = \"\"",
            "    result = \"Sensitive fields were found\"",
            "    # Check that the input privileged column is in dataset",
            "    error_message = 1",
            "    for label in dataset.columns:",
            "        if label == privileged_cols:",
            "            error_message = 0",
            "    if error_message == 1:",
            "        raise Exception(\"The specified privileged column is not in the dataset\")",
            "\n",
            "    # Calculate the number of bins",
            "    number_of_rows = len(dataset.index)",
            "    number_of_bins = math.ceil(math.sqrt(number_of_rows))",
            "\n",
            "    # Calculate EDF metric",
            "    edf_list = []",
            "    df_edf_list = []",
            "    for ind in range(len(biased_cols)):",
            "        attribute1_set = np.array(dataset[biased_cols[ind]].unique()).tolist()",
            "        for i in range(len(biased_cols)):",
            "            if (ind == i) or not (is_string_dtype(dataset[biased_cols[ind]].dtype)) or not (is_string_dtype(dataset[biased_cols[i]].dtype)):",
            "                pass",
            "            else:",
            "                attribute2_set = np.array(dataset[biased_cols[i]].unique()).tolist()",
            "                new_privileged_cols = privileged_cols + \"_01\"",
            "                dataset[new_privileged_cols] = dataset[privileged_cols].apply(to_num)   # .apply must be replaced with another method, performance issue",
            "                edf = get_edf_df(dataset, biased_cols[ind], biased_cols[i], attribute1_set, attribute2_set, new_privileged_cols)",
            "                edf_list.append(edf)",
            "                df = pd.DataFrame(read_edf(edf, n = 3))",
            "                df_edf_list.append(df)",
            "    # Setting final message",
            "    edf_result = 0",
            "    if not df_edf_list:",
            "        result += \" but compatible columns cannot be found to calculate EDF metric.\"",
            "        return result",
            "    else:",
            "        max_edf = 0",
            "        max_df_edf = df_edf_list[0]",
            "        for elem in df_edf_list:",
            "            if elem.iloc[0][2] > max_edf:",
            "                max_edf = elem.iloc[0][2]",
            "                max_df_edf = elem",
            "        edf_result = 1",
            "\n",
            "    if edf_result == 0:",
            "        result += \" but compatible columns cannot be found to calculate EDF metric.\"",
            "        return result",
            "    else:",
            "\n",
            "        # Calculate intersection, metrics and disparity",
            "        data_copy = get_intersection(dataset, biased_cols[0], biased_cols[1])",
            "        cont_vars = []",
            "        for label in dataset.columns:",
            "            if dataset[label].dtype == np.int64 or dataset[label].dtype == np.float64 or dataset[label].dtype == np.complex128 or dataset[label].dtype == np.int32 or dataset[label].dtype == np.float32:",
            "                cont_vars.append(label)",
            "        cat_vars = list(set(dataset.columns.values) - set(cont_vars))",
            "        intersect_var = biased_cols[0] + \"_\" + biased_cols[1]",
            "        privilege_values = dataset[privileged_cols].unique().tolist()",
            "        debias_params = get_debias_params(intersect_var, max_df_edf.iloc[0, 0], max_df_edf.iloc[0, 1], str(privilege_values[0]), str(privilege_values[1]))",
            "        metrics = etiq_wrapper_run(dataset, debias_params, cont_vars, cat_vars, privileged_cols, metrics_bonus)",
            "        df_metrics = get_df_from_metrics(metrics)",
            "        df_disparity = get_disparity_df(metrics, debias_params, metrics_list)",
            "        print(\"\\n\" + \"EDF (Empirical Differential Fairness) is the ratio between the ratios between positive and total cases of two groups, calculated on the data, without the contribution of a classifier.\")",
            "        print(\"EDF of the \" + biased_cols[0] + \" and \" + biased_cols[1] + \" intersection on the privileged variable \" + privileged_cols + \":\\n\")",
            "        print(max_df_edf)",
            "        print(\"\\n\")",
            "        print(\"Equal opportunity is the probability of a privileged individual being classified as such must be the same for everyone. In other words all groups should have similar, or ideally equal, True Positive Rates.\\nAlso it is a relaxation of the Equalized Odds, in which it is required that in addition to the same True Positive Rate there is also the same False Positive Rate.\\nDemographic Parity is obtained when all groups have the same Predictive Positive Rate.\\nThe set of all these metrics are defined here as Fairness metrics.\")",
            "        print(\"Fairness metrics for \" + df_metrics.iloc[0][\"class\"] + \" and \" + df_metrics.iloc[1][\"class\"] + \":\\n\")",
            "        print(df_metrics)",
            "        print(\"\\n\")",
            "        print(\"Disparity is the ratio of its value to the unprivileged group to its value to the privileged group.\")",
            "        print(\"Disparity on fairness metrics for \" + df_metrics.iloc[0][\"class\"] + \" and \" + df_metrics.iloc[1][\"class\"] + \":\\n\")",
            "        print(df_disparity)",
            "\n",
            "        # Calculate modal values, ratio between positive and negative outcome, occurrences of associating values to a datum feature",
            "        features = cat_vars",
            "        features.append(intersect_var)",
            "        for v in privilege_values:",
            "            if str(v) != pos_outcome:",
            "                neg_outcome = str(v)",
            "        df_ratio = get_ratio_df(data = dataset, features = features, p_feature = privileged_cols, positive_outcome = pos_outcome, negative_outcome = neg_outcome)",
            "        df_mode = get_mode_df(data = dataset, features = features, p_feature = privileged_cols, positive_outcome = pos_outcome, negative_outcome = neg_outcome)",
            "        df_intersection = get_intersection(dataset, biased_cols[0], biased_cols[1], drop = False)",
            "        print(\"Ratio between positive and negative outcomes:\\n\")",
            "        print(df_ratio)",
            "        print(\"\\n\")",
            "        print(\"Modal values:\\n\")",
            "        print(df_mode)",
            "        print(\"\\n\")",
            "        print(\"Intersection:\\n\")",
            "        print(df_intersection)",
            "        print(\"\\n\")",
            "        samples = []",
            "        for i in range(50):",
            "            sample = dataset.sample(n = 1000, ignore_index = True)",
            "            samples.append(sample)",
            "        results_pos, results_neg = get_maxOccurrences_in_samples(samples = samples, features = features, p_feature = privileged_cols, positive_outcome = pos_outcome, negative_outcome = neg_outcome)",
            "        print(\"Positive income mode:\\n\")",
            "        print(results_pos)",
            "        print(\"Negative income mode:\\n\")",
            "        print(results_neg)",
            "        print(\"\\n\")",
            "        df_values_of_1st = get_values_of(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 0], features = features)",
            "        print(\"Below is a list that provides the values most frequently associated with\"+ max_df_edf.iloc[0, 0] + \", and it's useful to observe any differences in modal values between the privileged and the unprivileged group:\\n\")",
            "        print(df_values_of_1st)",
            "        df_values_of_2nd = get_values_of(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 1], features = features)",
            "        print(\"Below is a list that provides the values most frequently associated with\"+ max_df_edf.iloc[0, 1] + \", and it's useful to observe any differences in modal values between the privileged and the unprivileged group:\\n\")",
            "        print(df_values_of_2nd)",
            "        print(\"\\n\")",
            "        df_values_of_outcome_1st = get_values_of_outcome(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 0], features = features, p_feature = privileged_cols, outcome = pos_outcome)",
            "        print(\"Instead below there is a list like the previous one but it filters the observations based on the result of the privilege feature, with positive outcome, and it's useful to observe the differences between the modal values of the privileged and non-privileged individuals for \" + max_df_edf.iloc[0, 0] + \":\\n\")",
            "        print(df_values_of_outcome_1st)",
            "        df_values_of_outcome_2nd = get_values_of_outcome(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 1], features = features, p_feature = privileged_cols, outcome = pos_outcome)",
            "        print(\"Instead below there is a list like the previous one but it filters the observations based on the result of the privilege feature, with positive outcome, and it's useful to observe the differences between the modal values of the privileged and non-privileged individuals for \" + max_df_edf.iloc[0, 1] + \":\\n\")",
            "        print(df_values_of_outcome_2nd)",
            "        print(\"\\n\")",
            "        df_values_of_outcome_1st_neg = get_values_of_outcome(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 0], features = features, p_feature = privileged_cols, outcome = neg_outcome)",
            "        print(\"Instead below there is a list like the previous one but it filters the observations based on the result of the privilege feature, with negative outcome, and it's useful to observe the differences between the modal values of the privileged and non-privileged individuals for \" + max_df_edf.iloc[0, 0] + \":\\n\")",
            "        print(df_values_of_outcome_1st_neg)",
            "        df_values_of_outcome_2nd_neg = get_values_of_outcome(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 1], features = features, p_feature = privileged_cols, outcome = neg_outcome)",
            "        print(\"Instead below there is a list like the previous one but it filters the observations based on the result of the privilege feature, with negative outcome, and it's useful to observe the differences between the modal values of the privileged and non-privileged individuals for \" + max_df_edf.iloc[0, 1] + \":\\n\")",
            "        print(df_values_of_outcome_2nd_neg)"
    ]);
        return [b + "(" + df + ", " + dropnan + ", " + biased_cols + ", " + privileged_cols + ", " + pos_outcome + ")", Blockly.Python.ORDER_FUNCTION_CALL];
    }

    Blockly.Python.anchoringBias = function (a) {
        // copy here Giorgia's library
        var b = Blockly.Python.provideFunction_("do_null", [
            "pass"
        ]);
        return b;
    }

    Blockly.Python.BIAS_Intersectional = Blockly.Python.intersectionalBias;
    Blockly.Python.BIAS_Anchoring = Blockly.Python.anchoringBias;

    return Blockly.Python;

});
