{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e3c3ff",
   "metadata": {},
   "source": [
    "# Intersectional bias analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff0c4191",
   "metadata": {
    "source_hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for trying out the ETIQ.ai toolkit!\n",
      "\n",
      "Visit our getting started documentation at https://docs.etiq.ai/\n",
      "\n",
      "Visit our Slack channel at https://etiqcore.slack.com/ for support or feedback.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from etiq_core import *;\n",
    "import opendatasets as od\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pprint\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import re\n",
    "import datetime\n",
    "import math\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from pandas.api.types import is_string_dtype\n",
    "import warnings\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1b6c7",
   "metadata": {
    "source_hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Setting display off warning and info messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger = logging.getLogger(\"etiq_core\")\n",
    "logger.setLevel(level = logging.CRITICAL)\n",
    "\n",
    "\n",
    "def get_debias_params(protected, privileged, unprivileged, positive_label, negative_label):\n",
    "    return BiasParams(protected=protected, privileged=privileged, unprivileged=unprivileged, positive_outcome_label=positive_label, negative_outcome_label=negative_label)\n",
    "\n",
    "\n",
    "transforms = [Dropna, EncodeLabels]\n",
    "metrics_bonus = [accuracy,  equal_opportunity,demographic_parity, equal_odds_tpr, equal_odds_tnr, true_neg_rate, true_pos_rate, individual_fairness, individual_fairness_cf]\n",
    "metrics_initial = [accuracy,  equal_opportunity,demographic_parity, equal_odds_tnr, individual_fairness]\n",
    "metrics_short = [accuracy, demographic_parity, equal_opportunity, individual_fairness]\n",
    "metrics_sshort = [accuracy, demographic_parity, equal_opportunity]\n",
    "metrics_list = ['accuracy','demographic_parity','equal_opportunity', 'individual_fairness']\n",
    "metrics_list_short = ['accuracy','demographic_parity','equal_opportunity']\n",
    "# Wrapper to avoid having to call the clean classifier, dl and pipe, returns metrics\n",
    "def etiq_wrapper_run(data, debias_params, cont_val, cat_val, p_feature, metrics):\n",
    "    xgb = DefaultXGBoostClassifier()\n",
    "    dl = DatasetLoader(data=data, label=p_feature, transforms=transforms, bias_params=debias_params, train_valid_test_splits=[0.8, 0.1, 0.1], cat_col=cat_vars, cont_col=cont_vars, names_col = data.columns.values);\n",
    "    pipeline_initial = DataPipeline(dataset_loader=dl, model=xgb, metrics=metrics);\n",
    "    pipeline_initial.run();\n",
    "    metrics = pipeline_initial.get_protected_metrics();\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Insert into the given dataset the column obtained by intersecting protected1 and protected2, drop the two original columns if drop is true\n",
    "def get_intersection(data, protected1, protected2, drop = True):\n",
    "    column_name = protected1 + \"_\" + protected2\n",
    "    data[column_name] = data[protected1] + \"_\" + data[protected2]\n",
    "    if(drop): data = data.drop([protected1, protected2],axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Create a dataframe from metrics_result of two rows (privileged and unprivileged), the columns are the metrics in debias_params (set globally)\n",
    "def get_df_from_metrics(metrics_result):\n",
    "    m = deepcopy(metrics_result)\n",
    "    item = m.popitem()\n",
    "    if(item[1] is not None):\n",
    "        l = item[1]\n",
    "        d = {'privilege':['privileged', 'unprivileged']}\n",
    "        d['class'] = [debias_params.privileged, debias_params.unprivileged]\n",
    "        for x in l:\n",
    "            ppitem = x.popitem()\n",
    "            d[ppitem[0]] = [ppitem[1][1], ppitem[1][3]]\n",
    "        df = pd.DataFrame(data = d)\n",
    "        return df\n",
    "    else:\n",
    "        return null\n",
    "\n",
    "\n",
    "# Create a dataframe from metrics_result with one row for metrics in metrics_in, columns are the parameters in biasParams_in and one column\n",
    "# for the calculated disparity as a ratio\n",
    "def get_disparity_df(metrics_result, biasParams_in, metrics_in):\n",
    "    m = deepcopy(metrics_result)\n",
    "    item = m.popitem()\n",
    "    if(item[1] is not None):\n",
    "        l = item[1]\n",
    "        d = {'metric': ['group'], 'privileged': [biasParams_in.privileged], 'unprivileged': [biasParams_in.unprivileged], 'disparity': ['']}\n",
    "        for x in l:\n",
    "            ppitem = x.popitem()\n",
    "            if(ppitem[0] in metrics_in):\n",
    "                d['metric'].append(ppitem[0])\n",
    "                d['privileged'].append(ppitem[1][1])\n",
    "                d['unprivileged'].append(ppitem[1][3])\n",
    "                d['disparity'].append(ppitem[1][3] / ppitem[1][1])\n",
    "        df = pd.DataFrame(data = d)\n",
    "        df = df.set_index('metric')\n",
    "        return df\n",
    "    else:\n",
    "        return null\n",
    "\n",
    "\n",
    "# Intersects feature1 and feature2 in dataset data. Calculate the EDF on the p_feature of the entries in the subgroups obtained by joining\n",
    "# attributes1 and attributes2. If in_place modifies d (intersects the columns but does NOT delete the originals)\n",
    "# I intersect f1 and f2, I choose which subgroups of the features I want to examine (e.g. I intersect Sex and Race, I choose 'White, Black' and\n",
    "# 'Male, Female' to search for elements in \"White_Male\", \"White_Female\", \"Black_Male\" and \" Black_Female\")\n",
    "def get_edf_df(data, feature1, feature2, attributes1, attributes2, p_feature, in_place = True):\n",
    "    d = data\n",
    "    if not in_place: d = data.deepcopy(data)\n",
    "    subg = feature1+'_'+feature2\n",
    "    intersections = []\n",
    "    for a1 in attributes1:\n",
    "        for a2 in attributes2:\n",
    "            if a1 != a2: intersections.append(a1+'_'+a2)\n",
    "    d = get_intersection(d, feature1, feature2, drop = False)\n",
    "    result = {'group1': [], 'group2': []}\n",
    "    for g in intersections:\n",
    "        for other in intersections:\n",
    "            if g != other:\n",
    "                result['group1'].append(g)\n",
    "                result['group2'].append(other)\n",
    "                #for s in subgs:\n",
    "                if 'disparity' not in result: result['disparity'] = []\n",
    "                if g in d[subg].unique() and other in d[subg].unique():\n",
    "                    p = d.groupby(subg).sum()\n",
    "                    Nys_i = p.at[g, p_feature]\n",
    "                    Ns_i = len(d[d[subg] == g])\n",
    "                    Nys_j = p.at[other, p_feature]\n",
    "                    Ns_j = len(d[d[subg] == other])\n",
    "                    result['disparity'].append((Nys_i / Ns_i) * (Ns_j / Nys_j))\n",
    "                else: result['disparity'].append('')\n",
    "    df = pd.DataFrame(data = result)\n",
    "    if not in_place: del d\n",
    "    return df\n",
    "\n",
    "\n",
    "# Extracts the n pairs with greatest difference of EDF from edf obtained from get_edf_df\n",
    "def read_edf(edf, n = 1):\n",
    "    groups = []\n",
    "    wedf = edf\n",
    "    if n > 1:\n",
    "        wedf = edf.copy()\n",
    "    for i in range(n):\n",
    "        idx = wedf['disparity'].idxmax()\n",
    "    val = wedf['disparity'].max()\n",
    "    groups.append((wedf.at[idx, 'group1'], wedf.at[idx, 'group2'], val))\n",
    "    if n > 1:\n",
    "        wedf.drop([idx], axis = 0, inplace = True)\n",
    "    return groups\n",
    "\n",
    "\n",
    "# Create a dataframe from dataset data with modal values and their occurrences of features in features for positive_outcome outcomes\n",
    "# and negative_outcome outcomes of the p_feature\n",
    "def get_mode_df(data, features, p_feature, positive_outcome, negative_outcome):\n",
    "    d = {'feature': [],\n",
    "        'mode_pos': [], 'mode_occ_pos': [], 'total_mode_occ_pos': [],\n",
    "        'mode_neg': [], 'mode_occ_neg': [], 'total_mode_occ_neg': []}\n",
    "    for ft in features:\n",
    "        pos = data[data[p_feature] == positive_outcome].groupby(ft).size()\n",
    "        neg = data[data[p_feature] == negative_outcome].groupby(ft).size()\n",
    "        d['feature'].append(ft)\n",
    "        d['mode_pos'].append(pos.idxmax())\n",
    "        d['mode_occ_pos'].append(pos.max())\n",
    "        d['total_mode_occ_pos'].append(len(data[data[ft] == pos.idxmax()]))\n",
    "        d['mode_neg'].append(neg.idxmax())\n",
    "        d['mode_occ_neg'].append(neg.max())\n",
    "        d['total_mode_occ_neg'].append(len(data[data[ft] == neg.idxmax()]))\n",
    "    df = pd.DataFrame(data = d)\n",
    "    df = df.set_index('feature')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Like get_mode_df, but instead of the modal value, the value with the greatest ratio between occurrences and total cardinality\n",
    "def get_ratio_df(data, features, p_feature, positive_outcome, negative_outcome):\n",
    "    d = {'feature': [], 'max_ratio_pos': [], 'max_ratio_occ_pos': [], 'max_ratio_tot_occ_pos': [], 'max_ratio_neg': [], 'max_ratio_occ_neg':[], 'max_ratio_tot_occ_neg':[]}\n",
    "    for ft in features:\n",
    "        pos = data[data[p_feature] == positive_outcome].groupby(ft).size()\n",
    "        neg = data[data[p_feature] == negative_outcome].groupby(ft).size()\n",
    "        d['feature'].append(ft)\n",
    "        ratios = {}\n",
    "        for i, v in enumerate(pos):\n",
    "            n = len(data[data[ft] == pos.index[i]])\n",
    "            ratios[pos.index[i]] = v / n\n",
    "        pos_ratios = sorted(ratios.items(), key = lambda x : x[1], reverse = True)\n",
    "        cat, val = pos_ratios[0]\n",
    "        max_i = (cat, round(val, 2))\n",
    "        d['max_ratio_pos'].append(max_i)\n",
    "        d['max_ratio_occ_pos'].append(pos[max_i[0]])\n",
    "        d['max_ratio_tot_occ_pos'].append(len(data[data[ft] == max_i[0]]))\n",
    "        ratios = {}\n",
    "        for i, v in enumerate(neg):\n",
    "            n = len(data[data[ft] == neg.index[i]])\n",
    "            ratios[neg.index[i]] = v / n\n",
    "        neg_ratios = sorted(ratios.items(), key = lambda x : x[1], reverse = True)\n",
    "        cat, val = neg_ratios[0]\n",
    "        max_i = (cat, round(val, 2))\n",
    "        d['max_ratio_neg'].append(max_i)\n",
    "        d['max_ratio_occ_neg'].append(neg[max_i[0]])\n",
    "        d['max_ratio_tot_occ_neg'].append(len(data[data[ft] == max_i[0]]))\n",
    "    df = pd.DataFrame(data = d)\n",
    "    df = df.set_index('feature')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Merge of the two functions above\n",
    "def get_mode_ratio_df(data, features, p_feature, positive_outcome, negative_outcome):\n",
    "    d = {'feature': [], 'mode_pos': [], 'mode_occ_pos': [], 'total_mode_occ_pos': [], 'max_ratio_pos': [], 'max_ratio_occ_pos': [], 'max_ratio_tot_occ_pos': [], 'mode_neg': [], 'mode_occ_neg': [], 'total_mode_occ_neg': [], 'max_ratio_neg': [], 'max_ratio_occ_neg':[], 'max_ratio_tot_occ_neg':[]}\n",
    "    for ft in features:\n",
    "        pos = data[data[p_feature] == positive_outcome].groupby(ft).size()\n",
    "        neg = data[data[p_feature] == negative_outcome].groupby(ft).size()\n",
    "        d['feature'].append(ft)\n",
    "        d['mode_pos'].append(pos.idxmax())\n",
    "        d['mode_occ_pos'].append(pos.max())\n",
    "        d['total_mode_occ_pos'].append(len(data[data[ft] == pos.idxmax()]))\n",
    "        ratios = {}\n",
    "        for i, v in enumerate(pos):\n",
    "            n = len(data[data[ft] == pos.index[i]])\n",
    "            ratios[pos.index[i]] = v / n\n",
    "        pos_ratios = sorted(ratios.items(), key = lambda x : x[1], reverse = True)\n",
    "        cat, val = pos_ratios[0]\n",
    "        max_i = (cat, round(val, 2))\n",
    "        d['max_ratio_pos'].append(max_i)\n",
    "        d['max_ratio_occ_pos'].append(pos[max_i[0]])\n",
    "        d['max_ratio_tot_occ_pos'].append(len(data[data[ft] == max_i[0]]))\n",
    "        d['mode_neg'].append(neg.idxmax())\n",
    "        d['mode_occ_neg'].append(neg.max())\n",
    "        d['total_mode_occ_neg'].append(len(data[data[ft] == neg.idxmax()]))\n",
    "        ratios = {}\n",
    "        for i, v in enumerate(neg):\n",
    "            n = len(data[data[ft] == neg.index[i]])\n",
    "            ratios[neg.index[i]] = v / n\n",
    "        neg_ratios = sorted(ratios.items(), key = lambda x : x[1], reverse = True)\n",
    "        cat, val = neg_ratios[0]\n",
    "        max_i = (cat, round(val, 2))\n",
    "        d['max_ratio_neg'].append(max_i)\n",
    "        d['max_ratio_occ_neg'].append(neg[max_i[0]])\n",
    "        d['max_ratio_tot_occ_neg'].append(len(data[data[ft] == max_i[0]]))\n",
    "    df = pd.DataFrame(data = d)\n",
    "    df = df.set_index('feature')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Returns a pair of dicts, the first for occurrences of positive_outcome of the p_feature and the second for occurrences\n",
    "# of negative_outcome. Each dict contains, for each feature in features, the number of times a value has been modal for at least\n",
    "# one of the samples\n",
    "def get_maxOccurrences_in_samples(samples, features, p_feature, positive_outcome, negative_outcome):\n",
    "    results_pos = {}\n",
    "    results_neg = {}\n",
    "    for i in range(len(samples)):\n",
    "        df = get_mode_ratio_df(data = samples[i], features = features, p_feature = p_feature, positive_outcome = positive_outcome, negative_outcome = negative_outcome)\n",
    "        for ind in df.index:\n",
    "            ft = ind\n",
    "            if ft not in results_pos: results_pos[ft] = {}\n",
    "            val = df.at[ind, 'mode_pos']\n",
    "            if val not in results_pos[ft]: results_pos[ft][val] = 0\n",
    "            results_pos[ft][val] += 1\n",
    "            if ft not in results_neg: results_neg[ft] = {}\n",
    "            val = df.at[ind, 'mode_neg']\n",
    "            if val not in results_neg[ft]: results_neg[ft][val] = 0\n",
    "            results_neg[ft][val] += 1\n",
    "    return (results_pos, results_neg)\n",
    "\n",
    "\n",
    "# As above but with reports\n",
    "def get_maxOccurrences_ratio_in_samples(samples, features, p_feature, positive_outcome, negative_outcome):\n",
    "    results_pos = {}\n",
    "    results_neg = {}\n",
    "    for i in range(len(samples)):\n",
    "        df = get_mode_ratio_df(data = samples[i], features = features, p_feature = p_feature, positive_outcome = positive_outcome, negative_outcome = negative_outcome)\n",
    "        for ind in df.index:\n",
    "            ft = ind\n",
    "            if ft not in results_pos: results_pos[ft] = {}\n",
    "            val, k = df.at[ind, 'max_ratio_pos']\n",
    "            if val not in results_pos[ft]: results_pos[ft][val] = 0\n",
    "            results_pos[ft][val] += 1\n",
    "            if ft not in results_neg: results_neg[ft] = {}\n",
    "            val, k = df.at[ind, 'max_ratio_neg']\n",
    "            if val not in results_neg[ft]: results_neg[ft][val] = 0\n",
    "            results_neg[ft][val] += 1\n",
    "    return (results_pos, results_neg)\n",
    "\n",
    "\n",
    "# Not used(?)\n",
    "def get_intersections_count(samples, features1, features2, attributes1, attributes2):\n",
    "    results = {}\n",
    "    subgs = []\n",
    "    for f1 in features1:\n",
    "        for f2 in features2:\n",
    "            if f1 != f2: subgs.append(f1+'_'+f2)\n",
    "    intersections = []\n",
    "    for a1 in attributes1:\n",
    "        for a2 in attributes2:\n",
    "            if a1 != a2: intersections.append(a1+'_'+a2)\n",
    "    for sample in samples:\n",
    "        for f1 in features1:\n",
    "            for f2 in features2:\n",
    "                if f1 != f2:\n",
    "                    sample = get_intersection(sample, f1, f2, drop = False)\n",
    "    for g in subgs:\n",
    "        for t in intersections:\n",
    "            n = len(sample[sample[g] == t])\n",
    "            if n > 0:\n",
    "                if g not in results: results[g] = {}\n",
    "                if t not in results[g]: results[g][t] = 0\n",
    "                results[g][t] += n\n",
    "    return results\n",
    "\n",
    "\n",
    "# Dict with modal feature values for the feature's value (bad name for var, sorry)\n",
    "# the usage examples in the rest of the notebook are far more helpful than the explanation\n",
    "def get_values_of(samples, feature, value, features):\n",
    "    result = {}\n",
    "    for sample in samples:\n",
    "        subset = sample[sample[feature] == value]\n",
    "    for ft in features:\n",
    "        if ft not in result: result[ft] = None\n",
    "        count = subset.groupby(ft).size()\n",
    "        if len(count) > 0: result[ft] = count.idxmax()\n",
    "    return result\n",
    "\n",
    "\n",
    "# Same as above, but filter by the outcome of the p_feature\n",
    "def get_values_of_outcome(samples, feature, value, features, p_feature, outcome):\n",
    "    result = {}\n",
    "    for sample in samples:\n",
    "        subset = sample[(sample[feature] == value) & (sample[p_feature] == outcome)]\n",
    "        for ft in features:\n",
    "            if ft not in result: result[ft] = None\n",
    "            count = subset.groupby(ft).size()\n",
    "            if len(count) > 0: result[ft] = count.idxmax()\n",
    "    return result\n",
    "\n",
    "\n",
    "# Removes the feature most closely related to the p_feature among the features in relevant_features\n",
    "# Returns a pair with the data changed and the index removed\n",
    "def remove_max_corr(data, relevant_features, p_feature):\n",
    "    corr = data.corr().abs()\n",
    "    corr.drop([p_feature], axis = 0, inplace = True)\n",
    "    for i in corr.index:\n",
    "        if i not in relevant_features:\n",
    "            corr.drop([i], axis = 0, inplace = True)\n",
    "    idx = corr[p_feature].idxmax()\n",
    "    data = data.drop([idx], axis = 1)\n",
    "    return (data, idx)\n",
    "\n",
    "\n",
    "# As above but repeated n times\n",
    "# Returns a pair with data and indexes removed\n",
    "def iterative_correlation_removal(n, data, relevant_features, p_feature):\n",
    "    removed = []\n",
    "    for i in range(n):\n",
    "        data, r = remove_max_corr(data, relevant_features, p_feature)\n",
    "        removed.append(r)\n",
    "    return data, removed\n",
    "\n",
    "\n",
    "# Iterates the process of removing a feature related to p_feature n times. If reinsert = false the result is cumulative,\n",
    "# otherwise I reinsert at each step and calculate the next in order of correlation\n",
    "# Returns a dict with disparity changes\n",
    "def disparity_change(data, n, reinsert, relevant_features, p_feature, debias_params, cont_vars, cat_vars, metrics):\n",
    "    old = {}\n",
    "    result = {}\n",
    "    metrics_list = []\n",
    "    columns = {}\n",
    "    for m in metrics:\n",
    "        metrics_list.append(m.__name__)\n",
    "    metrics_in = get_disparity_df(etiq_wrapper_run(data, debias_params, cont_vars, cat_vars, p_feature, metrics), debias_params, metrics_list)\n",
    "    for m in metrics_list:\n",
    "        old[m] = metrics_in.loc[m]['disparity']\n",
    "    corr = data.corr().abs()\n",
    "    corr.drop([p_feature], axis = 0, inplace = True)\n",
    "    for i in corr.index:\n",
    "        if i not in relevant_features:\n",
    "            corr.drop([i], axis = 0, inplace = True)\n",
    "    for i in range(n):\n",
    "        idx = corr[p_feature].idxmax()\n",
    "        corr.drop([idx], axis = 0, inplace = True)\n",
    "        column = data[idx]\n",
    "        columns[idx] = column\n",
    "        data.drop([idx], axis = 1, inplace = True)\n",
    "        cont_vars = list(set(cont_vars) - set([idx]))\n",
    "        xgb = DefaultXGBoostClassifier()\n",
    "        dl = DatasetLoader(data=data, label=p_feature, transforms=transforms, bias_params=debias_params, train_valid_test_splits=[0.8, 0.1, 0.1], cat_col=cat_vars, cont_col=cont_vars, names_col = data.columns.values);\n",
    "        pipeline_initial = DataPipeline(dataset_loader=dl, model=xgb, metrics=metrics);\n",
    "        pipeline_initial.run();\n",
    "        metr = pipeline_initial.get_protected_metrics();\n",
    "        metrics_out = get_disparity_df(metr, debias_params, metrics_list)\n",
    "        #metrics_out = get_disparity_df(etiq_wrapper_run(data, debias_params, cont_vars, cat_vars, p_feature, metrics),\n",
    "        #                              debias_params, metrics_list)\n",
    "        if idx not in result: result[idx] = {}\n",
    "        for m in metrics_list:\n",
    "            new = metrics_out.loc[m]['disparity']\n",
    "            result[idx][m] = new - old[m]\n",
    "        if reinsert:\n",
    "            cont_vars.append(idx)\n",
    "            data[idx] = column\n",
    "    if not reinsert:\n",
    "        for c in columns:\n",
    "            data[c] = columns[c]\n",
    "    return result\n",
    "\n",
    "\n",
    "# From the above function it extracts the features whose removal modifies the value of p_feature the most\n",
    "def disparity_change_get_max(result):\n",
    "    out = {}\n",
    "    for ft in result:\n",
    "        for m in result[ft]:\n",
    "            if m not in out: out[m] = (ft, result[ft][m], ft, result[ft][m])\n",
    "            if result[ft][m] < out[m][1]: out[m] = (ft, result[ft][m], out[m][2], out[m][3])\n",
    "            if result[ft][m] > out[m][3]: out[m] = (out[m][0], out[m][1], ft, result[ft][m])\n",
    "    return out\n",
    "\n",
    "\n",
    "def to_num(x):\n",
    "    threshold = dataset[privileged_cols].unique().tolist()\n",
    "    if (x == threshold[0]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Convert 'date of birth' or similar columns in 'Age' column\n",
    "def fix_age(x):\n",
    "    if x <= 0:\n",
    "        x += 99\n",
    "    return x\n",
    "\n",
    "\n",
    "def to_age(dataset_to_transform, label_to_transform):\n",
    "    now = datetime.date.today() # calcola data odierna\n",
    "    dob_copy = dataset_to_transform[label_to_transform] # copia del campo DOB\n",
    "    dob_copy = pd.to_datetime(dob_copy, format = '%m/%d/%y') # imposta il formato corretto\n",
    "    date_now = pd.to_datetime(now)\n",
    "    dataset_to_transform[\"Age\"] = (date_now - dob_copy)/np.timedelta64(1,'Y') # la differenza tra le due date, espressa in anni\n",
    "    dataset_to_transform[\"Age\"] = dataset_to_transform[\"Age\"].astype(int) # imposta il tipo di dato del campo come intero\n",
    "    dataset_to_transform['Age'] = dataset_to_transform['Age'].apply(fix_age) # serve per correggere un errore del parser di python nella funzione di conversione\n",
    "    # to_datetime: gli anni con valori < 69 venivano attribuiti al 1900 mentre quelli >= 69 al 2000, sfasando l'etÃ  di 99 anni\n",
    "\n",
    "dataset = pd.read_csv(\"adult.csv\")\n",
    "dropnan = 1\n",
    "biased_cols = ['gender', 'race']\n",
    "privileged_cols = 'income'\n",
    "pos_outcome = '>50K'\n",
    "\n",
    "# Checking input\n",
    "dataset_labels = []\n",
    "for elem in dataset.columns:\n",
    "    dataset_labels.append(str(elem))\n",
    "for col in biased_cols:\n",
    "    if col not in dataset_labels:\n",
    "        raise Exception(\"One or both biased columns are not in the dataset.\")\n",
    "if privileged_cols not in dataset_labels:\n",
    "    raise Exception(\"The privileged variable is not in the dataset.\")\n",
    "if pos_outcome not in dataset[privileged_cols].unique():\n",
    "    raise Exception(\"The positive outcome is not a possible value of the privileged variable.\")\n",
    "# Detecting dataset NaN values\n",
    "if dropnan == 1:\n",
    "    valuesToCheck = \"?\\/-\"\n",
    "    for elem in valuesToCheck:\n",
    "        if elem in dataset.values:\n",
    "            dataset.replace(elem, np.nan)\n",
    "    dataset.dropna()\n",
    "\n",
    "\n",
    "if \"DOB\" in dataset_labels:\n",
    "    to_age(dataset, \"DOB\")\n",
    "match_birth = []\n",
    "for label in dataset_labels:\n",
    "    if len(re.findall(\"birth\", label, re.IGNORECASE)) > 0:\n",
    "        match_birth.append(label)\n",
    "if len(match_birth) > 0:\n",
    "    to_age(dataset, match_birth[0])\n",
    "\n",
    "\n",
    "# Clean columns from space characters at the beginning and at the end of the string\n",
    "for elem in dataset.columns:\n",
    "    elem = elem.strip()\n",
    "\n",
    "\n",
    "# Check that the input biased columns are in dataset\n",
    "error_message = 1\n",
    "count_bias_cols = 0\n",
    "for elem in dataset.columns:\n",
    "    for label in biased_cols:\n",
    "        if label == elem:\n",
    "            count_bias_cols += 1\n",
    "if count_bias_cols == 0:\n",
    "    raise Exception(\"The specified biased columns are not in the dataset\")\n",
    "elif count_bias_cols == 1:\n",
    "    raise Exception(\"One specified biased column is not in the dataset\")\n",
    "\n",
    "\n",
    "# Here start the real bias analysis\n",
    "result = \"\"\n",
    "result = \"Sensitive fields were found\"\n",
    "# Check that the input privileged column is in dataset\n",
    "error_message = 1\n",
    "for label in dataset.columns:\n",
    "    if label == privileged_cols:\n",
    "        error_message = 0\n",
    "if error_message == 1:\n",
    "    raise Exception(\"The specified privileged column is not in the dataset\")\n",
    "\n",
    "\n",
    "# Calculate the number of bins\n",
    "number_of_rows = len(dataset.index)\n",
    "number_of_bins = math.ceil(math.sqrt(number_of_rows))\n",
    "\n",
    "\n",
    "# Calculate EDF metric\n",
    "edf_list = []\n",
    "df_edf_list = []\n",
    "for ind in range(len(biased_cols)):\n",
    "    attribute1_set = np.array(dataset[biased_cols[ind]].unique()).tolist()\n",
    "    for i in range(len(biased_cols)):\n",
    "        if (ind == i) or not (is_string_dtype(dataset[biased_cols[ind]].dtype)) or not (is_string_dtype(dataset[biased_cols[i]].dtype)):\n",
    "            pass\n",
    "        else:\n",
    "            attribute2_set = np.array(dataset[biased_cols[i]].unique()).tolist()\n",
    "            new_privileged_cols = privileged_cols + \"_01\"\n",
    "            dataset[new_privileged_cols] = dataset[privileged_cols].apply(to_num)   # .apply must be replaced with another method, performance issue\n",
    "            edf = get_edf_df(dataset, biased_cols[ind], biased_cols[i], attribute1_set, attribute2_set, new_privileged_cols)\n",
    "            edf_list.append(edf)\n",
    "            df = pd.DataFrame(read_edf(edf, n = 3))\n",
    "            df_edf_list.append(df)\n",
    "# Setting final message\n",
    "edf_result = 0\n",
    "if not df_edf_list:\n",
    "    result += \" but compatible columns cannot be found to calculate EDF metric.\"\n",
    "    raise Exception(result)\n",
    "else:\n",
    "    max_edf = 0\n",
    "    max_df_edf = df_edf_list[0]\n",
    "    for elem in df_edf_list:\n",
    "        if elem.iloc[0][2] > max_edf:\n",
    "            max_edf = elem.iloc[0][2]\n",
    "            max_df_edf = elem\n",
    "    edf_result = 1\n",
    "\n",
    "\n",
    "if edf_result == 0:\n",
    "    result += \" but compatible columns cannot be found to calculate EDF metric.\"\n",
    "    raise Exception(result)\n",
    "else:\n",
    "\n",
    "\n",
    "    # Calculate intersection, metrics and disparity\n",
    "    data_copy = get_intersection(dataset, biased_cols[0], biased_cols[1])\n",
    "    cont_vars = []\n",
    "    for label in dataset.columns:\n",
    "        if dataset[label].dtype == np.int64 or dataset[label].dtype == np.float64 or dataset[label].dtype == np.complex128 or dataset[label].dtype == np.int32 or dataset[label].dtype == np.float32:\n",
    "            cont_vars.append(label)\n",
    "    cat_vars = list(set(dataset.columns.values) - set(cont_vars))\n",
    "    intersect_var = biased_cols[0] + \"_\" + biased_cols[1]\n",
    "    privilege_values = dataset[privileged_cols].unique().tolist()\n",
    "    debias_params = get_debias_params(intersect_var, max_df_edf.iloc[0, 0], max_df_edf.iloc[0, 1], str(privilege_values[0]), str(privilege_values[1]))\n",
    "    metrics = etiq_wrapper_run(dataset, debias_params, cont_vars, cat_vars, privileged_cols, metrics_bonus)\n",
    "    df_metrics = get_df_from_metrics(metrics)\n",
    "    df_disparity = get_disparity_df(metrics, debias_params, metrics_list)\n",
    "\n",
    "\n",
    "    # Calculate modal values, ratio between positive and negative outcome, occurrences of associating values to a datum feature\n",
    "    features = cat_vars\n",
    "    neg_outcome = \"\"\n",
    "    for v in privilege_values:\n",
    "        if str(v) != pos_outcome:\n",
    "            neg_outcome = str(v)\n",
    "    if not neg_outcome:\n",
    "        raise ValueError(\"The value of the negative outcome could not be found. Please check that the privilege variable contains exactly two values.\")\n",
    "    df_ratio = get_ratio_df(data = dataset, features = features, p_feature = privileged_cols, positive_outcome = pos_outcome, negative_outcome = neg_outcome)\n",
    "    df_mode = get_mode_df(data = dataset, features = features, p_feature = privileged_cols, positive_outcome = pos_outcome, negative_outcome = neg_outcome)\n",
    "    df_intersection = get_intersection(dataset, biased_cols[0], biased_cols[1], drop = False)\n",
    "    samples = []\n",
    "    for i in range(50):\n",
    "        sample = dataset.sample(n = 1000, ignore_index = True)\n",
    "        samples.append(sample)\n",
    "    results_pos, results_neg = get_maxOccurrences_in_samples(samples = samples, features = features, p_feature = privileged_cols, positive_outcome = pos_outcome, negative_outcome = neg_outcome)\n",
    "    df_values_of_1st = get_values_of(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 0], features = features)\n",
    "    df_values_of_2nd = get_values_of(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 1], features = features)\n",
    "    df_values_of_outcome_1st = get_values_of_outcome(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 0], features = features, p_feature = privileged_cols, outcome = pos_outcome)\n",
    "    df_values_of_outcome_2nd = get_values_of_outcome(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 1], features = features, p_feature = privileged_cols, outcome = pos_outcome)\n",
    "    df_outcome_1st_neg = get_values_of_outcome(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 0], features = features, p_feature = privileged_cols, outcome = neg_outcome)\n",
    "    df_outcome_2nd_neg = get_values_of_outcome(samples = [dataset], feature = intersect_var, value = max_df_edf.iloc[0, 1], features = features, p_feature = privileged_cols, outcome = neg_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e99539",
   "metadata": {},
   "source": [
    "## EDF\n",
    "The Empirical Differential Fairness (EDF) is the ratio between the ratios between positive and total cases of two groups, calculated on the data, without the contribution of a classifier.\n",
    "EDF of the {{ biased_cols[0] }} and {{ biased_cols[1] }} intersection on the privileged variable {{ privileged_cols }}:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df_edf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58cb140",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "Equal opportunity is the probability of a privileged individual being classified as such must be the same for everyone. In other words all groups should have similar, or ideally equal, True Positive Rates.\n",
    "Also it is a relaxation of the Equalized Odds, in which it is required that in addition to the same True Positive Rate there is also the same False Positive Rate.\n",
    "Demographic Parity is obtained when all groups have the same Predictive Positive Rate.\n",
    "The set of all these metrics are defined here as Fairness metrics.\n",
    "Fairness metrics for {{ df_metrics.iloc[0][\"class\"] }} and {{ df_metrics.iloc[1][\"class\"] }}:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd6873",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2201079b",
   "metadata": {},
   "source": [
    "## Disparity\n",
    "Disparity is the ratio of its value to the unprivileged group to its value to the privileged group.\n",
    "Disparity on fairness metrics for {{ df_metrics.iloc[0][\"class\"] }} and {{ df_metrics.iloc[1][\"class\"] }}:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d901a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d814435",
   "metadata": {},
   "source": [
    "## Ratio\n",
    "Ratio between positive and negative outcomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f03e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a7eb7",
   "metadata": {},
   "source": [
    "## Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec23eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01062b21",
   "metadata": {},
   "source": [
    "## Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d82bd4e",
   "metadata": {},
   "source": [
    "## Positive privileged mode\n",
    "Positive mode for {{ privileged_cols }}:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cb4a99",
   "metadata": {},
   "source": [
    "## Negative privileged mode\n",
    "Negative mode for {{ privileged_cols }}:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11799f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516afdc3",
   "metadata": {},
   "source": [
    "## Frequent pattern #1\n",
    "Below is a list that provides the values most frequently associated with {{ max_df_edf.iloc[0, 0] }}, and it's useful to observe any differences in modal values between the privileged and the unprivileged group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3705e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values_of_1st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f492e",
   "metadata": {},
   "source": [
    "## Frequent pattern #2\n",
    "Below is a list that provides the values most frequently associated with {{ max_df_edf.iloc[0, 1] }}, and it's useful to observe any differences in modal values between the privileged and the unprivileged group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f17df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values_of_2nd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa18889c",
   "metadata": {},
   "source": [
    "## Frequent pattern positive privileged #1\n",
    "Instead below there is a list like the previous one but it filters the observations based on the result of the privilege feature, with positive outcome, and it's useful to observe the differences between the modal values of the privileged and non-privileged individuals for {{ max_df_edf.iloc[0, 0] }}:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b28c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values_of_outcome_1st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946cf1ad",
   "metadata": {},
   "source": [
    "## Frequent pattern positive privileged #2\n",
    "Instead below there is a list like the previous one but it filters the observations based on the result of the privilege feature, with positive outcome, and it's useful to observe the differences between the modal values of the privileged and non-privileged individuals for {{ max_df_edf.iloc[0, 1] }}:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ebe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values_of_outcome_2nd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7704da84",
   "metadata": {},
   "source": [
    "## Frequent pattern negative privileged #1\n",
    "Instead below there is a list like the previous one but it filters the observations based on the result of the privilege feature, with negative outcome, and it's useful to observe the differences between the modal values of the privileged and non-privileged individuals for {{ max_df_edf.iloc[0, 0] }}:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcome_1st_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8179e69c",
   "metadata": {},
   "source": [
    "## Frequent pattern negative privileged #2\n",
    "Instead below there is a list like the previous one but it filters the observations based on the result of the privilege feature, with negative outcome, and it's useful to observe the differences between the modal values of the privileged and non-privileged individuals for {{ max_df_edf.iloc[0, 1] }}:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d025cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcome_2nd_neg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
